{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 22:46:43.046678: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-23 22:46:43.157066: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 22:46:43.157083: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-10-23 22:46:43.181671: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-23 22:46:43.785379: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 22:46:43.785463: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 22:46:43.785470: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from os.path import realpath\n",
    "import glob\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import join as join\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.applications import ResNet101\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation = \"sigmoid\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 03:39:25.045687: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-23 03:39:25.045893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 03:39:25.045952: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 03:39:25.046007: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 03:39:25.046059: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 03:39:25.046110: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 03:39:25.046161: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 03:39:25.046213: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 03:39:25.046264: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib/python3.10/dist-packages/cv2/../../lib64:\n",
      "2022-10-23 03:39:25.046272: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1934] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-10-23 03:39:25.046770: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
      "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.experimental.preprocessing.RandomFlip(\"horizontal\", \n",
    "                                                 input_shape=(SIZE, \n",
    "                                                              SIZE,\n",
    "                                                              3)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.2),\n",
    "    layers.experimental.preprocessing.RandomZoom(0.2),\n",
    "    \n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_augmentation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [45], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dropout\n\u001b[1;32m      4\u001b[0m feature_extractor \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 5\u001b[0m feature_extractor\u001b[38;5;241m.\u001b[39madd(\u001b[43mdata_augmentation\u001b[49m)\n\u001b[1;32m      6\u001b[0m feature_extractor\u001b[38;5;241m.\u001b[39madd(Conv2D(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m, activation \u001b[38;5;241m=\u001b[39m activation, padding \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msame\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape \u001b[38;5;241m=\u001b[39m (SIZE, SIZE, \u001b[38;5;241m3\u001b[39m)))\n\u001b[1;32m      7\u001b[0m feature_extractor\u001b[38;5;241m.\u001b[39madd(BatchNormalization())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data_augmentation' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dropout\n",
    "\n",
    "\n",
    "feature_extractor = Sequential()\n",
    "feature_extractor.add(data_augmentation)\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', input_shape = (SIZE, SIZE, 3)))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(32, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "\n",
    "feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "\n",
    "feature_extractor.add(Conv2D(64, 3, activation = activation, padding = 'same', kernel_initializer = 'he_uniform'))\n",
    "feature_extractor.add(BatchNormalization())\n",
    "feature_extractor.add(MaxPooling2D())\n",
    "feature_extractor.add(Dropout(0.1))\n",
    "feature_extractor.add(Flatten())\n",
    "\n",
    "\n",
    "x = feature_extractor.output  \n",
    "x = Dense(256, activation = activation, kernel_initializer = 'he_uniform')(x)\n",
    "prediction_layer = Dense(6, activation = 'softmax')(x)\n",
    "cnn_model = Model(inputs=feature_extractor.input, outputs=prediction_layer)\n",
    "cnn_model.compile(optimizer=\"rmsprop\",loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "print(cnn_model.summary()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interno = pd.read_csv('./df_interno.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interno.replace({\"CLASSE\":[6, 7]}, 5, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASSE</th>\n",
       "      <th>VIGOR</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>196598</th>\n",
       "      <th>196599</th>\n",
       "      <th>196600</th>\n",
       "      <th>196601</th>\n",
       "      <th>196602</th>\n",
       "      <th>196603</th>\n",
       "      <th>196604</th>\n",
       "      <th>196605</th>\n",
       "      <th>196606</th>\n",
       "      <th>196607</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.360784</td>\n",
       "      <td>0.407843</td>\n",
       "      <td>0.490196</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.509804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.313725</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.231373</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.250980</td>\n",
       "      <td>0.211765</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.301961</td>\n",
       "      <td>0.282353</td>\n",
       "      <td>0.317647</td>\n",
       "      <td>0.321569</td>\n",
       "      <td>0.286275</td>\n",
       "      <td>0.337255</td>\n",
       "      <td>0.305882</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329412</td>\n",
       "      <td>0.278431</td>\n",
       "      <td>0.341176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows Ã— 196610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     CLASSE  VIGOR         0         1         2         3         4  \\\n",
       "0         4      1  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "1         2      0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2         3      0  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "3         4      1  0.000000  0.000000  0.000000  0.321569  0.286275   \n",
       "4         4      1  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "..      ...    ...       ...       ...       ...       ...       ...   \n",
       "445       4      1  0.266667  0.231373  0.282353  0.250980  0.211765   \n",
       "446       4      1  0.301961  0.282353  0.317647  0.321569  0.286275   \n",
       "447       4      1  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "448       4      1  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "449       4      1  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "            5         6         7  ...    196598  196599  196600  196601  \\\n",
       "0    0.000000  0.000000  0.000000  ...  0.000000     0.0     0.0     0.0   \n",
       "1    0.000000  0.000000  0.000000  ...  0.360784     0.0     0.0     0.0   \n",
       "2    0.000000  0.000000  0.000000  ...  0.000000     0.0     0.0     0.0   \n",
       "3    0.333333  0.313725  0.282353  ...  0.000000     0.0     0.0     0.0   \n",
       "4    0.000000  0.000000  0.000000  ...  0.000000     0.0     0.0     0.0   \n",
       "..        ...       ...       ...  ...       ...     ...     ...     ...   \n",
       "445  0.262745  0.000000  0.000000  ...  0.000000     0.0     0.0     0.0   \n",
       "446  0.337255  0.305882  0.254902  ...  0.000000     0.0     0.0     0.0   \n",
       "447  0.000000  0.000000  0.000000  ...  0.000000     0.0     0.0     0.0   \n",
       "448  0.000000  0.000000  0.000000  ...  0.000000     0.0     0.0     0.0   \n",
       "449  0.000000  0.000000  0.000000  ...  0.000000     0.0     0.0     0.0   \n",
       "\n",
       "     196602    196603    196604    196605    196606    196607  \n",
       "0       0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "1       0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2       0.4  0.360784  0.407843  0.490196  0.466667  0.509804  \n",
       "3       0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "4       0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "..      ...       ...       ...       ...       ...       ...  \n",
       "445     0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "446     0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "447     0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "448     0.0  0.000000  0.000000  0.329412  0.278431  0.341176  \n",
       "449     0.0  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "\n",
       "[450 rows x 196610 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vigor = df_interno['VIGOR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = df_interno['CLASSE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 2, 3, 5, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classe.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interno.drop(['CLASSE', 'VIGOR'], axis = 1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 196608)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_interno.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interno = df_interno.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interno = np.reshape(df_interno, (450, 256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "classe = classe.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier  #Random Forest algorithm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_interno, classe, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_one_hot = to_categorical(y_train)\n",
    "y_test_one_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 6)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 6)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mcnn_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_one_hot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_one_hot\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      4\u001b[0m val_loss \u001b[38;5;241m=\u001b[39m history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:3618\u001b[0m, in \u001b[0;36mModel._assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3612\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_assert_compile_was_called\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m   3613\u001b[0m     \u001b[39m# Checks whether `compile` has been called. If it has been called,\u001b[39;00m\n\u001b[1;32m   3614\u001b[0m     \u001b[39m# then the optimizer is set. This is different from whether the\u001b[39;00m\n\u001b[1;32m   3615\u001b[0m     \u001b[39m# model is compiled\u001b[39;00m\n\u001b[1;32m   3616\u001b[0m     \u001b[39m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[39;00m\n\u001b[1;32m   3617\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_compiled:\n\u001b[0;32m-> 3618\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   3619\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou must compile your model before \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3620\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtraining/testing. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3621\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mUse `model.compile(optimizer, loss)`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   3622\u001b[0m         )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "\n",
    "history = cnn_model.fit(X_train, y_train_one_hot, epochs=1000, validation_data = (X_test, y_test_one_hot))\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 128, 128, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(337, 6)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113, 6)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "\n",
    "pretrained_model= tf.keras.applications.ResNet101(include_top=False,\n",
    "                   input_shape=(128,128,3),\n",
    "                   pooling='avg',classes=6,\n",
    "                   weights='imagenet')\n",
    "for layer in pretrained_model.layers:\n",
    "        layer.trainable=True\n",
    "\n",
    "resnet_model.add(pretrained_model)\n",
    "\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_model = Sequential()\n",
    "\n",
    "pretrained_model= tf.keras.applications.VGG16(include_top=False,\n",
    "                   input_shape=(128,128,3),\n",
    "                   pooling='avg',classes=6,\n",
    "                   weights='imagenet')\n",
    "for layer in pretrained_model.layers:\n",
    "        layer.trainable=True\n",
    "\n",
    "resnet_model.add(pretrained_model)\n",
    "\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(512, activation='relu'))\n",
    "resnet_model.add(Dense(6, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 40s 4s/step - loss: 10.6573 - accuracy: 0.5371 - val_loss: 1.1009 - val_accuracy: 0.6460\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 38s 3s/step - loss: 1.1552 - accuracy: 0.5875 - val_loss: 1.0629 - val_accuracy: 0.6460\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 39s 4s/step - loss: 1.1468 - accuracy: 0.5875 - val_loss: 1.0711 - val_accuracy: 0.6460\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 39s 4s/step - loss: 1.1427 - accuracy: 0.5875 - val_loss: 1.0810 - val_accuracy: 0.6460\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 39s 4s/step - loss: 1.1367 - accuracy: 0.5875 - val_loss: 1.2019 - val_accuracy: 0.6460\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 39s 3s/step - loss: 1.1608 - accuracy: 0.5875 - val_loss: 1.1383 - val_accuracy: 0.6460\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 39s 4s/step - loss: 1.1414 - accuracy: 0.5875 - val_loss: 1.1005 - val_accuracy: 0.6460\n",
      "Epoch 8/100\n",
      " 3/11 [=======>......................] - ETA: 28s - loss: 1.1973 - accuracy: 0.5625"
     ]
    }
   ],
   "source": [
    "resnet_model.compile(optimizer=\"rmsprop\",loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = resnet_model.fit(X_train, y_train_one_hot, validation_data=(X_test, y_test_one_hot), epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classificadores import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 256, 256, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 256, 256, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 128, 128, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 128, 128, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 128, 128, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 64, 64, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 64, 64, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 64, 64, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 32, 32, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 32, 32, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 32, 32, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 16, 16, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 16, 16, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 0\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 11:48:22.506471: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 536870912 exceeds 10% of free system memory.\n",
      "2022-10-23 11:48:22.689183: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 536870912 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/11 [=>............................] - ETA: 32s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 11:48:25.404195: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 536870912 exceeds 10% of free system memory.\n",
      "2022-10-23 11:48:25.499239: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 536870912 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2/11 [====>.........................] - ETA: 25s"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-23 11:48:28.286823: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 536870912 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 31s 3s/step\n",
      "4/4 [==============================] - 10s 2s/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn import naive_bayes, svm\n",
    "\n",
    "\n",
    "VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))\n",
    "#Make loaded layers as non-trainable. This is important as we want to work with pre-trained weights\n",
    "for layer in VGG_model.layers:\n",
    "\tlayer.trainable = False\n",
    "    \n",
    "VGG_model.summary()  #Trainable parameters will be 0\n",
    "\n",
    "#Now, let us use features from convolutional network for RF\n",
    "feature_extractor=VGG_model.predict(X_train)\n",
    "\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "\n",
    "X_for_RF = features #This is our X input to RF\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 250, max_depth=10, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature = VGG_model.predict(X_test)\n",
    "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
    "\n",
    "#Now predict using the trained RF model. \n",
    "prediction_RF = RF_model.predict(X_test_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Default metric period is 5 because AUC is/are not implemented for GPU\n",
      "AUC is not implemented on GPU. Will use CPU for metric computation, this could significantly affect learning time\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.6086016\ttest: 1.6086412\tbest: 1.6086412 (0)\ttotal: 134ms\tremaining: 11m 11s\n",
      "1:\ttotal: 274ms\tremaining: 11m 24s\n",
      "2:\ttotal: 389ms\tremaining: 10m 47s\n",
      "3:\ttotal: 509ms\tremaining: 10m 35s\n",
      "4:\ttotal: 630ms\tremaining: 10m 29s\n",
      "5:\tlearn: 1.6046494\ttest: 1.6057186\tbest: 1.6057186 (5)\ttotal: 757ms\tremaining: 10m 30s\n",
      "6:\ttotal: 871ms\tremaining: 10m 21s\n",
      "7:\ttotal: 1.01s\tremaining: 10m 29s\n",
      "8:\ttotal: 1.12s\tremaining: 10m 19s\n",
      "9:\ttotal: 1.23s\tremaining: 10m 12s\n",
      "10:\tlearn: 1.6005396\ttest: 1.6021639\tbest: 1.6021639 (10)\ttotal: 1.35s\tremaining: 10m 14s\n",
      "11:\ttotal: 1.48s\tremaining: 10m 17s\n",
      "12:\ttotal: 1.62s\tremaining: 10m 21s\n",
      "13:\ttotal: 1.75s\tremaining: 10m 22s\n",
      "14:\ttotal: 1.87s\tremaining: 10m 23s\n",
      "15:\tlearn: 1.5965207\ttest: 1.5989212\tbest: 1.5989212 (15)\ttotal: 1.99s\tremaining: 10m 20s\n",
      "16:\ttotal: 2.09s\tremaining: 10m 13s\n",
      "17:\ttotal: 2.22s\tremaining: 10m 15s\n",
      "18:\ttotal: 2.35s\tremaining: 10m 16s\n",
      "19:\ttotal: 2.48s\tremaining: 10m 16s\n",
      "20:\tlearn: 1.5925405\ttest: 1.5958519\tbest: 1.5958519 (20)\ttotal: 2.61s\tremaining: 10m 19s\n",
      "21:\ttotal: 2.7s\tremaining: 10m 10s\n",
      "22:\ttotal: 2.81s\tremaining: 10m 8s\n",
      "23:\ttotal: 2.94s\tremaining: 10m 10s\n",
      "24:\ttotal: 3.07s\tremaining: 10m 10s\n",
      "25:\tlearn: 1.5886209\ttest: 1.5926977\tbest: 1.5926977 (25)\ttotal: 3.2s\tremaining: 10m 11s\n",
      "26:\ttotal: 3.31s\tremaining: 10m 10s\n",
      "27:\ttotal: 3.44s\tremaining: 10m 10s\n",
      "28:\ttotal: 3.57s\tremaining: 10m 11s\n",
      "29:\ttotal: 3.7s\tremaining: 10m 13s\n",
      "30:\tlearn: 1.5845034\ttest: 1.5895445\tbest: 1.5895445 (30)\ttotal: 3.83s\tremaining: 10m 14s\n",
      "31:\ttotal: 3.94s\tremaining: 10m 11s\n",
      "32:\ttotal: 4.07s\tremaining: 10m 12s\n",
      "33:\ttotal: 4.21s\tremaining: 10m 14s\n",
      "34:\ttotal: 4.3s\tremaining: 10m 10s\n",
      "35:\tlearn: 1.5802074\ttest: 1.5860690\tbest: 1.5860690 (35)\ttotal: 4.43s\tremaining: 10m 11s\n",
      "36:\ttotal: 4.53s\tremaining: 10m 8s\n",
      "37:\ttotal: 4.66s\tremaining: 10m 8s\n",
      "38:\ttotal: 4.79s\tremaining: 10m 8s\n",
      "39:\ttotal: 4.9s\tremaining: 10m 7s\n",
      "40:\tlearn: 1.5761204\ttest: 1.5824412\tbest: 1.5824412 (40)\ttotal: 5.01s\tremaining: 10m 5s\n",
      "41:\ttotal: 5.13s\tremaining: 10m 5s\n",
      "42:\ttotal: 5.25s\tremaining: 10m 5s\n",
      "43:\ttotal: 5.39s\tremaining: 10m 6s\n",
      "44:\ttotal: 5.51s\tremaining: 10m 6s\n",
      "45:\tlearn: 1.5720528\ttest: 1.5792466\tbest: 1.5792466 (45)\ttotal: 5.63s\tremaining: 10m 6s\n",
      "46:\ttotal: 5.75s\tremaining: 10m 6s\n",
      "47:\ttotal: 5.89s\tremaining: 10m 7s\n",
      "48:\ttotal: 6.01s\tremaining: 10m 7s\n",
      "49:\ttotal: 6.14s\tremaining: 10m 8s\n",
      "50:\tlearn: 1.5683885\ttest: 1.5765721\tbest: 1.5765721 (50)\ttotal: 6.28s\tremaining: 10m 9s\n",
      "51:\ttotal: 6.39s\tremaining: 10m 8s\n",
      "52:\ttotal: 6.51s\tremaining: 10m 7s\n",
      "53:\ttotal: 6.63s\tremaining: 10m 6s\n",
      "54:\ttotal: 6.75s\tremaining: 10m 6s\n",
      "55:\tlearn: 1.5643436\ttest: 1.5733456\tbest: 1.5733456 (55)\ttotal: 6.88s\tremaining: 10m 7s\n",
      "56:\ttotal: 7s\tremaining: 10m 6s\n",
      "57:\ttotal: 7.13s\tremaining: 10m 7s\n",
      "58:\ttotal: 7.25s\tremaining: 10m 7s\n",
      "59:\ttotal: 7.39s\tremaining: 10m 8s\n",
      "60:\tlearn: 1.5603198\ttest: 1.5702608\tbest: 1.5702608 (60)\ttotal: 7.51s\tremaining: 10m 8s\n",
      "61:\ttotal: 7.62s\tremaining: 10m 6s\n",
      "62:\ttotal: 7.76s\tremaining: 10m 7s\n",
      "63:\ttotal: 7.86s\tremaining: 10m 6s\n",
      "64:\ttotal: 7.97s\tremaining: 10m 5s\n",
      "65:\tlearn: 1.5563574\ttest: 1.5670844\tbest: 1.5670844 (65)\ttotal: 8.09s\tremaining: 10m 4s\n",
      "66:\ttotal: 8.21s\tremaining: 10m 4s\n",
      "67:\ttotal: 8.32s\tremaining: 10m 3s\n",
      "68:\ttotal: 8.45s\tremaining: 10m 3s\n",
      "69:\ttotal: 8.57s\tremaining: 10m 3s\n",
      "70:\tlearn: 1.5523419\ttest: 1.5640451\tbest: 1.5640451 (70)\ttotal: 8.7s\tremaining: 10m 3s\n",
      "71:\ttotal: 8.82s\tremaining: 10m 3s\n",
      "72:\ttotal: 8.95s\tremaining: 10m 4s\n",
      "73:\ttotal: 9.06s\tremaining: 10m 3s\n",
      "74:\ttotal: 9.18s\tremaining: 10m 3s\n",
      "75:\tlearn: 1.5488071\ttest: 1.5612670\tbest: 1.5612670 (75)\ttotal: 9.32s\tremaining: 10m 3s\n",
      "76:\ttotal: 9.43s\tremaining: 10m 3s\n",
      "77:\ttotal: 9.57s\tremaining: 10m 3s\n",
      "78:\ttotal: 9.69s\tremaining: 10m 3s\n",
      "79:\ttotal: 9.82s\tremaining: 10m 3s\n",
      "80:\tlearn: 1.5452711\ttest: 1.5589567\tbest: 1.5589567 (80)\ttotal: 9.96s\tremaining: 10m 4s\n",
      "81:\ttotal: 10.1s\tremaining: 10m 5s\n",
      "82:\ttotal: 10.2s\tremaining: 10m 4s\n",
      "83:\ttotal: 10.3s\tremaining: 10m 4s\n",
      "84:\ttotal: 10.5s\tremaining: 10m 4s\n",
      "85:\tlearn: 1.5416166\ttest: 1.5563088\tbest: 1.5563088 (85)\ttotal: 10.6s\tremaining: 10m 4s\n",
      "86:\ttotal: 10.7s\tremaining: 10m 4s\n",
      "87:\ttotal: 10.8s\tremaining: 10m 4s\n",
      "88:\ttotal: 10.9s\tremaining: 10m 3s\n",
      "89:\ttotal: 11s\tremaining: 10m 2s\n",
      "90:\tlearn: 1.5377454\ttest: 1.5533863\tbest: 1.5533863 (90)\ttotal: 11.2s\tremaining: 10m 2s\n",
      "91:\ttotal: 11.3s\tremaining: 10m 2s\n",
      "92:\ttotal: 11.4s\tremaining: 10m 2s\n",
      "93:\ttotal: 11.6s\tremaining: 10m 3s\n",
      "94:\ttotal: 11.7s\tremaining: 10m 3s\n",
      "95:\tlearn: 1.5342181\ttest: 1.5505439\tbest: 1.5505439 (95)\ttotal: 11.8s\tremaining: 10m 3s\n",
      "96:\ttotal: 11.9s\tremaining: 10m 2s\n",
      "97:\ttotal: 12s\tremaining: 10m 2s\n",
      "98:\ttotal: 12.2s\tremaining: 10m 1s\n",
      "99:\ttotal: 12.3s\tremaining: 10m 1s\n",
      "100:\tlearn: 1.5302944\ttest: 1.5476618\tbest: 1.5476618 (100)\ttotal: 12.4s\tremaining: 10m 1s\n",
      "101:\ttotal: 12.5s\tremaining: 10m\n",
      "102:\ttotal: 12.6s\tremaining: 10m 1s\n",
      "103:\ttotal: 12.8s\tremaining: 10m\n",
      "104:\ttotal: 12.9s\tremaining: 10m\n",
      "105:\tlearn: 1.5263733\ttest: 1.5447249\tbest: 1.5447249 (105)\ttotal: 13s\tremaining: 10m\n",
      "106:\ttotal: 13.1s\tremaining: 10m\n",
      "107:\ttotal: 13.3s\tremaining: 10m\n",
      "108:\ttotal: 13.4s\tremaining: 10m\n",
      "109:\ttotal: 13.5s\tremaining: 9m 59s\n",
      "110:\tlearn: 1.5226777\ttest: 1.5417173\tbest: 1.5417173 (110)\ttotal: 13.6s\tremaining: 9m 59s\n",
      "111:\ttotal: 13.7s\tremaining: 9m 59s\n",
      "112:\ttotal: 13.9s\tremaining: 9m 59s\n",
      "113:\ttotal: 14s\tremaining: 9m 59s\n",
      "114:\ttotal: 14.1s\tremaining: 9m 59s\n",
      "115:\tlearn: 1.5191282\ttest: 1.5392683\tbest: 1.5392683 (115)\ttotal: 14.2s\tremaining: 9m 58s\n",
      "116:\ttotal: 14.3s\tremaining: 9m 58s\n",
      "117:\ttotal: 14.5s\tremaining: 9m 58s\n",
      "118:\ttotal: 14.6s\tremaining: 9m 58s\n",
      "119:\ttotal: 14.7s\tremaining: 9m 57s\n",
      "120:\tlearn: 1.5155863\ttest: 1.5365071\tbest: 1.5365071 (120)\ttotal: 14.8s\tremaining: 9m 57s\n",
      "121:\ttotal: 14.9s\tremaining: 9m 56s\n",
      "122:\ttotal: 15.1s\tremaining: 9m 57s\n",
      "123:\ttotal: 15.2s\tremaining: 9m 56s\n",
      "124:\ttotal: 15.3s\tremaining: 9m 56s\n",
      "125:\tlearn: 1.5120917\ttest: 1.5340175\tbest: 1.5340175 (125)\ttotal: 15.4s\tremaining: 9m 57s\n",
      "126:\ttotal: 15.6s\tremaining: 9m 57s\n",
      "127:\ttotal: 15.7s\tremaining: 9m 56s\n",
      "128:\ttotal: 15.8s\tremaining: 9m 56s\n",
      "129:\ttotal: 15.9s\tremaining: 9m 55s\n",
      "130:\tlearn: 1.5085786\ttest: 1.5313677\tbest: 1.5313677 (130)\ttotal: 16s\tremaining: 9m 55s\n",
      "131:\ttotal: 16.1s\tremaining: 9m 55s\n",
      "132:\ttotal: 16.3s\tremaining: 9m 54s\n",
      "133:\ttotal: 16.4s\tremaining: 9m 54s\n",
      "134:\ttotal: 16.5s\tremaining: 9m 54s\n",
      "135:\tlearn: 1.5048607\ttest: 1.5284019\tbest: 1.5284019 (135)\ttotal: 16.6s\tremaining: 9m 54s\n",
      "136:\ttotal: 16.7s\tremaining: 9m 53s\n",
      "137:\ttotal: 16.9s\tremaining: 9m 54s\n",
      "138:\ttotal: 17s\tremaining: 9m 54s\n",
      "139:\ttotal: 17.1s\tremaining: 9m 54s\n",
      "140:\tlearn: 1.5014304\ttest: 1.5257587\tbest: 1.5257587 (140)\ttotal: 17.3s\tremaining: 9m 54s\n",
      "141:\ttotal: 17.4s\tremaining: 9m 54s\n",
      "142:\ttotal: 17.5s\tremaining: 9m 53s\n",
      "143:\ttotal: 17.6s\tremaining: 9m 53s\n",
      "144:\ttotal: 17.7s\tremaining: 9m 53s\n",
      "145:\tlearn: 1.4978163\ttest: 1.5230755\tbest: 1.5230755 (145)\ttotal: 17.8s\tremaining: 9m 52s\n",
      "146:\ttotal: 18s\tremaining: 9m 53s\n",
      "147:\ttotal: 18.1s\tremaining: 9m 53s\n",
      "148:\ttotal: 18.2s\tremaining: 9m 53s\n",
      "149:\ttotal: 18.3s\tremaining: 9m 52s\n",
      "150:\tlearn: 1.4944103\ttest: 1.5204606\tbest: 1.5204606 (150)\ttotal: 18.5s\tremaining: 9m 52s\n",
      "151:\ttotal: 18.6s\tremaining: 9m 51s\n",
      "152:\ttotal: 18.7s\tremaining: 9m 51s\n",
      "153:\ttotal: 18.8s\tremaining: 9m 51s\n",
      "154:\ttotal: 18.9s\tremaining: 9m 52s\n",
      "155:\tlearn: 1.4910219\ttest: 1.5178166\tbest: 1.5178166 (155)\ttotal: 19.1s\tremaining: 9m 51s\n",
      "156:\ttotal: 19.2s\tremaining: 9m 52s\n",
      "157:\ttotal: 19.3s\tremaining: 9m 51s\n",
      "158:\ttotal: 19.4s\tremaining: 9m 51s\n",
      "159:\ttotal: 19.6s\tremaining: 9m 51s\n",
      "160:\tlearn: 1.4877053\ttest: 1.5153522\tbest: 1.5153522 (160)\ttotal: 19.7s\tremaining: 9m 51s\n",
      "161:\ttotal: 19.8s\tremaining: 9m 51s\n",
      "162:\ttotal: 19.9s\tremaining: 9m 51s\n",
      "163:\ttotal: 20s\tremaining: 9m 51s\n",
      "164:\ttotal: 20.2s\tremaining: 9m 51s\n",
      "165:\tlearn: 1.4842973\ttest: 1.5128848\tbest: 1.5128848 (165)\ttotal: 20.3s\tremaining: 9m 51s\n",
      "166:\ttotal: 20.4s\tremaining: 9m 51s\n",
      "167:\ttotal: 20.6s\tremaining: 9m 51s\n",
      "168:\ttotal: 20.7s\tremaining: 9m 50s\n",
      "169:\ttotal: 20.8s\tremaining: 9m 50s\n",
      "170:\tlearn: 1.4807625\ttest: 1.5105018\tbest: 1.5105018 (170)\ttotal: 20.9s\tremaining: 9m 50s\n",
      "171:\ttotal: 21s\tremaining: 9m 50s\n",
      "172:\ttotal: 21.1s\tremaining: 9m 50s\n",
      "173:\ttotal: 21.3s\tremaining: 9m 50s\n",
      "174:\ttotal: 21.4s\tremaining: 9m 50s\n",
      "175:\tlearn: 1.4776762\ttest: 1.5084734\tbest: 1.5084734 (175)\ttotal: 21.5s\tremaining: 9m 50s\n",
      "176:\ttotal: 21.7s\tremaining: 9m 50s\n",
      "177:\ttotal: 21.8s\tremaining: 9m 50s\n",
      "178:\ttotal: 21.9s\tremaining: 9m 50s\n",
      "179:\ttotal: 22s\tremaining: 9m 49s\n",
      "180:\tlearn: 1.4742385\ttest: 1.5058402\tbest: 1.5058402 (180)\ttotal: 22.1s\tremaining: 9m 49s\n",
      "181:\ttotal: 22.3s\tremaining: 9m 49s\n",
      "182:\ttotal: 22.4s\tremaining: 9m 49s\n",
      "183:\ttotal: 22.5s\tremaining: 9m 49s\n",
      "184:\ttotal: 22.7s\tremaining: 9m 49s\n",
      "185:\tlearn: 1.4709132\ttest: 1.5032711\tbest: 1.5032711 (185)\ttotal: 22.8s\tremaining: 9m 49s\n",
      "186:\ttotal: 22.9s\tremaining: 9m 49s\n",
      "187:\ttotal: 23s\tremaining: 9m 49s\n",
      "188:\ttotal: 23.1s\tremaining: 9m 48s\n",
      "189:\ttotal: 23.2s\tremaining: 9m 47s\n",
      "190:\tlearn: 1.4671062\ttest: 1.5000008\tbest: 1.5000008 (190)\ttotal: 23.3s\tremaining: 9m 47s\n",
      "191:\ttotal: 23.5s\tremaining: 9m 47s\n",
      "192:\ttotal: 23.6s\tremaining: 9m 47s\n",
      "193:\ttotal: 23.7s\tremaining: 9m 47s\n",
      "194:\ttotal: 23.8s\tremaining: 9m 46s\n",
      "195:\tlearn: 1.4637659\ttest: 1.4974565\tbest: 1.4974565 (195)\ttotal: 23.9s\tremaining: 9m 46s\n",
      "196:\ttotal: 24.1s\tremaining: 9m 46s\n",
      "197:\ttotal: 24.2s\tremaining: 9m 46s\n",
      "198:\ttotal: 24.3s\tremaining: 9m 46s\n",
      "199:\ttotal: 24.4s\tremaining: 9m 46s\n",
      "200:\tlearn: 1.4606698\ttest: 1.4952268\tbest: 1.4952268 (200)\ttotal: 24.6s\tremaining: 9m 46s\n",
      "201:\ttotal: 24.7s\tremaining: 9m 46s\n",
      "202:\ttotal: 24.8s\tremaining: 9m 45s\n",
      "203:\ttotal: 24.9s\tremaining: 9m 45s\n",
      "204:\ttotal: 25s\tremaining: 9m 45s\n",
      "205:\tlearn: 1.4573734\ttest: 1.4927631\tbest: 1.4927631 (205)\ttotal: 25.1s\tremaining: 9m 45s\n",
      "206:\ttotal: 25.3s\tremaining: 9m 45s\n",
      "207:\ttotal: 25.4s\tremaining: 9m 45s\n",
      "208:\ttotal: 25.5s\tremaining: 9m 44s\n",
      "209:\ttotal: 25.6s\tremaining: 9m 44s\n",
      "210:\tlearn: 1.4540545\ttest: 1.4903856\tbest: 1.4903856 (210)\ttotal: 25.7s\tremaining: 9m 43s\n",
      "211:\ttotal: 25.8s\tremaining: 9m 43s\n",
      "212:\ttotal: 26s\tremaining: 9m 43s\n",
      "213:\ttotal: 26.1s\tremaining: 9m 42s\n",
      "214:\ttotal: 26.2s\tremaining: 9m 42s\n",
      "215:\tlearn: 1.4506896\ttest: 1.4877982\tbest: 1.4877982 (215)\ttotal: 26.3s\tremaining: 9m 42s\n",
      "216:\ttotal: 26.4s\tremaining: 9m 42s\n",
      "217:\ttotal: 26.5s\tremaining: 9m 42s\n",
      "218:\ttotal: 26.7s\tremaining: 9m 42s\n",
      "219:\ttotal: 26.8s\tremaining: 9m 41s\n",
      "220:\tlearn: 1.4474515\ttest: 1.4855075\tbest: 1.4855075 (220)\ttotal: 26.9s\tremaining: 9m 41s\n",
      "221:\ttotal: 27s\tremaining: 9m 41s\n",
      "222:\ttotal: 27.1s\tremaining: 9m 41s\n",
      "223:\ttotal: 27.3s\tremaining: 9m 41s\n",
      "224:\ttotal: 27.4s\tremaining: 9m 41s\n",
      "225:\tlearn: 1.4440766\ttest: 1.4828914\tbest: 1.4828914 (225)\ttotal: 27.5s\tremaining: 9m 40s\n",
      "226:\ttotal: 27.6s\tremaining: 9m 40s\n",
      "227:\ttotal: 27.7s\tremaining: 9m 40s\n",
      "228:\ttotal: 27.9s\tremaining: 9m 40s\n",
      "229:\ttotal: 28s\tremaining: 9m 40s\n",
      "230:\tlearn: 1.4411763\ttest: 1.4807793\tbest: 1.4807793 (230)\ttotal: 28.1s\tremaining: 9m 40s\n",
      "231:\ttotal: 28.2s\tremaining: 9m 40s\n",
      "232:\ttotal: 28.4s\tremaining: 9m 40s\n",
      "233:\ttotal: 28.5s\tremaining: 9m 40s\n",
      "234:\ttotal: 28.6s\tremaining: 9m 40s\n",
      "235:\tlearn: 1.4381522\ttest: 1.4785804\tbest: 1.4785804 (235)\ttotal: 28.7s\tremaining: 9m 39s\n",
      "236:\ttotal: 28.9s\tremaining: 9m 39s\n",
      "237:\ttotal: 29s\tremaining: 9m 39s\n",
      "238:\ttotal: 29.1s\tremaining: 9m 39s\n",
      "239:\ttotal: 29.2s\tremaining: 9m 39s\n",
      "240:\tlearn: 1.4348309\ttest: 1.4759979\tbest: 1.4759979 (240)\ttotal: 29.3s\tremaining: 9m 39s\n",
      "241:\ttotal: 29.5s\tremaining: 9m 39s\n",
      "242:\ttotal: 29.6s\tremaining: 9m 38s\n",
      "243:\ttotal: 29.7s\tremaining: 9m 38s\n",
      "244:\ttotal: 29.8s\tremaining: 9m 38s\n",
      "245:\tlearn: 1.4315329\ttest: 1.4734851\tbest: 1.4734851 (245)\ttotal: 29.9s\tremaining: 9m 38s\n",
      "246:\ttotal: 30.1s\tremaining: 9m 38s\n",
      "247:\ttotal: 30.2s\tremaining: 9m 38s\n",
      "248:\ttotal: 30.3s\tremaining: 9m 38s\n",
      "249:\ttotal: 30.5s\tremaining: 9m 38s\n",
      "250:\tlearn: 1.4284197\ttest: 1.4712967\tbest: 1.4712967 (250)\ttotal: 30.6s\tremaining: 9m 38s\n",
      "251:\ttotal: 30.7s\tremaining: 9m 38s\n",
      "252:\ttotal: 30.8s\tremaining: 9m 38s\n",
      "253:\ttotal: 30.9s\tremaining: 9m 37s\n",
      "254:\ttotal: 31.1s\tremaining: 9m 37s\n",
      "255:\tlearn: 1.4255076\ttest: 1.4691737\tbest: 1.4691737 (255)\ttotal: 31.2s\tremaining: 9m 37s\n",
      "256:\ttotal: 31.3s\tremaining: 9m 37s\n",
      "257:\ttotal: 31.4s\tremaining: 9m 37s\n",
      "258:\ttotal: 31.5s\tremaining: 9m 36s\n",
      "259:\ttotal: 31.6s\tremaining: 9m 36s\n",
      "260:\tlearn: 1.4224106\ttest: 1.4666327\tbest: 1.4666327 (260)\ttotal: 31.7s\tremaining: 9m 36s\n",
      "261:\ttotal: 31.8s\tremaining: 9m 35s\n",
      "262:\ttotal: 32s\tremaining: 9m 35s\n",
      "263:\ttotal: 32.1s\tremaining: 9m 35s\n",
      "264:\ttotal: 32.2s\tremaining: 9m 35s\n",
      "265:\tlearn: 1.4190882\ttest: 1.4642990\tbest: 1.4642990 (265)\ttotal: 32.3s\tremaining: 9m 35s\n",
      "266:\ttotal: 32.5s\tremaining: 9m 35s\n",
      "267:\ttotal: 32.6s\tremaining: 9m 34s\n",
      "268:\ttotal: 32.7s\tremaining: 9m 34s\n",
      "269:\ttotal: 32.8s\tremaining: 9m 34s\n",
      "270:\tlearn: 1.4159314\ttest: 1.4616659\tbest: 1.4616659 (270)\ttotal: 32.9s\tremaining: 9m 34s\n",
      "271:\ttotal: 33s\tremaining: 9m 33s\n",
      "272:\ttotal: 33.1s\tremaining: 9m 33s\n",
      "273:\ttotal: 33.2s\tremaining: 9m 33s\n",
      "274:\ttotal: 33.4s\tremaining: 9m 33s\n",
      "275:\tlearn: 1.4126409\ttest: 1.4591748\tbest: 1.4591748 (275)\ttotal: 33.5s\tremaining: 9m 32s\n",
      "276:\ttotal: 33.6s\tremaining: 9m 32s\n",
      "277:\ttotal: 33.7s\tremaining: 9m 32s\n",
      "278:\ttotal: 33.9s\tremaining: 9m 33s\n",
      "279:\ttotal: 34s\tremaining: 9m 32s\n",
      "280:\tlearn: 1.4095892\ttest: 1.4568958\tbest: 1.4568958 (280)\ttotal: 34.1s\tremaining: 9m 32s\n",
      "281:\ttotal: 34.2s\tremaining: 9m 32s\n",
      "282:\ttotal: 34.3s\tremaining: 9m 32s\n",
      "283:\ttotal: 34.4s\tremaining: 9m 31s\n",
      "284:\ttotal: 34.5s\tremaining: 9m 31s\n",
      "285:\tlearn: 1.4062996\ttest: 1.4542910\tbest: 1.4542910 (285)\ttotal: 34.7s\tremaining: 9m 31s\n",
      "286:\ttotal: 34.8s\tremaining: 9m 31s\n",
      "287:\ttotal: 34.9s\tremaining: 9m 30s\n",
      "288:\ttotal: 35s\tremaining: 9m 30s\n",
      "289:\ttotal: 35.1s\tremaining: 9m 30s\n",
      "290:\tlearn: 1.4029693\ttest: 1.4517730\tbest: 1.4517730 (290)\ttotal: 35.2s\tremaining: 9m 29s\n",
      "291:\ttotal: 35.3s\tremaining: 9m 29s\n",
      "292:\ttotal: 35.5s\tremaining: 9m 29s\n",
      "293:\ttotal: 35.6s\tremaining: 9m 29s\n",
      "294:\ttotal: 35.7s\tremaining: 9m 28s\n",
      "295:\tlearn: 1.3996428\ttest: 1.4490762\tbest: 1.4490762 (295)\ttotal: 35.8s\tremaining: 9m 28s\n",
      "296:\ttotal: 35.9s\tremaining: 9m 28s\n",
      "297:\ttotal: 36s\tremaining: 9m 28s\n",
      "298:\ttotal: 36.2s\tremaining: 9m 28s\n",
      "299:\ttotal: 36.3s\tremaining: 9m 28s\n",
      "300:\tlearn: 1.3968269\ttest: 1.4471727\tbest: 1.4471727 (300)\ttotal: 36.4s\tremaining: 9m 28s\n",
      "301:\ttotal: 36.6s\tremaining: 9m 28s\n",
      "302:\ttotal: 36.7s\tremaining: 9m 28s\n",
      "303:\ttotal: 36.8s\tremaining: 9m 28s\n",
      "304:\ttotal: 36.9s\tremaining: 9m 28s\n",
      "305:\tlearn: 1.3938780\ttest: 1.4448566\tbest: 1.4448566 (305)\ttotal: 37s\tremaining: 9m 28s\n",
      "306:\ttotal: 37.2s\tremaining: 9m 28s\n",
      "307:\ttotal: 37.3s\tremaining: 9m 28s\n",
      "308:\ttotal: 37.4s\tremaining: 9m 28s\n",
      "309:\ttotal: 37.5s\tremaining: 9m 27s\n",
      "310:\tlearn: 1.3908567\ttest: 1.4424183\tbest: 1.4424183 (310)\ttotal: 37.6s\tremaining: 9m 27s\n",
      "311:\ttotal: 37.8s\tremaining: 9m 27s\n",
      "312:\ttotal: 37.9s\tremaining: 9m 27s\n",
      "313:\ttotal: 38s\tremaining: 9m 26s\n",
      "314:\ttotal: 38.1s\tremaining: 9m 26s\n",
      "315:\tlearn: 1.3878950\ttest: 1.4399980\tbest: 1.4399980 (315)\ttotal: 38.2s\tremaining: 9m 26s\n",
      "316:\ttotal: 38.4s\tremaining: 9m 26s\n",
      "317:\ttotal: 38.5s\tremaining: 9m 26s\n",
      "318:\ttotal: 38.6s\tremaining: 9m 26s\n",
      "319:\ttotal: 38.7s\tremaining: 9m 25s\n",
      "320:\tlearn: 1.3847107\ttest: 1.4374310\tbest: 1.4374310 (320)\ttotal: 38.8s\tremaining: 9m 25s\n",
      "321:\ttotal: 38.9s\tremaining: 9m 25s\n",
      "322:\ttotal: 39s\tremaining: 9m 25s\n",
      "323:\ttotal: 39.2s\tremaining: 9m 25s\n",
      "324:\ttotal: 39.3s\tremaining: 9m 25s\n",
      "325:\tlearn: 1.3819951\ttest: 1.4355504\tbest: 1.4355504 (325)\ttotal: 39.4s\tremaining: 9m 24s\n",
      "326:\ttotal: 39.5s\tremaining: 9m 25s\n",
      "327:\ttotal: 39.6s\tremaining: 9m 24s\n",
      "328:\ttotal: 39.7s\tremaining: 9m 24s\n",
      "329:\ttotal: 39.9s\tremaining: 9m 24s\n",
      "330:\tlearn: 1.3791573\ttest: 1.4332856\tbest: 1.4332856 (330)\ttotal: 40s\tremaining: 9m 24s\n",
      "331:\ttotal: 40.1s\tremaining: 9m 24s\n",
      "332:\ttotal: 40.2s\tremaining: 9m 23s\n",
      "333:\ttotal: 40.4s\tremaining: 9m 23s\n",
      "334:\ttotal: 40.5s\tremaining: 9m 23s\n",
      "335:\tlearn: 1.3763655\ttest: 1.4312492\tbest: 1.4312492 (335)\ttotal: 40.6s\tremaining: 9m 23s\n",
      "336:\ttotal: 40.7s\tremaining: 9m 23s\n",
      "337:\ttotal: 40.8s\tremaining: 9m 23s\n",
      "338:\ttotal: 40.9s\tremaining: 9m 22s\n",
      "339:\ttotal: 41.1s\tremaining: 9m 22s\n",
      "340:\tlearn: 1.3733375\ttest: 1.4288857\tbest: 1.4288857 (340)\ttotal: 41.2s\tremaining: 9m 22s\n",
      "341:\ttotal: 41.3s\tremaining: 9m 22s\n",
      "342:\ttotal: 41.4s\tremaining: 9m 22s\n",
      "343:\ttotal: 41.5s\tremaining: 9m 21s\n",
      "344:\ttotal: 41.6s\tremaining: 9m 21s\n",
      "345:\tlearn: 1.3704618\ttest: 1.4268588\tbest: 1.4268588 (345)\ttotal: 41.8s\tremaining: 9m 21s\n",
      "346:\ttotal: 41.9s\tremaining: 9m 21s\n",
      "347:\ttotal: 42s\tremaining: 9m 21s\n",
      "348:\ttotal: 42.1s\tremaining: 9m 21s\n",
      "349:\ttotal: 42.2s\tremaining: 9m 21s\n",
      "350:\tlearn: 1.3677146\ttest: 1.4250367\tbest: 1.4250367 (350)\ttotal: 42.4s\tremaining: 9m 21s\n",
      "351:\ttotal: 42.5s\tremaining: 9m 20s\n",
      "352:\ttotal: 42.6s\tremaining: 9m 20s\n",
      "353:\ttotal: 42.7s\tremaining: 9m 20s\n",
      "354:\ttotal: 42.8s\tremaining: 9m 20s\n",
      "355:\tlearn: 1.3648961\ttest: 1.4229547\tbest: 1.4229547 (355)\ttotal: 43s\tremaining: 9m 20s\n",
      "356:\ttotal: 43.1s\tremaining: 9m 20s\n",
      "357:\ttotal: 43.2s\tremaining: 9m 19s\n",
      "358:\ttotal: 43.3s\tremaining: 9m 19s\n",
      "359:\ttotal: 43.4s\tremaining: 9m 19s\n",
      "360:\tlearn: 1.3618371\ttest: 1.4204766\tbest: 1.4204766 (360)\ttotal: 43.5s\tremaining: 9m 19s\n",
      "361:\ttotal: 43.6s\tremaining: 9m 19s\n",
      "362:\ttotal: 43.8s\tremaining: 9m 19s\n",
      "363:\ttotal: 43.9s\tremaining: 9m 18s\n",
      "364:\ttotal: 44s\tremaining: 9m 18s\n",
      "365:\tlearn: 1.3590847\ttest: 1.4186617\tbest: 1.4186617 (365)\ttotal: 44.1s\tremaining: 9m 18s\n",
      "366:\ttotal: 44.2s\tremaining: 9m 18s\n",
      "367:\ttotal: 44.3s\tremaining: 9m 18s\n",
      "368:\ttotal: 44.5s\tremaining: 9m 18s\n",
      "369:\ttotal: 44.6s\tremaining: 9m 18s\n",
      "370:\tlearn: 1.3564772\ttest: 1.4169114\tbest: 1.4169114 (370)\ttotal: 44.7s\tremaining: 9m 18s\n",
      "371:\ttotal: 44.8s\tremaining: 9m 17s\n",
      "372:\ttotal: 44.9s\tremaining: 9m 17s\n",
      "373:\ttotal: 45.1s\tremaining: 9m 17s\n",
      "374:\ttotal: 45.2s\tremaining: 9m 17s\n",
      "375:\tlearn: 1.3536681\ttest: 1.4149038\tbest: 1.4149038 (375)\ttotal: 45.3s\tremaining: 9m 17s\n",
      "376:\ttotal: 45.4s\tremaining: 9m 17s\n",
      "377:\ttotal: 45.5s\tremaining: 9m 16s\n",
      "378:\ttotal: 45.7s\tremaining: 9m 16s\n",
      "379:\ttotal: 45.8s\tremaining: 9m 16s\n",
      "380:\tlearn: 1.3509615\ttest: 1.4129501\tbest: 1.4129501 (380)\ttotal: 45.9s\tremaining: 9m 16s\n",
      "381:\ttotal: 46s\tremaining: 9m 16s\n",
      "382:\ttotal: 46.1s\tremaining: 9m 16s\n",
      "383:\ttotal: 46.2s\tremaining: 9m 15s\n",
      "384:\ttotal: 46.4s\tremaining: 9m 15s\n",
      "385:\tlearn: 1.3478809\ttest: 1.4107064\tbest: 1.4107064 (385)\ttotal: 46.5s\tremaining: 9m 15s\n",
      "386:\ttotal: 46.6s\tremaining: 9m 15s\n",
      "387:\ttotal: 46.7s\tremaining: 9m 15s\n",
      "388:\ttotal: 46.8s\tremaining: 9m 15s\n",
      "389:\ttotal: 47s\tremaining: 9m 15s\n",
      "390:\tlearn: 1.3452098\ttest: 1.4089071\tbest: 1.4089071 (390)\ttotal: 47.1s\tremaining: 9m 15s\n",
      "391:\ttotal: 47.2s\tremaining: 9m 14s\n",
      "392:\ttotal: 47.3s\tremaining: 9m 14s\n",
      "393:\ttotal: 47.4s\tremaining: 9m 14s\n",
      "394:\ttotal: 47.6s\tremaining: 9m 14s\n",
      "395:\tlearn: 1.3425237\ttest: 1.4068531\tbest: 1.4068531 (395)\ttotal: 47.7s\tremaining: 9m 14s\n",
      "396:\ttotal: 47.8s\tremaining: 9m 13s\n",
      "397:\ttotal: 47.9s\tremaining: 9m 13s\n",
      "398:\ttotal: 48s\tremaining: 9m 13s\n",
      "399:\ttotal: 48.1s\tremaining: 9m 13s\n",
      "400:\tlearn: 1.3397593\ttest: 1.4046380\tbest: 1.4046380 (400)\ttotal: 48.2s\tremaining: 9m 13s\n",
      "401:\ttotal: 48.4s\tremaining: 9m 13s\n",
      "402:\ttotal: 48.5s\tremaining: 9m 12s\n",
      "403:\ttotal: 48.6s\tremaining: 9m 12s\n",
      "404:\ttotal: 48.7s\tremaining: 9m 12s\n",
      "405:\tlearn: 1.3371031\ttest: 1.4026257\tbest: 1.4026257 (405)\ttotal: 48.8s\tremaining: 9m 12s\n",
      "406:\ttotal: 48.9s\tremaining: 9m 12s\n",
      "407:\ttotal: 49.1s\tremaining: 9m 12s\n",
      "408:\ttotal: 49.2s\tremaining: 9m 12s\n",
      "409:\ttotal: 49.3s\tremaining: 9m 11s\n",
      "410:\tlearn: 1.3345733\ttest: 1.4007965\tbest: 1.4007965 (410)\ttotal: 49.4s\tremaining: 9m 11s\n",
      "411:\ttotal: 49.5s\tremaining: 9m 11s\n",
      "412:\ttotal: 49.7s\tremaining: 9m 11s\n",
      "413:\ttotal: 49.8s\tremaining: 9m 11s\n",
      "414:\ttotal: 49.9s\tremaining: 9m 11s\n",
      "415:\tlearn: 1.3318635\ttest: 1.3987571\tbest: 1.3987571 (415)\ttotal: 50s\tremaining: 9m 11s\n",
      "416:\ttotal: 50.1s\tremaining: 9m 10s\n",
      "417:\ttotal: 50.2s\tremaining: 9m 10s\n",
      "418:\ttotal: 50.4s\tremaining: 9m 10s\n",
      "419:\ttotal: 50.5s\tremaining: 9m 10s\n",
      "420:\tlearn: 1.3292822\ttest: 1.3968710\tbest: 1.3968710 (420)\ttotal: 50.6s\tremaining: 9m 10s\n",
      "421:\ttotal: 50.7s\tremaining: 9m 10s\n",
      "422:\ttotal: 50.8s\tremaining: 9m 9s\n",
      "423:\ttotal: 50.9s\tremaining: 9m 9s\n",
      "424:\ttotal: 51s\tremaining: 9m 9s\n",
      "425:\tlearn: 1.3266645\ttest: 1.3951284\tbest: 1.3951284 (425)\ttotal: 51.2s\tremaining: 9m 9s\n",
      "426:\ttotal: 51.3s\tremaining: 9m 9s\n",
      "427:\ttotal: 51.4s\tremaining: 9m 9s\n",
      "428:\ttotal: 51.5s\tremaining: 9m 9s\n",
      "429:\ttotal: 51.7s\tremaining: 9m 9s\n",
      "430:\tlearn: 1.3240883\ttest: 1.3932330\tbest: 1.3932330 (430)\ttotal: 51.8s\tremaining: 9m 8s\n",
      "431:\ttotal: 51.9s\tremaining: 9m 8s\n",
      "432:\ttotal: 52s\tremaining: 9m 8s\n",
      "433:\ttotal: 52.1s\tremaining: 9m 8s\n",
      "434:\ttotal: 52.2s\tremaining: 9m 8s\n",
      "435:\tlearn: 1.3214792\ttest: 1.3911434\tbest: 1.3911434 (435)\ttotal: 52.4s\tremaining: 9m 8s\n",
      "436:\ttotal: 52.5s\tremaining: 9m 7s\n",
      "437:\ttotal: 52.6s\tremaining: 9m 7s\n",
      "438:\ttotal: 52.7s\tremaining: 9m 7s\n",
      "439:\ttotal: 52.8s\tremaining: 9m 7s\n",
      "440:\tlearn: 1.3188340\ttest: 1.3891928\tbest: 1.3891928 (440)\ttotal: 52.9s\tremaining: 9m 7s\n",
      "441:\ttotal: 53s\tremaining: 9m 7s\n",
      "442:\ttotal: 53.2s\tremaining: 9m 6s\n",
      "443:\ttotal: 53.3s\tremaining: 9m 6s\n",
      "444:\ttotal: 53.4s\tremaining: 9m 6s\n",
      "445:\tlearn: 1.3162152\ttest: 1.3871276\tbest: 1.3871276 (445)\ttotal: 53.5s\tremaining: 9m 6s\n",
      "446:\ttotal: 53.6s\tremaining: 9m 6s\n",
      "447:\ttotal: 53.8s\tremaining: 9m 6s\n",
      "448:\ttotal: 53.9s\tremaining: 9m 5s\n",
      "449:\ttotal: 54s\tremaining: 9m 5s\n",
      "450:\tlearn: 1.3135407\ttest: 1.3850623\tbest: 1.3850623 (450)\ttotal: 54.1s\tremaining: 9m 5s\n",
      "451:\ttotal: 54.2s\tremaining: 9m 5s\n",
      "452:\ttotal: 54.4s\tremaining: 9m 5s\n",
      "453:\ttotal: 54.5s\tremaining: 9m 5s\n",
      "454:\ttotal: 54.6s\tremaining: 9m 5s\n",
      "455:\tlearn: 1.3111767\ttest: 1.3833634\tbest: 1.3833634 (455)\ttotal: 54.7s\tremaining: 9m 5s\n",
      "456:\ttotal: 54.8s\tremaining: 9m 5s\n",
      "457:\ttotal: 55s\tremaining: 9m 4s\n",
      "458:\ttotal: 55.1s\tremaining: 9m 4s\n",
      "459:\ttotal: 55.2s\tremaining: 9m 4s\n",
      "460:\tlearn: 1.3084007\ttest: 1.3813436\tbest: 1.3813436 (460)\ttotal: 55.3s\tremaining: 9m 4s\n",
      "461:\ttotal: 55.5s\tremaining: 9m 4s\n",
      "462:\ttotal: 55.6s\tremaining: 9m 4s\n",
      "463:\ttotal: 55.7s\tremaining: 9m 4s\n",
      "464:\ttotal: 55.9s\tremaining: 9m 4s\n",
      "465:\tlearn: 1.3060601\ttest: 1.3798172\tbest: 1.3798172 (465)\ttotal: 56s\tremaining: 9m 4s\n",
      "466:\ttotal: 56.1s\tremaining: 9m 4s\n",
      "467:\ttotal: 56.2s\tremaining: 9m 4s\n",
      "468:\ttotal: 56.4s\tremaining: 9m 4s\n",
      "469:\ttotal: 56.5s\tremaining: 9m 4s\n",
      "470:\tlearn: 1.3036260\ttest: 1.3781626\tbest: 1.3781626 (470)\ttotal: 56.6s\tremaining: 9m 4s\n",
      "471:\ttotal: 56.7s\tremaining: 9m 4s\n",
      "472:\ttotal: 56.8s\tremaining: 9m 3s\n",
      "473:\ttotal: 57s\tremaining: 9m 3s\n",
      "474:\ttotal: 57.1s\tremaining: 9m 3s\n",
      "475:\tlearn: 1.3011866\ttest: 1.3764041\tbest: 1.3764041 (475)\ttotal: 57.2s\tremaining: 9m 3s\n",
      "476:\ttotal: 57.3s\tremaining: 9m 3s\n",
      "477:\ttotal: 57.4s\tremaining: 9m 3s\n",
      "478:\ttotal: 57.6s\tremaining: 9m 3s\n",
      "479:\ttotal: 57.7s\tremaining: 9m 3s\n",
      "480:\tlearn: 1.2985538\ttest: 1.3744284\tbest: 1.3744284 (480)\ttotal: 57.8s\tremaining: 9m 2s\n",
      "481:\ttotal: 57.9s\tremaining: 9m 2s\n",
      "482:\ttotal: 58s\tremaining: 9m 2s\n",
      "483:\ttotal: 58.1s\tremaining: 9m 1s\n",
      "484:\ttotal: 58.2s\tremaining: 9m 1s\n",
      "485:\tlearn: 1.2958443\ttest: 1.3724658\tbest: 1.3724658 (485)\ttotal: 58.3s\tremaining: 9m 1s\n",
      "486:\ttotal: 58.5s\tremaining: 9m 1s\n",
      "487:\ttotal: 58.6s\tremaining: 9m 1s\n",
      "488:\ttotal: 58.7s\tremaining: 9m 1s\n",
      "489:\ttotal: 58.8s\tremaining: 9m 1s\n",
      "490:\tlearn: 1.2934058\ttest: 1.3707001\tbest: 1.3707001 (490)\ttotal: 58.9s\tremaining: 9m 1s\n",
      "491:\ttotal: 59.1s\tremaining: 9m 1s\n",
      "492:\ttotal: 59.2s\tremaining: 9m 1s\n",
      "493:\ttotal: 59.3s\tremaining: 9m 1s\n",
      "494:\ttotal: 59.4s\tremaining: 9m\n",
      "495:\tlearn: 1.2910013\ttest: 1.3689694\tbest: 1.3689694 (495)\ttotal: 59.6s\tremaining: 9m\n",
      "496:\ttotal: 59.7s\tremaining: 9m\n",
      "497:\ttotal: 59.8s\tremaining: 9m\n",
      "498:\ttotal: 59.9s\tremaining: 9m\n",
      "499:\ttotal: 1m\tremaining: 9m\n",
      "500:\tlearn: 1.2885918\ttest: 1.3672715\tbest: 1.3672715 (500)\ttotal: 1m\tremaining: 9m\n",
      "501:\ttotal: 1m\tremaining: 8m 59s\n",
      "502:\ttotal: 1m\tremaining: 8m 59s\n",
      "503:\ttotal: 1m\tremaining: 8m 59s\n",
      "504:\ttotal: 1m\tremaining: 8m 59s\n",
      "505:\tlearn: 1.2860701\ttest: 1.3655645\tbest: 1.3655645 (505)\ttotal: 1m\tremaining: 8m 59s\n",
      "506:\ttotal: 1m\tremaining: 8m 59s\n",
      "507:\ttotal: 1m\tremaining: 8m 59s\n",
      "508:\ttotal: 1m 1s\tremaining: 8m 59s\n",
      "509:\ttotal: 1m 1s\tremaining: 8m 58s\n",
      "510:\tlearn: 1.2835593\ttest: 1.3637058\tbest: 1.3637058 (510)\ttotal: 1m 1s\tremaining: 8m 58s\n",
      "511:\ttotal: 1m 1s\tremaining: 8m 58s\n",
      "512:\ttotal: 1m 1s\tremaining: 8m 58s\n",
      "513:\ttotal: 1m 1s\tremaining: 8m 58s\n",
      "514:\ttotal: 1m 1s\tremaining: 8m 58s\n",
      "515:\tlearn: 1.2811658\ttest: 1.3617899\tbest: 1.3617899 (515)\ttotal: 1m 1s\tremaining: 8m 58s\n",
      "516:\ttotal: 1m 2s\tremaining: 8m 58s\n",
      "517:\ttotal: 1m 2s\tremaining: 8m 57s\n",
      "518:\ttotal: 1m 2s\tremaining: 8m 57s\n",
      "519:\ttotal: 1m 2s\tremaining: 8m 57s\n",
      "520:\tlearn: 1.2786874\ttest: 1.3600747\tbest: 1.3600747 (520)\ttotal: 1m 2s\tremaining: 8m 57s\n",
      "521:\ttotal: 1m 2s\tremaining: 8m 57s\n",
      "522:\ttotal: 1m 2s\tremaining: 8m 57s\n",
      "523:\ttotal: 1m 2s\tremaining: 8m 57s\n",
      "524:\ttotal: 1m 3s\tremaining: 8m 57s\n",
      "525:\tlearn: 1.2762818\ttest: 1.3583675\tbest: 1.3583675 (525)\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "526:\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "527:\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "528:\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "529:\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "530:\tlearn: 1.2740476\ttest: 1.3566614\tbest: 1.3566614 (530)\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "531:\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "532:\ttotal: 1m 3s\tremaining: 8m 56s\n",
      "533:\ttotal: 1m 4s\tremaining: 8m 56s\n",
      "534:\ttotal: 1m 4s\tremaining: 8m 55s\n",
      "535:\tlearn: 1.2715273\ttest: 1.3550221\tbest: 1.3550221 (535)\ttotal: 1m 4s\tremaining: 8m 55s\n",
      "536:\ttotal: 1m 4s\tremaining: 8m 55s\n",
      "537:\ttotal: 1m 4s\tremaining: 8m 55s\n",
      "538:\ttotal: 1m 4s\tremaining: 8m 55s\n",
      "539:\ttotal: 1m 4s\tremaining: 8m 55s\n",
      "540:\tlearn: 1.2693482\ttest: 1.3536762\tbest: 1.3536762 (540)\ttotal: 1m 4s\tremaining: 8m 55s\n",
      "541:\ttotal: 1m 5s\tremaining: 8m 55s\n",
      "542:\ttotal: 1m 5s\tremaining: 8m 55s\n",
      "543:\ttotal: 1m 5s\tremaining: 8m 55s\n",
      "544:\ttotal: 1m 5s\tremaining: 8m 55s\n",
      "545:\tlearn: 1.2672105\ttest: 1.3521961\tbest: 1.3521961 (545)\ttotal: 1m 5s\tremaining: 8m 54s\n",
      "546:\ttotal: 1m 5s\tremaining: 8m 54s\n",
      "547:\ttotal: 1m 5s\tremaining: 8m 54s\n",
      "548:\ttotal: 1m 5s\tremaining: 8m 54s\n",
      "549:\ttotal: 1m 6s\tremaining: 8m 54s\n",
      "550:\tlearn: 1.2647121\ttest: 1.3503637\tbest: 1.3503637 (550)\ttotal: 1m 6s\tremaining: 8m 54s\n",
      "551:\ttotal: 1m 6s\tremaining: 8m 54s\n",
      "552:\ttotal: 1m 6s\tremaining: 8m 54s\n",
      "553:\ttotal: 1m 6s\tremaining: 8m 53s\n",
      "554:\ttotal: 1m 6s\tremaining: 8m 53s\n",
      "555:\tlearn: 1.2624385\ttest: 1.3486546\tbest: 1.3486546 (555)\ttotal: 1m 6s\tremaining: 8m 53s\n",
      "556:\ttotal: 1m 6s\tremaining: 8m 53s\n",
      "557:\ttotal: 1m 6s\tremaining: 8m 53s\n",
      "558:\ttotal: 1m 7s\tremaining: 8m 53s\n",
      "559:\ttotal: 1m 7s\tremaining: 8m 52s\n",
      "560:\tlearn: 1.2601608\ttest: 1.3468909\tbest: 1.3468909 (560)\ttotal: 1m 7s\tremaining: 8m 52s\n",
      "561:\ttotal: 1m 7s\tremaining: 8m 52s\n",
      "562:\ttotal: 1m 7s\tremaining: 8m 52s\n",
      "563:\ttotal: 1m 7s\tremaining: 8m 52s\n",
      "564:\ttotal: 1m 7s\tremaining: 8m 52s\n",
      "565:\tlearn: 1.2579461\ttest: 1.3452583\tbest: 1.3452583 (565)\ttotal: 1m 7s\tremaining: 8m 52s\n",
      "566:\ttotal: 1m 8s\tremaining: 8m 52s\n",
      "567:\ttotal: 1m 8s\tremaining: 8m 51s\n",
      "568:\ttotal: 1m 8s\tremaining: 8m 51s\n",
      "569:\ttotal: 1m 8s\tremaining: 8m 51s\n",
      "570:\tlearn: 1.2554354\ttest: 1.3433749\tbest: 1.3433749 (570)\ttotal: 1m 8s\tremaining: 8m 51s\n",
      "571:\ttotal: 1m 8s\tremaining: 8m 51s\n",
      "572:\ttotal: 1m 8s\tremaining: 8m 51s\n",
      "573:\ttotal: 1m 8s\tremaining: 8m 51s\n",
      "574:\ttotal: 1m 9s\tremaining: 8m 51s\n",
      "575:\tlearn: 1.2532207\ttest: 1.3418285\tbest: 1.3418285 (575)\ttotal: 1m 9s\tremaining: 8m 50s\n",
      "576:\ttotal: 1m 9s\tremaining: 8m 50s\n",
      "577:\ttotal: 1m 9s\tremaining: 8m 50s\n",
      "578:\ttotal: 1m 9s\tremaining: 8m 50s\n",
      "579:\ttotal: 1m 9s\tremaining: 8m 50s\n",
      "580:\tlearn: 1.2510635\ttest: 1.3403906\tbest: 1.3403906 (580)\ttotal: 1m 9s\tremaining: 8m 50s\n",
      "581:\ttotal: 1m 9s\tremaining: 8m 50s\n",
      "582:\ttotal: 1m 9s\tremaining: 8m 50s\n",
      "583:\ttotal: 1m 10s\tremaining: 8m 50s\n",
      "584:\ttotal: 1m 10s\tremaining: 8m 50s\n",
      "585:\tlearn: 1.2489081\ttest: 1.3389201\tbest: 1.3389201 (585)\ttotal: 1m 10s\tremaining: 8m 50s\n",
      "586:\ttotal: 1m 10s\tremaining: 8m 49s\n",
      "587:\ttotal: 1m 10s\tremaining: 8m 49s\n",
      "588:\ttotal: 1m 10s\tremaining: 8m 49s\n",
      "589:\ttotal: 1m 10s\tremaining: 8m 49s\n",
      "590:\tlearn: 1.2467036\ttest: 1.3373518\tbest: 1.3373518 (590)\ttotal: 1m 10s\tremaining: 8m 49s\n",
      "591:\ttotal: 1m 11s\tremaining: 8m 49s\n",
      "592:\ttotal: 1m 11s\tremaining: 8m 49s\n",
      "593:\ttotal: 1m 11s\tremaining: 8m 49s\n",
      "594:\ttotal: 1m 11s\tremaining: 8m 48s\n",
      "595:\tlearn: 1.2444721\ttest: 1.3357867\tbest: 1.3357867 (595)\ttotal: 1m 11s\tremaining: 8m 48s\n",
      "596:\ttotal: 1m 11s\tremaining: 8m 48s\n",
      "597:\ttotal: 1m 11s\tremaining: 8m 48s\n",
      "598:\ttotal: 1m 11s\tremaining: 8m 48s\n",
      "599:\ttotal: 1m 12s\tremaining: 8m 48s\n",
      "600:\tlearn: 1.2422772\ttest: 1.3339580\tbest: 1.3339580 (600)\ttotal: 1m 12s\tremaining: 8m 48s\n",
      "601:\ttotal: 1m 12s\tremaining: 8m 47s\n",
      "602:\ttotal: 1m 12s\tremaining: 8m 47s\n",
      "603:\ttotal: 1m 12s\tremaining: 8m 47s\n",
      "604:\ttotal: 1m 12s\tremaining: 8m 47s\n",
      "605:\tlearn: 1.2399480\ttest: 1.3324639\tbest: 1.3324639 (605)\ttotal: 1m 12s\tremaining: 8m 47s\n",
      "606:\ttotal: 1m 12s\tremaining: 8m 47s\n",
      "607:\ttotal: 1m 12s\tremaining: 8m 47s\n",
      "608:\ttotal: 1m 13s\tremaining: 8m 47s\n",
      "609:\ttotal: 1m 13s\tremaining: 8m 46s\n",
      "610:\tlearn: 1.2378447\ttest: 1.3310367\tbest: 1.3310367 (610)\ttotal: 1m 13s\tremaining: 8m 46s\n",
      "611:\ttotal: 1m 13s\tremaining: 8m 46s\n",
      "612:\ttotal: 1m 13s\tremaining: 8m 46s\n",
      "613:\ttotal: 1m 13s\tremaining: 8m 46s\n",
      "614:\ttotal: 1m 13s\tremaining: 8m 46s\n",
      "615:\tlearn: 1.2354291\ttest: 1.3291391\tbest: 1.3291391 (615)\ttotal: 1m 13s\tremaining: 8m 45s\n",
      "616:\ttotal: 1m 14s\tremaining: 8m 45s\n",
      "617:\ttotal: 1m 14s\tremaining: 8m 45s\n",
      "618:\ttotal: 1m 14s\tremaining: 8m 45s\n",
      "619:\ttotal: 1m 14s\tremaining: 8m 45s\n",
      "620:\tlearn: 1.2332769\ttest: 1.3277686\tbest: 1.3277686 (620)\ttotal: 1m 14s\tremaining: 8m 45s\n",
      "621:\ttotal: 1m 14s\tremaining: 8m 44s\n",
      "622:\ttotal: 1m 14s\tremaining: 8m 44s\n",
      "623:\ttotal: 1m 14s\tremaining: 8m 44s\n",
      "624:\ttotal: 1m 14s\tremaining: 8m 44s\n",
      "625:\tlearn: 1.2309578\ttest: 1.3261832\tbest: 1.3261832 (625)\ttotal: 1m 15s\tremaining: 8m 44s\n",
      "626:\ttotal: 1m 15s\tremaining: 8m 44s\n",
      "627:\ttotal: 1m 15s\tremaining: 8m 44s\n",
      "628:\ttotal: 1m 15s\tremaining: 8m 44s\n",
      "629:\ttotal: 1m 15s\tremaining: 8m 44s\n",
      "630:\tlearn: 1.2288991\ttest: 1.3248841\tbest: 1.3248841 (630)\ttotal: 1m 15s\tremaining: 8m 44s\n",
      "631:\ttotal: 1m 15s\tremaining: 8m 44s\n",
      "632:\ttotal: 1m 15s\tremaining: 8m 44s\n",
      "633:\ttotal: 1m 16s\tremaining: 8m 43s\n",
      "634:\ttotal: 1m 16s\tremaining: 8m 43s\n",
      "635:\tlearn: 1.2266010\ttest: 1.3231895\tbest: 1.3231895 (635)\ttotal: 1m 16s\tremaining: 8m 43s\n",
      "636:\ttotal: 1m 16s\tremaining: 8m 43s\n",
      "637:\ttotal: 1m 16s\tremaining: 8m 43s\n",
      "638:\ttotal: 1m 16s\tremaining: 8m 43s\n",
      "639:\ttotal: 1m 16s\tremaining: 8m 43s\n",
      "640:\tlearn: 1.2245029\ttest: 1.3216820\tbest: 1.3216820 (640)\ttotal: 1m 16s\tremaining: 8m 43s\n",
      "641:\ttotal: 1m 17s\tremaining: 8m 42s\n",
      "642:\ttotal: 1m 17s\tremaining: 8m 42s\n",
      "643:\ttotal: 1m 17s\tremaining: 8m 42s\n",
      "644:\ttotal: 1m 17s\tremaining: 8m 42s\n",
      "645:\tlearn: 1.2223719\ttest: 1.3199642\tbest: 1.3199642 (645)\ttotal: 1m 17s\tremaining: 8m 42s\n",
      "646:\ttotal: 1m 17s\tremaining: 8m 42s\n",
      "647:\ttotal: 1m 17s\tremaining: 8m 42s\n",
      "648:\ttotal: 1m 17s\tremaining: 8m 42s\n",
      "649:\ttotal: 1m 18s\tremaining: 8m 42s\n",
      "650:\tlearn: 1.2204522\ttest: 1.3185538\tbest: 1.3185538 (650)\ttotal: 1m 18s\tremaining: 8m 41s\n",
      "651:\ttotal: 1m 18s\tremaining: 8m 41s\n",
      "652:\ttotal: 1m 18s\tremaining: 8m 41s\n",
      "653:\ttotal: 1m 18s\tremaining: 8m 41s\n",
      "654:\ttotal: 1m 18s\tremaining: 8m 41s\n",
      "655:\tlearn: 1.2183333\ttest: 1.3172391\tbest: 1.3172391 (655)\ttotal: 1m 18s\tremaining: 8m 41s\n",
      "656:\ttotal: 1m 18s\tremaining: 8m 41s\n",
      "657:\ttotal: 1m 18s\tremaining: 8m 41s\n",
      "658:\ttotal: 1m 19s\tremaining: 8m 41s\n",
      "659:\ttotal: 1m 19s\tremaining: 8m 40s\n",
      "660:\tlearn: 1.2162191\ttest: 1.3157782\tbest: 1.3157782 (660)\ttotal: 1m 19s\tremaining: 8m 40s\n",
      "661:\ttotal: 1m 19s\tremaining: 8m 40s\n",
      "662:\ttotal: 1m 19s\tremaining: 8m 40s\n",
      "663:\ttotal: 1m 19s\tremaining: 8m 40s\n",
      "664:\ttotal: 1m 19s\tremaining: 8m 40s\n",
      "665:\tlearn: 1.2141596\ttest: 1.3143841\tbest: 1.3143841 (665)\ttotal: 1m 19s\tremaining: 8m 40s\n",
      "666:\ttotal: 1m 20s\tremaining: 8m 40s\n",
      "667:\ttotal: 1m 20s\tremaining: 8m 39s\n",
      "668:\ttotal: 1m 20s\tremaining: 8m 39s\n",
      "669:\ttotal: 1m 20s\tremaining: 8m 39s\n",
      "670:\tlearn: 1.2120816\ttest: 1.3130373\tbest: 1.3130373 (670)\ttotal: 1m 20s\tremaining: 8m 39s\n",
      "671:\ttotal: 1m 20s\tremaining: 8m 39s\n",
      "672:\ttotal: 1m 20s\tremaining: 8m 39s\n",
      "673:\ttotal: 1m 20s\tremaining: 8m 39s\n",
      "674:\ttotal: 1m 21s\tremaining: 8m 39s\n",
      "675:\tlearn: 1.2101486\ttest: 1.3117855\tbest: 1.3117855 (675)\ttotal: 1m 21s\tremaining: 8m 38s\n",
      "676:\ttotal: 1m 21s\tremaining: 8m 38s\n",
      "677:\ttotal: 1m 21s\tremaining: 8m 38s\n",
      "678:\ttotal: 1m 21s\tremaining: 8m 38s\n",
      "679:\ttotal: 1m 21s\tremaining: 8m 38s\n",
      "680:\tlearn: 1.2080525\ttest: 1.3100680\tbest: 1.3100680 (680)\ttotal: 1m 21s\tremaining: 8m 38s\n",
      "681:\ttotal: 1m 21s\tremaining: 8m 38s\n",
      "682:\ttotal: 1m 21s\tremaining: 8m 37s\n",
      "683:\ttotal: 1m 22s\tremaining: 8m 37s\n",
      "684:\ttotal: 1m 22s\tremaining: 8m 37s\n",
      "685:\tlearn: 1.2060571\ttest: 1.3087319\tbest: 1.3087319 (685)\ttotal: 1m 22s\tremaining: 8m 37s\n",
      "686:\ttotal: 1m 22s\tremaining: 8m 37s\n",
      "687:\ttotal: 1m 22s\tremaining: 8m 37s\n",
      "688:\ttotal: 1m 22s\tremaining: 8m 36s\n",
      "689:\ttotal: 1m 22s\tremaining: 8m 36s\n",
      "690:\tlearn: 1.2039345\ttest: 1.3072911\tbest: 1.3072911 (690)\ttotal: 1m 22s\tremaining: 8m 36s\n",
      "691:\ttotal: 1m 22s\tremaining: 8m 36s\n",
      "692:\ttotal: 1m 23s\tremaining: 8m 36s\n",
      "693:\ttotal: 1m 23s\tremaining: 8m 36s\n",
      "694:\ttotal: 1m 23s\tremaining: 8m 36s\n",
      "695:\tlearn: 1.2019172\ttest: 1.3059255\tbest: 1.3059255 (695)\ttotal: 1m 23s\tremaining: 8m 36s\n",
      "696:\ttotal: 1m 23s\tremaining: 8m 36s\n",
      "697:\ttotal: 1m 23s\tremaining: 8m 35s\n",
      "698:\ttotal: 1m 23s\tremaining: 8m 35s\n",
      "699:\ttotal: 1m 23s\tremaining: 8m 35s\n",
      "700:\tlearn: 1.1998599\ttest: 1.3045714\tbest: 1.3045714 (700)\ttotal: 1m 24s\tremaining: 8m 35s\n",
      "701:\ttotal: 1m 24s\tremaining: 8m 35s\n",
      "702:\ttotal: 1m 24s\tremaining: 8m 35s\n",
      "703:\ttotal: 1m 24s\tremaining: 8m 35s\n",
      "704:\ttotal: 1m 24s\tremaining: 8m 34s\n",
      "705:\tlearn: 1.1978561\ttest: 1.3033137\tbest: 1.3033137 (705)\ttotal: 1m 24s\tremaining: 8m 34s\n",
      "706:\ttotal: 1m 24s\tremaining: 8m 34s\n",
      "707:\ttotal: 1m 24s\tremaining: 8m 34s\n",
      "708:\ttotal: 1m 24s\tremaining: 8m 34s\n",
      "709:\ttotal: 1m 25s\tremaining: 8m 34s\n",
      "710:\tlearn: 1.1958233\ttest: 1.3018726\tbest: 1.3018726 (710)\ttotal: 1m 25s\tremaining: 8m 34s\n",
      "711:\ttotal: 1m 25s\tremaining: 8m 33s\n",
      "712:\ttotal: 1m 25s\tremaining: 8m 33s\n",
      "713:\ttotal: 1m 25s\tremaining: 8m 33s\n",
      "714:\ttotal: 1m 25s\tremaining: 8m 33s\n",
      "715:\tlearn: 1.1936135\ttest: 1.3001231\tbest: 1.3001231 (715)\ttotal: 1m 25s\tremaining: 8m 33s\n",
      "716:\ttotal: 1m 25s\tremaining: 8m 32s\n",
      "717:\ttotal: 1m 25s\tremaining: 8m 32s\n",
      "718:\ttotal: 1m 26s\tremaining: 8m 32s\n",
      "719:\ttotal: 1m 26s\tremaining: 8m 32s\n",
      "720:\tlearn: 1.1915557\ttest: 1.2986385\tbest: 1.2986385 (720)\ttotal: 1m 26s\tremaining: 8m 32s\n",
      "721:\ttotal: 1m 26s\tremaining: 8m 32s\n",
      "722:\ttotal: 1m 26s\tremaining: 8m 32s\n",
      "723:\ttotal: 1m 26s\tremaining: 8m 32s\n",
      "724:\ttotal: 1m 26s\tremaining: 8m 32s\n",
      "725:\tlearn: 1.1895040\ttest: 1.2973234\tbest: 1.2973234 (725)\ttotal: 1m 26s\tremaining: 8m 31s\n",
      "726:\ttotal: 1m 27s\tremaining: 8m 31s\n",
      "727:\ttotal: 1m 27s\tremaining: 8m 31s\n",
      "728:\ttotal: 1m 27s\tremaining: 8m 31s\n",
      "729:\ttotal: 1m 27s\tremaining: 8m 31s\n",
      "730:\tlearn: 1.1875137\ttest: 1.2960196\tbest: 1.2960196 (730)\ttotal: 1m 27s\tremaining: 8m 31s\n",
      "731:\ttotal: 1m 27s\tremaining: 8m 31s\n",
      "732:\ttotal: 1m 27s\tremaining: 8m 30s\n",
      "733:\ttotal: 1m 27s\tremaining: 8m 30s\n",
      "734:\ttotal: 1m 28s\tremaining: 8m 30s\n",
      "735:\tlearn: 1.1856451\ttest: 1.2947862\tbest: 1.2947862 (735)\ttotal: 1m 28s\tremaining: 8m 30s\n",
      "736:\ttotal: 1m 28s\tremaining: 8m 30s\n",
      "737:\ttotal: 1m 28s\tremaining: 8m 30s\n",
      "738:\ttotal: 1m 28s\tremaining: 8m 30s\n",
      "739:\ttotal: 1m 28s\tremaining: 8m 30s\n",
      "740:\tlearn: 1.1835900\ttest: 1.2934352\tbest: 1.2934352 (740)\ttotal: 1m 28s\tremaining: 8m 30s\n",
      "741:\ttotal: 1m 28s\tremaining: 8m 29s\n",
      "742:\ttotal: 1m 28s\tremaining: 8m 29s\n",
      "743:\ttotal: 1m 29s\tremaining: 8m 29s\n",
      "744:\ttotal: 1m 29s\tremaining: 8m 29s\n",
      "745:\tlearn: 1.1816258\ttest: 1.2919703\tbest: 1.2919703 (745)\ttotal: 1m 29s\tremaining: 8m 29s\n",
      "746:\ttotal: 1m 29s\tremaining: 8m 29s\n",
      "747:\ttotal: 1m 29s\tremaining: 8m 29s\n",
      "748:\ttotal: 1m 29s\tremaining: 8m 29s\n",
      "749:\ttotal: 1m 29s\tremaining: 8m 29s\n",
      "750:\tlearn: 1.1797826\ttest: 1.2907323\tbest: 1.2907323 (750)\ttotal: 1m 29s\tremaining: 8m 29s\n",
      "751:\ttotal: 1m 30s\tremaining: 8m 28s\n",
      "752:\ttotal: 1m 30s\tremaining: 8m 28s\n",
      "753:\ttotal: 1m 30s\tremaining: 8m 28s\n",
      "754:\ttotal: 1m 30s\tremaining: 8m 28s\n",
      "755:\tlearn: 1.1778903\ttest: 1.2895565\tbest: 1.2895565 (755)\ttotal: 1m 30s\tremaining: 8m 28s\n",
      "756:\ttotal: 1m 30s\tremaining: 8m 28s\n",
      "757:\ttotal: 1m 30s\tremaining: 8m 28s\n",
      "758:\ttotal: 1m 30s\tremaining: 8m 28s\n",
      "759:\ttotal: 1m 31s\tremaining: 8m 28s\n",
      "760:\tlearn: 1.1759261\ttest: 1.2882970\tbest: 1.2882970 (760)\ttotal: 1m 31s\tremaining: 8m 27s\n",
      "761:\ttotal: 1m 31s\tremaining: 8m 27s\n",
      "762:\ttotal: 1m 31s\tremaining: 8m 27s\n",
      "763:\ttotal: 1m 31s\tremaining: 8m 27s\n",
      "764:\ttotal: 1m 31s\tremaining: 8m 27s\n",
      "765:\tlearn: 1.1739538\ttest: 1.2868547\tbest: 1.2868547 (765)\ttotal: 1m 31s\tremaining: 8m 27s\n",
      "766:\ttotal: 1m 31s\tremaining: 8m 27s\n",
      "767:\ttotal: 1m 31s\tremaining: 8m 26s\n",
      "768:\ttotal: 1m 32s\tremaining: 8m 26s\n",
      "769:\ttotal: 1m 32s\tremaining: 8m 26s\n",
      "770:\tlearn: 1.1720759\ttest: 1.2855954\tbest: 1.2855954 (770)\ttotal: 1m 32s\tremaining: 8m 26s\n",
      "771:\ttotal: 1m 32s\tremaining: 8m 26s\n",
      "772:\ttotal: 1m 32s\tremaining: 8m 26s\n",
      "773:\ttotal: 1m 32s\tremaining: 8m 26s\n",
      "774:\ttotal: 1m 32s\tremaining: 8m 26s\n",
      "775:\tlearn: 1.1702048\ttest: 1.2843614\tbest: 1.2843614 (775)\ttotal: 1m 32s\tremaining: 8m 25s\n",
      "776:\ttotal: 1m 33s\tremaining: 8m 25s\n",
      "777:\ttotal: 1m 33s\tremaining: 8m 25s\n",
      "778:\ttotal: 1m 33s\tremaining: 8m 25s\n",
      "779:\ttotal: 1m 33s\tremaining: 8m 25s\n",
      "780:\tlearn: 1.1683216\ttest: 1.2831999\tbest: 1.2831999 (780)\ttotal: 1m 33s\tremaining: 8m 25s\n",
      "781:\ttotal: 1m 33s\tremaining: 8m 25s\n",
      "782:\ttotal: 1m 33s\tremaining: 8m 25s\n",
      "783:\ttotal: 1m 33s\tremaining: 8m 25s\n",
      "784:\ttotal: 1m 34s\tremaining: 8m 25s\n",
      "785:\tlearn: 1.1664331\ttest: 1.2820221\tbest: 1.2820221 (785)\ttotal: 1m 34s\tremaining: 8m 24s\n",
      "786:\ttotal: 1m 34s\tremaining: 8m 24s\n",
      "787:\ttotal: 1m 34s\tremaining: 8m 24s\n",
      "788:\ttotal: 1m 34s\tremaining: 8m 24s\n",
      "789:\ttotal: 1m 34s\tremaining: 8m 24s\n",
      "790:\tlearn: 1.1644591\ttest: 1.2806035\tbest: 1.2806035 (790)\ttotal: 1m 34s\tremaining: 8m 24s\n",
      "791:\ttotal: 1m 34s\tremaining: 8m 24s\n",
      "792:\ttotal: 1m 35s\tremaining: 8m 23s\n",
      "793:\ttotal: 1m 35s\tremaining: 8m 23s\n",
      "794:\ttotal: 1m 35s\tremaining: 8m 23s\n",
      "795:\tlearn: 1.1624532\ttest: 1.2792211\tbest: 1.2792211 (795)\ttotal: 1m 35s\tremaining: 8m 23s\n",
      "796:\ttotal: 1m 35s\tremaining: 8m 23s\n",
      "797:\ttotal: 1m 35s\tremaining: 8m 23s\n",
      "798:\ttotal: 1m 35s\tremaining: 8m 23s\n",
      "799:\ttotal: 1m 35s\tremaining: 8m 22s\n",
      "800:\tlearn: 1.1604922\ttest: 1.2778647\tbest: 1.2778647 (800)\ttotal: 1m 35s\tremaining: 8m 22s\n",
      "801:\ttotal: 1m 36s\tremaining: 8m 22s\n",
      "802:\ttotal: 1m 36s\tremaining: 8m 22s\n",
      "803:\ttotal: 1m 36s\tremaining: 8m 22s\n",
      "804:\ttotal: 1m 36s\tremaining: 8m 22s\n",
      "805:\tlearn: 1.1585478\ttest: 1.2767832\tbest: 1.2767832 (805)\ttotal: 1m 36s\tremaining: 8m 22s\n",
      "806:\ttotal: 1m 36s\tremaining: 8m 22s\n",
      "807:\ttotal: 1m 36s\tremaining: 8m 21s\n",
      "808:\ttotal: 1m 36s\tremaining: 8m 21s\n",
      "809:\ttotal: 1m 36s\tremaining: 8m 21s\n",
      "810:\tlearn: 1.1567182\ttest: 1.2756358\tbest: 1.2756358 (810)\ttotal: 1m 37s\tremaining: 8m 21s\n",
      "811:\ttotal: 1m 37s\tremaining: 8m 21s\n",
      "812:\ttotal: 1m 37s\tremaining: 8m 21s\n",
      "813:\ttotal: 1m 37s\tremaining: 8m 21s\n",
      "814:\ttotal: 1m 37s\tremaining: 8m 21s\n",
      "815:\tlearn: 1.1548234\ttest: 1.2743706\tbest: 1.2743706 (815)\ttotal: 1m 37s\tremaining: 8m 20s\n",
      "816:\ttotal: 1m 37s\tremaining: 8m 20s\n",
      "817:\ttotal: 1m 37s\tremaining: 8m 20s\n",
      "818:\ttotal: 1m 38s\tremaining: 8m 20s\n",
      "819:\ttotal: 1m 38s\tremaining: 8m 20s\n",
      "820:\tlearn: 1.1529340\ttest: 1.2732408\tbest: 1.2732408 (820)\ttotal: 1m 38s\tremaining: 8m 20s\n",
      "821:\ttotal: 1m 38s\tremaining: 8m 20s\n",
      "822:\ttotal: 1m 38s\tremaining: 8m 20s\n",
      "823:\ttotal: 1m 38s\tremaining: 8m 20s\n",
      "824:\ttotal: 1m 38s\tremaining: 8m 20s\n",
      "825:\tlearn: 1.1510986\ttest: 1.2721167\tbest: 1.2721167 (825)\ttotal: 1m 38s\tremaining: 8m 19s\n",
      "826:\ttotal: 1m 39s\tremaining: 8m 19s\n",
      "827:\ttotal: 1m 39s\tremaining: 8m 19s\n",
      "828:\ttotal: 1m 39s\tremaining: 8m 19s\n",
      "829:\ttotal: 1m 39s\tremaining: 8m 19s\n",
      "830:\tlearn: 1.1493195\ttest: 1.2707603\tbest: 1.2707603 (830)\ttotal: 1m 39s\tremaining: 8m 19s\n",
      "831:\ttotal: 1m 39s\tremaining: 8m 19s\n",
      "832:\ttotal: 1m 39s\tremaining: 8m 19s\n",
      "833:\ttotal: 1m 39s\tremaining: 8m 19s\n",
      "834:\ttotal: 1m 40s\tremaining: 8m 18s\n",
      "835:\tlearn: 1.1473856\ttest: 1.2694841\tbest: 1.2694841 (835)\ttotal: 1m 40s\tremaining: 8m 18s\n",
      "836:\ttotal: 1m 40s\tremaining: 8m 18s\n",
      "837:\ttotal: 1m 40s\tremaining: 8m 18s\n",
      "838:\ttotal: 1m 40s\tremaining: 8m 18s\n",
      "839:\ttotal: 1m 40s\tremaining: 8m 18s\n",
      "840:\tlearn: 1.1455996\ttest: 1.2683424\tbest: 1.2683424 (840)\ttotal: 1m 40s\tremaining: 8m 18s\n",
      "841:\ttotal: 1m 40s\tremaining: 8m 18s\n",
      "842:\ttotal: 1m 40s\tremaining: 8m 17s\n",
      "843:\ttotal: 1m 41s\tremaining: 8m 17s\n",
      "844:\ttotal: 1m 41s\tremaining: 8m 17s\n",
      "845:\tlearn: 1.1437104\ttest: 1.2671674\tbest: 1.2671674 (845)\ttotal: 1m 41s\tremaining: 8m 17s\n",
      "846:\ttotal: 1m 41s\tremaining: 8m 17s\n",
      "847:\ttotal: 1m 41s\tremaining: 8m 17s\n",
      "848:\ttotal: 1m 41s\tremaining: 8m 17s\n",
      "849:\ttotal: 1m 41s\tremaining: 8m 16s\n",
      "850:\tlearn: 1.1418854\ttest: 1.2659607\tbest: 1.2659607 (850)\ttotal: 1m 41s\tremaining: 8m 16s\n",
      "851:\ttotal: 1m 42s\tremaining: 8m 16s\n",
      "852:\ttotal: 1m 42s\tremaining: 8m 16s\n",
      "853:\ttotal: 1m 42s\tremaining: 8m 16s\n",
      "854:\ttotal: 1m 42s\tremaining: 8m 16s\n",
      "855:\tlearn: 1.1399935\ttest: 1.2646064\tbest: 1.2646064 (855)\ttotal: 1m 42s\tremaining: 8m 16s\n",
      "856:\ttotal: 1m 42s\tremaining: 8m 16s\n",
      "857:\ttotal: 1m 42s\tremaining: 8m 16s\n",
      "858:\ttotal: 1m 42s\tremaining: 8m 15s\n",
      "859:\ttotal: 1m 42s\tremaining: 8m 15s\n",
      "860:\tlearn: 1.1382789\ttest: 1.2635386\tbest: 1.2635386 (860)\ttotal: 1m 43s\tremaining: 8m 15s\n",
      "861:\ttotal: 1m 43s\tremaining: 8m 15s\n",
      "862:\ttotal: 1m 43s\tremaining: 8m 15s\n",
      "863:\ttotal: 1m 43s\tremaining: 8m 15s\n",
      "864:\ttotal: 1m 43s\tremaining: 8m 15s\n",
      "865:\tlearn: 1.1365107\ttest: 1.2624049\tbest: 1.2624049 (865)\ttotal: 1m 43s\tremaining: 8m 15s\n",
      "866:\ttotal: 1m 43s\tremaining: 8m 15s\n",
      "867:\ttotal: 1m 43s\tremaining: 8m 14s\n",
      "868:\ttotal: 1m 44s\tremaining: 8m 14s\n",
      "869:\ttotal: 1m 44s\tremaining: 8m 14s\n",
      "870:\tlearn: 1.1347475\ttest: 1.2613182\tbest: 1.2613182 (870)\ttotal: 1m 44s\tremaining: 8m 14s\n",
      "871:\ttotal: 1m 44s\tremaining: 8m 14s\n",
      "872:\ttotal: 1m 44s\tremaining: 8m 14s\n",
      "873:\ttotal: 1m 44s\tremaining: 8m 14s\n",
      "874:\ttotal: 1m 44s\tremaining: 8m 14s\n",
      "875:\tlearn: 1.1330224\ttest: 1.2602160\tbest: 1.2602160 (875)\ttotal: 1m 44s\tremaining: 8m 14s\n",
      "876:\ttotal: 1m 45s\tremaining: 8m 13s\n",
      "877:\ttotal: 1m 45s\tremaining: 8m 13s\n",
      "878:\ttotal: 1m 45s\tremaining: 8m 13s\n",
      "879:\ttotal: 1m 45s\tremaining: 8m 13s\n",
      "880:\tlearn: 1.1311906\ttest: 1.2588920\tbest: 1.2588920 (880)\ttotal: 1m 45s\tremaining: 8m 13s\n",
      "881:\ttotal: 1m 45s\tremaining: 8m 13s\n",
      "882:\ttotal: 1m 45s\tremaining: 8m 13s\n",
      "883:\ttotal: 1m 45s\tremaining: 8m 13s\n",
      "884:\ttotal: 1m 46s\tremaining: 8m 13s\n",
      "885:\tlearn: 1.1294282\ttest: 1.2577101\tbest: 1.2577101 (885)\ttotal: 1m 46s\tremaining: 8m 13s\n",
      "886:\ttotal: 1m 46s\tremaining: 8m 13s\n",
      "887:\ttotal: 1m 46s\tremaining: 8m 12s\n",
      "888:\ttotal: 1m 46s\tremaining: 8m 12s\n",
      "889:\ttotal: 1m 46s\tremaining: 8m 12s\n",
      "890:\tlearn: 1.1275877\ttest: 1.2563899\tbest: 1.2563899 (890)\ttotal: 1m 46s\tremaining: 8m 12s\n",
      "891:\ttotal: 1m 46s\tremaining: 8m 12s\n",
      "892:\ttotal: 1m 47s\tremaining: 8m 12s\n",
      "893:\ttotal: 1m 47s\tremaining: 8m 12s\n",
      "894:\ttotal: 1m 47s\tremaining: 8m 12s\n",
      "895:\tlearn: 1.1259496\ttest: 1.2554053\tbest: 1.2554053 (895)\ttotal: 1m 47s\tremaining: 8m 12s\n",
      "896:\ttotal: 1m 47s\tremaining: 8m 12s\n",
      "897:\ttotal: 1m 47s\tremaining: 8m 12s\n",
      "898:\ttotal: 1m 47s\tremaining: 8m 12s\n",
      "899:\ttotal: 1m 48s\tremaining: 8m 12s\n",
      "900:\tlearn: 1.1242826\ttest: 1.2544067\tbest: 1.2544067 (900)\ttotal: 1m 48s\tremaining: 8m 12s\n",
      "901:\ttotal: 1m 48s\tremaining: 8m 12s\n",
      "902:\ttotal: 1m 48s\tremaining: 8m 11s\n",
      "903:\ttotal: 1m 48s\tremaining: 8m 11s\n",
      "904:\ttotal: 1m 48s\tremaining: 8m 11s\n",
      "905:\tlearn: 1.1225216\ttest: 1.2530257\tbest: 1.2530257 (905)\ttotal: 1m 48s\tremaining: 8m 11s\n",
      "906:\ttotal: 1m 48s\tremaining: 8m 11s\n",
      "907:\ttotal: 1m 48s\tremaining: 8m 11s\n",
      "908:\ttotal: 1m 49s\tremaining: 8m 10s\n",
      "909:\ttotal: 1m 49s\tremaining: 8m 10s\n",
      "910:\tlearn: 1.1207808\ttest: 1.2520232\tbest: 1.2520232 (910)\ttotal: 1m 49s\tremaining: 8m 10s\n",
      "911:\ttotal: 1m 49s\tremaining: 8m 10s\n",
      "912:\ttotal: 1m 49s\tremaining: 8m 10s\n",
      "913:\ttotal: 1m 49s\tremaining: 8m 10s\n",
      "914:\ttotal: 1m 49s\tremaining: 8m 10s\n",
      "915:\tlearn: 1.1190339\ttest: 1.2508923\tbest: 1.2508923 (915)\ttotal: 1m 49s\tremaining: 8m 10s\n",
      "916:\ttotal: 1m 50s\tremaining: 8m 10s\n",
      "917:\ttotal: 1m 50s\tremaining: 8m 9s\n",
      "918:\ttotal: 1m 50s\tremaining: 8m 9s\n",
      "919:\ttotal: 1m 50s\tremaining: 8m 9s\n",
      "920:\tlearn: 1.1173286\ttest: 1.2498132\tbest: 1.2498132 (920)\ttotal: 1m 50s\tremaining: 8m 9s\n",
      "921:\ttotal: 1m 50s\tremaining: 8m 9s\n",
      "922:\ttotal: 1m 50s\tremaining: 8m 9s\n",
      "923:\ttotal: 1m 50s\tremaining: 8m 9s\n",
      "924:\ttotal: 1m 50s\tremaining: 8m 8s\n",
      "925:\tlearn: 1.1155209\ttest: 1.2487183\tbest: 1.2487183 (925)\ttotal: 1m 51s\tremaining: 8m 8s\n",
      "926:\ttotal: 1m 51s\tremaining: 8m 8s\n",
      "927:\ttotal: 1m 51s\tremaining: 8m 8s\n",
      "928:\ttotal: 1m 51s\tremaining: 8m 8s\n",
      "929:\ttotal: 1m 51s\tremaining: 8m 8s\n",
      "930:\tlearn: 1.1138642\ttest: 1.2478031\tbest: 1.2478031 (930)\ttotal: 1m 51s\tremaining: 8m 8s\n",
      "931:\ttotal: 1m 51s\tremaining: 8m 8s\n",
      "932:\ttotal: 1m 51s\tremaining: 8m 7s\n",
      "933:\ttotal: 1m 52s\tremaining: 8m 7s\n",
      "934:\ttotal: 1m 52s\tremaining: 8m 7s\n",
      "935:\tlearn: 1.1121427\ttest: 1.2467088\tbest: 1.2467088 (935)\ttotal: 1m 52s\tremaining: 8m 7s\n",
      "936:\ttotal: 1m 52s\tremaining: 8m 7s\n",
      "937:\ttotal: 1m 52s\tremaining: 8m 7s\n",
      "938:\ttotal: 1m 52s\tremaining: 8m 7s\n",
      "939:\ttotal: 1m 52s\tremaining: 8m 7s\n",
      "940:\tlearn: 1.1104538\ttest: 1.2455667\tbest: 1.2455667 (940)\ttotal: 1m 52s\tremaining: 8m 7s\n",
      "941:\ttotal: 1m 53s\tremaining: 8m 6s\n",
      "942:\ttotal: 1m 53s\tremaining: 8m 6s\n",
      "943:\ttotal: 1m 53s\tremaining: 8m 6s\n",
      "944:\ttotal: 1m 53s\tremaining: 8m 6s\n",
      "945:\tlearn: 1.1087232\ttest: 1.2445239\tbest: 1.2445239 (945)\ttotal: 1m 53s\tremaining: 8m 6s\n",
      "946:\ttotal: 1m 53s\tremaining: 8m 6s\n",
      "947:\ttotal: 1m 53s\tremaining: 8m 6s\n",
      "948:\ttotal: 1m 53s\tremaining: 8m 5s\n",
      "949:\ttotal: 1m 53s\tremaining: 8m 5s\n",
      "950:\tlearn: 1.1070231\ttest: 1.2433597\tbest: 1.2433597 (950)\ttotal: 1m 54s\tremaining: 8m 5s\n",
      "951:\ttotal: 1m 54s\tremaining: 8m 5s\n",
      "952:\ttotal: 1m 54s\tremaining: 8m 5s\n",
      "953:\ttotal: 1m 54s\tremaining: 8m 5s\n",
      "954:\ttotal: 1m 54s\tremaining: 8m 5s\n",
      "955:\tlearn: 1.1053528\ttest: 1.2423794\tbest: 1.2423794 (955)\ttotal: 1m 54s\tremaining: 8m 5s\n",
      "956:\ttotal: 1m 54s\tremaining: 8m 4s\n",
      "957:\ttotal: 1m 54s\tremaining: 8m 4s\n",
      "958:\ttotal: 1m 55s\tremaining: 8m 4s\n",
      "959:\ttotal: 1m 55s\tremaining: 8m 4s\n",
      "960:\tlearn: 1.1037076\ttest: 1.2412828\tbest: 1.2412828 (960)\ttotal: 1m 55s\tremaining: 8m 4s\n",
      "961:\ttotal: 1m 55s\tremaining: 8m 4s\n",
      "962:\ttotal: 1m 55s\tremaining: 8m 4s\n",
      "963:\ttotal: 1m 55s\tremaining: 8m 4s\n",
      "964:\ttotal: 1m 55s\tremaining: 8m 3s\n",
      "965:\tlearn: 1.1019566\ttest: 1.2402506\tbest: 1.2402506 (965)\ttotal: 1m 55s\tremaining: 8m 3s\n",
      "966:\ttotal: 1m 55s\tremaining: 8m 3s\n",
      "967:\ttotal: 1m 56s\tremaining: 8m 3s\n",
      "968:\ttotal: 1m 56s\tremaining: 8m 3s\n",
      "969:\ttotal: 1m 56s\tremaining: 8m 3s\n",
      "970:\tlearn: 1.1002101\ttest: 1.2390554\tbest: 1.2390554 (970)\ttotal: 1m 56s\tremaining: 8m 3s\n",
      "971:\ttotal: 1m 56s\tremaining: 8m 3s\n",
      "972:\ttotal: 1m 56s\tremaining: 8m 3s\n",
      "973:\ttotal: 1m 56s\tremaining: 8m 2s\n",
      "974:\ttotal: 1m 56s\tremaining: 8m 2s\n",
      "975:\tlearn: 1.0985111\ttest: 1.2379826\tbest: 1.2379826 (975)\ttotal: 1m 57s\tremaining: 8m 2s\n",
      "976:\ttotal: 1m 57s\tremaining: 8m 2s\n",
      "977:\ttotal: 1m 57s\tremaining: 8m 2s\n",
      "978:\ttotal: 1m 57s\tremaining: 8m 2s\n",
      "979:\ttotal: 1m 57s\tremaining: 8m 2s\n",
      "980:\tlearn: 1.0968846\ttest: 1.2370072\tbest: 1.2370072 (980)\ttotal: 1m 57s\tremaining: 8m 2s\n",
      "981:\ttotal: 1m 57s\tremaining: 8m 2s\n",
      "982:\ttotal: 1m 57s\tremaining: 8m 1s\n",
      "983:\ttotal: 1m 58s\tremaining: 8m 1s\n",
      "984:\ttotal: 1m 58s\tremaining: 8m 1s\n",
      "985:\tlearn: 1.0953001\ttest: 1.2359011\tbest: 1.2359011 (985)\ttotal: 1m 58s\tremaining: 8m 1s\n",
      "986:\ttotal: 1m 58s\tremaining: 8m 1s\n",
      "987:\ttotal: 1m 58s\tremaining: 8m 1s\n",
      "988:\ttotal: 1m 58s\tremaining: 8m 1s\n",
      "989:\ttotal: 1m 58s\tremaining: 8m 1s\n",
      "990:\tlearn: 1.0936564\ttest: 1.2349292\tbest: 1.2349292 (990)\ttotal: 1m 58s\tremaining: 8m 1s\n",
      "991:\ttotal: 1m 59s\tremaining: 8m\n",
      "992:\ttotal: 1m 59s\tremaining: 8m\n",
      "993:\ttotal: 1m 59s\tremaining: 8m\n",
      "994:\ttotal: 1m 59s\tremaining: 8m\n",
      "995:\tlearn: 1.0920419\ttest: 1.2338003\tbest: 1.2338003 (995)\ttotal: 1m 59s\tremaining: 8m\n",
      "996:\ttotal: 1m 59s\tremaining: 8m\n",
      "997:\ttotal: 1m 59s\tremaining: 8m\n",
      "998:\ttotal: 1m 59s\tremaining: 8m\n",
      "999:\ttotal: 2m\tremaining: 8m\n",
      "1000:\tlearn: 1.0903789\ttest: 1.2329431\tbest: 1.2329431 (1000)\ttotal: 2m\tremaining: 7m 59s\n",
      "1001:\ttotal: 2m\tremaining: 7m 59s\n",
      "1002:\ttotal: 2m\tremaining: 7m 59s\n",
      "1003:\ttotal: 2m\tremaining: 7m 59s\n",
      "1004:\ttotal: 2m\tremaining: 7m 59s\n",
      "1005:\tlearn: 1.0887359\ttest: 1.2320204\tbest: 1.2320204 (1005)\ttotal: 2m\tremaining: 7m 59s\n",
      "1006:\ttotal: 2m\tremaining: 7m 59s\n",
      "1007:\ttotal: 2m\tremaining: 7m 59s\n",
      "1008:\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "1009:\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "1010:\tlearn: 1.0871032\ttest: 1.2309038\tbest: 1.2309038 (1010)\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "1011:\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "1012:\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "1013:\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "1014:\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "1015:\tlearn: 1.0855276\ttest: 1.2298908\tbest: 1.2298908 (1015)\ttotal: 2m 1s\tremaining: 7m 58s\n",
      "1016:\ttotal: 2m 2s\tremaining: 7m 57s\n",
      "1017:\ttotal: 2m 2s\tremaining: 7m 57s\n",
      "1018:\ttotal: 2m 2s\tremaining: 7m 57s\n",
      "1019:\ttotal: 2m 2s\tremaining: 7m 57s\n",
      "1020:\tlearn: 1.0838621\ttest: 1.2287396\tbest: 1.2287396 (1020)\ttotal: 2m 2s\tremaining: 7m 57s\n",
      "1021:\ttotal: 2m 2s\tremaining: 7m 57s\n",
      "1022:\ttotal: 2m 2s\tremaining: 7m 56s\n",
      "1023:\ttotal: 2m 2s\tremaining: 7m 56s\n",
      "1024:\ttotal: 2m 2s\tremaining: 7m 56s\n",
      "1025:\tlearn: 1.0822413\ttest: 1.2276628\tbest: 1.2276628 (1025)\ttotal: 2m 3s\tremaining: 7m 56s\n",
      "1026:\ttotal: 2m 3s\tremaining: 7m 56s\n",
      "1027:\ttotal: 2m 3s\tremaining: 7m 56s\n",
      "1028:\ttotal: 2m 3s\tremaining: 7m 56s\n",
      "1029:\ttotal: 2m 3s\tremaining: 7m 55s\n",
      "1030:\tlearn: 1.0806369\ttest: 1.2265981\tbest: 1.2265981 (1030)\ttotal: 2m 3s\tremaining: 7m 55s\n",
      "1031:\ttotal: 2m 3s\tremaining: 7m 55s\n",
      "1032:\ttotal: 2m 3s\tremaining: 7m 55s\n",
      "1033:\ttotal: 2m 3s\tremaining: 7m 55s\n",
      "1034:\ttotal: 2m 4s\tremaining: 7m 55s\n",
      "1035:\tlearn: 1.0791568\ttest: 1.2257585\tbest: 1.2257585 (1035)\ttotal: 2m 4s\tremaining: 7m 55s\n",
      "1036:\ttotal: 2m 4s\tremaining: 7m 55s\n",
      "1037:\ttotal: 2m 4s\tremaining: 7m 55s\n",
      "1038:\ttotal: 2m 4s\tremaining: 7m 54s\n",
      "1039:\ttotal: 2m 4s\tremaining: 7m 54s\n",
      "1040:\tlearn: 1.0776021\ttest: 1.2247663\tbest: 1.2247663 (1040)\ttotal: 2m 4s\tremaining: 7m 54s\n",
      "1041:\ttotal: 2m 4s\tremaining: 7m 54s\n",
      "1042:\ttotal: 2m 5s\tremaining: 7m 54s\n",
      "1043:\ttotal: 2m 5s\tremaining: 7m 54s\n",
      "1044:\ttotal: 2m 5s\tremaining: 7m 54s\n",
      "1045:\tlearn: 1.0761536\ttest: 1.2239428\tbest: 1.2239428 (1045)\ttotal: 2m 5s\tremaining: 7m 54s\n",
      "1046:\ttotal: 2m 5s\tremaining: 7m 54s\n",
      "1047:\ttotal: 2m 5s\tremaining: 7m 54s\n",
      "1048:\ttotal: 2m 5s\tremaining: 7m 54s\n",
      "1049:\ttotal: 2m 5s\tremaining: 7m 53s\n",
      "1050:\tlearn: 1.0747185\ttest: 1.2229950\tbest: 1.2229950 (1050)\ttotal: 2m 6s\tremaining: 7m 53s\n",
      "1051:\ttotal: 2m 6s\tremaining: 7m 53s\n",
      "1052:\ttotal: 2m 6s\tremaining: 7m 53s\n",
      "1053:\ttotal: 2m 6s\tremaining: 7m 53s\n",
      "1054:\ttotal: 2m 6s\tremaining: 7m 53s\n",
      "1055:\tlearn: 1.0731670\ttest: 1.2220157\tbest: 1.2220157 (1055)\ttotal: 2m 6s\tremaining: 7m 53s\n",
      "1056:\ttotal: 2m 6s\tremaining: 7m 52s\n",
      "1057:\ttotal: 2m 6s\tremaining: 7m 52s\n",
      "1058:\ttotal: 2m 7s\tremaining: 7m 52s\n",
      "1059:\ttotal: 2m 7s\tremaining: 7m 52s\n",
      "1060:\tlearn: 1.0716613\ttest: 1.2212098\tbest: 1.2212098 (1060)\ttotal: 2m 7s\tremaining: 7m 52s\n",
      "1061:\ttotal: 2m 7s\tremaining: 7m 52s\n",
      "1062:\ttotal: 2m 7s\tremaining: 7m 52s\n",
      "1063:\ttotal: 2m 7s\tremaining: 7m 52s\n",
      "1064:\ttotal: 2m 7s\tremaining: 7m 52s\n",
      "1065:\tlearn: 1.0701432\ttest: 1.2203896\tbest: 1.2203896 (1065)\ttotal: 2m 7s\tremaining: 7m 51s\n",
      "1066:\ttotal: 2m 7s\tremaining: 7m 51s\n",
      "1067:\ttotal: 2m 8s\tremaining: 7m 51s\n",
      "1068:\ttotal: 2m 8s\tremaining: 7m 51s\n",
      "1069:\ttotal: 2m 8s\tremaining: 7m 51s\n",
      "1070:\tlearn: 1.0686760\ttest: 1.2194518\tbest: 1.2194518 (1070)\ttotal: 2m 8s\tremaining: 7m 51s\n",
      "1071:\ttotal: 2m 8s\tremaining: 7m 51s\n",
      "1072:\ttotal: 2m 8s\tremaining: 7m 51s\n",
      "1073:\ttotal: 2m 8s\tremaining: 7m 51s\n",
      "1074:\ttotal: 2m 8s\tremaining: 7m 50s\n",
      "1075:\tlearn: 1.0671752\ttest: 1.2186115\tbest: 1.2186115 (1075)\ttotal: 2m 9s\tremaining: 7m 50s\n",
      "1076:\ttotal: 2m 9s\tremaining: 7m 50s\n",
      "1077:\ttotal: 2m 9s\tremaining: 7m 50s\n",
      "1078:\ttotal: 2m 9s\tremaining: 7m 50s\n",
      "1079:\ttotal: 2m 9s\tremaining: 7m 50s\n",
      "1080:\tlearn: 1.0657081\ttest: 1.2175887\tbest: 1.2175887 (1080)\ttotal: 2m 9s\tremaining: 7m 50s\n",
      "1081:\ttotal: 2m 9s\tremaining: 7m 49s\n",
      "1082:\ttotal: 2m 9s\tremaining: 7m 49s\n",
      "1083:\ttotal: 2m 10s\tremaining: 7m 49s\n",
      "1084:\ttotal: 2m 10s\tremaining: 7m 49s\n",
      "1085:\tlearn: 1.0642608\ttest: 1.2167820\tbest: 1.2167820 (1085)\ttotal: 2m 10s\tremaining: 7m 49s\n",
      "1086:\ttotal: 2m 10s\tremaining: 7m 49s\n",
      "1087:\ttotal: 2m 10s\tremaining: 7m 49s\n",
      "1088:\ttotal: 2m 10s\tremaining: 7m 49s\n",
      "1089:\ttotal: 2m 10s\tremaining: 7m 49s\n",
      "1090:\tlearn: 1.0626503\ttest: 1.2158384\tbest: 1.2158384 (1090)\ttotal: 2m 10s\tremaining: 7m 48s\n",
      "1091:\ttotal: 2m 10s\tremaining: 7m 48s\n",
      "1092:\ttotal: 2m 11s\tremaining: 7m 48s\n",
      "1093:\ttotal: 2m 11s\tremaining: 7m 48s\n",
      "1094:\ttotal: 2m 11s\tremaining: 7m 48s\n",
      "1095:\tlearn: 1.0611248\ttest: 1.2148582\tbest: 1.2148582 (1095)\ttotal: 2m 11s\tremaining: 7m 48s\n",
      "1096:\ttotal: 2m 11s\tremaining: 7m 48s\n",
      "1097:\ttotal: 2m 11s\tremaining: 7m 48s\n",
      "1098:\ttotal: 2m 11s\tremaining: 7m 47s\n",
      "1099:\ttotal: 2m 11s\tremaining: 7m 47s\n",
      "1100:\tlearn: 1.0595346\ttest: 1.2137435\tbest: 1.2137435 (1100)\ttotal: 2m 12s\tremaining: 7m 47s\n",
      "1101:\ttotal: 2m 12s\tremaining: 7m 47s\n",
      "1102:\ttotal: 2m 12s\tremaining: 7m 47s\n",
      "1103:\ttotal: 2m 12s\tremaining: 7m 47s\n",
      "1104:\ttotal: 2m 12s\tremaining: 7m 47s\n",
      "1105:\tlearn: 1.0580087\ttest: 1.2128800\tbest: 1.2128800 (1105)\ttotal: 2m 12s\tremaining: 7m 47s\n",
      "1106:\ttotal: 2m 12s\tremaining: 7m 46s\n",
      "1107:\ttotal: 2m 12s\tremaining: 7m 46s\n",
      "1108:\ttotal: 2m 13s\tremaining: 7m 46s\n",
      "1109:\ttotal: 2m 13s\tremaining: 7m 46s\n",
      "1110:\tlearn: 1.0565325\ttest: 1.2120318\tbest: 1.2120318 (1110)\ttotal: 2m 13s\tremaining: 7m 46s\n",
      "1111:\ttotal: 2m 13s\tremaining: 7m 46s\n",
      "1112:\ttotal: 2m 13s\tremaining: 7m 46s\n",
      "1113:\ttotal: 2m 13s\tremaining: 7m 46s\n",
      "1114:\ttotal: 2m 13s\tremaining: 7m 45s\n",
      "1115:\tlearn: 1.0550517\ttest: 1.2111964\tbest: 1.2111964 (1115)\ttotal: 2m 13s\tremaining: 7m 45s\n",
      "1116:\ttotal: 2m 13s\tremaining: 7m 45s\n",
      "1117:\ttotal: 2m 14s\tremaining: 7m 45s\n",
      "1118:\ttotal: 2m 14s\tremaining: 7m 45s\n",
      "1119:\ttotal: 2m 14s\tremaining: 7m 45s\n",
      "1120:\tlearn: 1.0536188\ttest: 1.2103485\tbest: 1.2103485 (1120)\ttotal: 2m 14s\tremaining: 7m 45s\n",
      "1121:\ttotal: 2m 14s\tremaining: 7m 45s\n",
      "1122:\ttotal: 2m 14s\tremaining: 7m 45s\n",
      "1123:\ttotal: 2m 14s\tremaining: 7m 45s\n",
      "1124:\ttotal: 2m 14s\tremaining: 7m 44s\n",
      "1125:\tlearn: 1.0520815\ttest: 1.2094750\tbest: 1.2094750 (1125)\ttotal: 2m 15s\tremaining: 7m 44s\n",
      "1126:\ttotal: 2m 15s\tremaining: 7m 44s\n",
      "1127:\ttotal: 2m 15s\tremaining: 7m 44s\n",
      "1128:\ttotal: 2m 15s\tremaining: 7m 44s\n",
      "1129:\ttotal: 2m 15s\tremaining: 7m 44s\n",
      "1130:\tlearn: 1.0505862\ttest: 1.2085940\tbest: 1.2085940 (1130)\ttotal: 2m 15s\tremaining: 7m 44s\n",
      "1131:\ttotal: 2m 15s\tremaining: 7m 44s\n",
      "1132:\ttotal: 2m 15s\tremaining: 7m 43s\n",
      "1133:\ttotal: 2m 16s\tremaining: 7m 43s\n",
      "1134:\ttotal: 2m 16s\tremaining: 7m 43s\n",
      "1135:\tlearn: 1.0491248\ttest: 1.2077318\tbest: 1.2077318 (1135)\ttotal: 2m 16s\tremaining: 7m 43s\n",
      "1136:\ttotal: 2m 16s\tremaining: 7m 43s\n",
      "1137:\ttotal: 2m 16s\tremaining: 7m 43s\n",
      "1138:\ttotal: 2m 16s\tremaining: 7m 43s\n",
      "1139:\ttotal: 2m 16s\tremaining: 7m 43s\n",
      "1140:\tlearn: 1.0475654\ttest: 1.2068986\tbest: 1.2068986 (1140)\ttotal: 2m 16s\tremaining: 7m 43s\n",
      "1141:\ttotal: 2m 17s\tremaining: 7m 42s\n",
      "1142:\ttotal: 2m 17s\tremaining: 7m 42s\n",
      "1143:\ttotal: 2m 17s\tremaining: 7m 42s\n",
      "1144:\ttotal: 2m 17s\tremaining: 7m 42s\n",
      "1145:\tlearn: 1.0461587\ttest: 1.2060513\tbest: 1.2060513 (1145)\ttotal: 2m 17s\tremaining: 7m 42s\n",
      "1146:\ttotal: 2m 17s\tremaining: 7m 42s\n",
      "1147:\ttotal: 2m 17s\tremaining: 7m 42s\n",
      "1148:\ttotal: 2m 17s\tremaining: 7m 42s\n",
      "1149:\ttotal: 2m 17s\tremaining: 7m 41s\n",
      "1150:\tlearn: 1.0446619\ttest: 1.2052645\tbest: 1.2052645 (1150)\ttotal: 2m 18s\tremaining: 7m 41s\n",
      "1151:\ttotal: 2m 18s\tremaining: 7m 41s\n",
      "1152:\ttotal: 2m 18s\tremaining: 7m 41s\n",
      "1153:\ttotal: 2m 18s\tremaining: 7m 41s\n",
      "1154:\ttotal: 2m 18s\tremaining: 7m 41s\n",
      "1155:\tlearn: 1.0431805\ttest: 1.2043109\tbest: 1.2043109 (1155)\ttotal: 2m 18s\tremaining: 7m 41s\n",
      "1156:\ttotal: 2m 18s\tremaining: 7m 41s\n",
      "1157:\ttotal: 2m 18s\tremaining: 7m 41s\n",
      "1158:\ttotal: 2m 19s\tremaining: 7m 40s\n",
      "1159:\ttotal: 2m 19s\tremaining: 7m 40s\n",
      "1160:\tlearn: 1.0417478\ttest: 1.2035028\tbest: 1.2035028 (1160)\ttotal: 2m 19s\tremaining: 7m 40s\n",
      "1161:\ttotal: 2m 19s\tremaining: 7m 40s\n",
      "1162:\ttotal: 2m 19s\tremaining: 7m 40s\n",
      "1163:\ttotal: 2m 19s\tremaining: 7m 40s\n",
      "1164:\ttotal: 2m 19s\tremaining: 7m 39s\n",
      "1165:\tlearn: 1.0402348\ttest: 1.2025562\tbest: 1.2025562 (1165)\ttotal: 2m 19s\tremaining: 7m 39s\n",
      "1166:\ttotal: 2m 19s\tremaining: 7m 39s\n",
      "1167:\ttotal: 2m 20s\tremaining: 7m 39s\n",
      "1168:\ttotal: 2m 20s\tremaining: 7m 39s\n",
      "1169:\ttotal: 2m 20s\tremaining: 7m 39s\n",
      "1170:\tlearn: 1.0388080\ttest: 1.2017649\tbest: 1.2017649 (1170)\ttotal: 2m 20s\tremaining: 7m 39s\n",
      "1171:\ttotal: 2m 20s\tremaining: 7m 39s\n",
      "1172:\ttotal: 2m 20s\tremaining: 7m 38s\n",
      "1173:\ttotal: 2m 20s\tremaining: 7m 38s\n",
      "1174:\ttotal: 2m 20s\tremaining: 7m 38s\n",
      "1175:\tlearn: 1.0372881\ttest: 1.2007160\tbest: 1.2007160 (1175)\ttotal: 2m 21s\tremaining: 7m 38s\n",
      "1176:\ttotal: 2m 21s\tremaining: 7m 38s\n",
      "1177:\ttotal: 2m 21s\tremaining: 7m 38s\n",
      "1178:\ttotal: 2m 21s\tremaining: 7m 38s\n",
      "1179:\ttotal: 2m 21s\tremaining: 7m 38s\n",
      "1180:\tlearn: 1.0359515\ttest: 1.1999366\tbest: 1.1999366 (1180)\ttotal: 2m 21s\tremaining: 7m 37s\n",
      "1181:\ttotal: 2m 21s\tremaining: 7m 37s\n",
      "1182:\ttotal: 2m 21s\tremaining: 7m 37s\n",
      "1183:\ttotal: 2m 21s\tremaining: 7m 37s\n",
      "1184:\ttotal: 2m 22s\tremaining: 7m 37s\n",
      "1185:\tlearn: 1.0344005\ttest: 1.1990011\tbest: 1.1990011 (1185)\ttotal: 2m 22s\tremaining: 7m 37s\n",
      "1186:\ttotal: 2m 22s\tremaining: 7m 37s\n",
      "1187:\ttotal: 2m 22s\tremaining: 7m 36s\n",
      "1188:\ttotal: 2m 22s\tremaining: 7m 36s\n",
      "1189:\ttotal: 2m 22s\tremaining: 7m 36s\n",
      "1190:\tlearn: 1.0329267\ttest: 1.1981263\tbest: 1.1981263 (1190)\ttotal: 2m 22s\tremaining: 7m 36s\n",
      "1191:\ttotal: 2m 22s\tremaining: 7m 36s\n",
      "1192:\ttotal: 2m 23s\tremaining: 7m 36s\n",
      "1193:\ttotal: 2m 23s\tremaining: 7m 36s\n",
      "1194:\ttotal: 2m 23s\tremaining: 7m 36s\n",
      "1195:\tlearn: 1.0314382\ttest: 1.1972694\tbest: 1.1972694 (1195)\ttotal: 2m 23s\tremaining: 7m 35s\n",
      "1196:\ttotal: 2m 23s\tremaining: 7m 35s\n",
      "1197:\ttotal: 2m 23s\tremaining: 7m 35s\n",
      "1198:\ttotal: 2m 23s\tremaining: 7m 35s\n",
      "1199:\ttotal: 2m 23s\tremaining: 7m 35s\n",
      "1200:\tlearn: 1.0299893\ttest: 1.1965220\tbest: 1.1965220 (1200)\ttotal: 2m 23s\tremaining: 7m 35s\n",
      "1201:\ttotal: 2m 24s\tremaining: 7m 35s\n",
      "1202:\ttotal: 2m 24s\tremaining: 7m 35s\n",
      "1203:\ttotal: 2m 24s\tremaining: 7m 35s\n",
      "1204:\ttotal: 2m 24s\tremaining: 7m 34s\n",
      "1205:\tlearn: 1.0285634\ttest: 1.1957584\tbest: 1.1957584 (1205)\ttotal: 2m 24s\tremaining: 7m 34s\n",
      "1206:\ttotal: 2m 24s\tremaining: 7m 34s\n",
      "1207:\ttotal: 2m 24s\tremaining: 7m 34s\n",
      "1208:\ttotal: 2m 24s\tremaining: 7m 34s\n",
      "1209:\ttotal: 2m 25s\tremaining: 7m 34s\n",
      "1210:\tlearn: 1.0271479\ttest: 1.1948294\tbest: 1.1948294 (1210)\ttotal: 2m 25s\tremaining: 7m 34s\n",
      "1211:\ttotal: 2m 25s\tremaining: 7m 33s\n",
      "1212:\ttotal: 2m 25s\tremaining: 7m 33s\n",
      "1213:\ttotal: 2m 25s\tremaining: 7m 33s\n",
      "1214:\ttotal: 2m 25s\tremaining: 7m 33s\n",
      "1215:\tlearn: 1.0257498\ttest: 1.1941102\tbest: 1.1941102 (1215)\ttotal: 2m 25s\tremaining: 7m 33s\n",
      "1216:\ttotal: 2m 25s\tremaining: 7m 33s\n",
      "1217:\ttotal: 2m 25s\tremaining: 7m 33s\n",
      "1218:\ttotal: 2m 26s\tremaining: 7m 33s\n",
      "1219:\ttotal: 2m 26s\tremaining: 7m 32s\n",
      "1220:\tlearn: 1.0242546\ttest: 1.1933492\tbest: 1.1933492 (1220)\ttotal: 2m 26s\tremaining: 7m 32s\n",
      "1221:\ttotal: 2m 26s\tremaining: 7m 32s\n",
      "1222:\ttotal: 2m 26s\tremaining: 7m 32s\n",
      "1223:\ttotal: 2m 26s\tremaining: 7m 32s\n",
      "1224:\ttotal: 2m 26s\tremaining: 7m 32s\n",
      "1225:\tlearn: 1.0229744\ttest: 1.1926999\tbest: 1.1926999 (1225)\ttotal: 2m 26s\tremaining: 7m 32s\n",
      "1226:\ttotal: 2m 27s\tremaining: 7m 32s\n",
      "1227:\ttotal: 2m 27s\tremaining: 7m 32s\n",
      "1228:\ttotal: 2m 27s\tremaining: 7m 31s\n",
      "1229:\ttotal: 2m 27s\tremaining: 7m 31s\n",
      "1230:\tlearn: 1.0215487\ttest: 1.1919548\tbest: 1.1919548 (1230)\ttotal: 2m 27s\tremaining: 7m 31s\n",
      "1231:\ttotal: 2m 27s\tremaining: 7m 31s\n",
      "1232:\ttotal: 2m 27s\tremaining: 7m 31s\n",
      "1233:\ttotal: 2m 27s\tremaining: 7m 31s\n",
      "1234:\ttotal: 2m 27s\tremaining: 7m 31s\n",
      "1235:\tlearn: 1.0201414\ttest: 1.1913366\tbest: 1.1913366 (1235)\ttotal: 2m 28s\tremaining: 7m 31s\n",
      "1236:\ttotal: 2m 28s\tremaining: 7m 30s\n",
      "1237:\ttotal: 2m 28s\tremaining: 7m 30s\n",
      "1238:\ttotal: 2m 28s\tremaining: 7m 30s\n",
      "1239:\ttotal: 2m 28s\tremaining: 7m 30s\n",
      "1240:\tlearn: 1.0188028\ttest: 1.1905327\tbest: 1.1905327 (1240)\ttotal: 2m 28s\tremaining: 7m 30s\n",
      "1241:\ttotal: 2m 28s\tremaining: 7m 30s\n",
      "1242:\ttotal: 2m 28s\tremaining: 7m 30s\n",
      "1243:\ttotal: 2m 29s\tremaining: 7m 29s\n",
      "1244:\ttotal: 2m 29s\tremaining: 7m 29s\n",
      "1245:\tlearn: 1.0174289\ttest: 1.1896306\tbest: 1.1896306 (1245)\ttotal: 2m 29s\tremaining: 7m 29s\n",
      "1246:\ttotal: 2m 29s\tremaining: 7m 29s\n",
      "1247:\ttotal: 2m 29s\tremaining: 7m 29s\n",
      "1248:\ttotal: 2m 29s\tremaining: 7m 29s\n",
      "1249:\ttotal: 2m 29s\tremaining: 7m 29s\n",
      "1250:\tlearn: 1.0161499\ttest: 1.1888085\tbest: 1.1888085 (1250)\ttotal: 2m 29s\tremaining: 7m 29s\n",
      "1251:\ttotal: 2m 29s\tremaining: 7m 28s\n",
      "1252:\ttotal: 2m 30s\tremaining: 7m 28s\n",
      "1253:\ttotal: 2m 30s\tremaining: 7m 28s\n",
      "1254:\ttotal: 2m 30s\tremaining: 7m 28s\n",
      "1255:\tlearn: 1.0148440\ttest: 1.1880982\tbest: 1.1880982 (1255)\ttotal: 2m 30s\tremaining: 7m 28s\n",
      "1256:\ttotal: 2m 30s\tremaining: 7m 28s\n",
      "1257:\ttotal: 2m 30s\tremaining: 7m 28s\n",
      "1258:\ttotal: 2m 30s\tremaining: 7m 27s\n",
      "1259:\ttotal: 2m 30s\tremaining: 7m 27s\n",
      "1260:\tlearn: 1.0134153\ttest: 1.1871937\tbest: 1.1871937 (1260)\ttotal: 2m 30s\tremaining: 7m 27s\n",
      "1261:\ttotal: 2m 31s\tremaining: 7m 27s\n",
      "1262:\ttotal: 2m 31s\tremaining: 7m 27s\n",
      "1263:\ttotal: 2m 31s\tremaining: 7m 27s\n",
      "1264:\ttotal: 2m 31s\tremaining: 7m 27s\n",
      "1265:\tlearn: 1.0121255\ttest: 1.1864922\tbest: 1.1864922 (1265)\ttotal: 2m 31s\tremaining: 7m 27s\n",
      "1266:\ttotal: 2m 31s\tremaining: 7m 26s\n",
      "1267:\ttotal: 2m 31s\tremaining: 7m 26s\n",
      "1268:\ttotal: 2m 31s\tremaining: 7m 26s\n",
      "1269:\ttotal: 2m 32s\tremaining: 7m 26s\n",
      "1270:\tlearn: 1.0107507\ttest: 1.1856444\tbest: 1.1856444 (1270)\ttotal: 2m 32s\tremaining: 7m 26s\n",
      "1271:\ttotal: 2m 32s\tremaining: 7m 26s\n",
      "1272:\ttotal: 2m 32s\tremaining: 7m 26s\n",
      "1273:\ttotal: 2m 32s\tremaining: 7m 25s\n",
      "1274:\ttotal: 2m 32s\tremaining: 7m 25s\n",
      "1275:\tlearn: 1.0094339\ttest: 1.1848262\tbest: 1.1848262 (1275)\ttotal: 2m 32s\tremaining: 7m 25s\n",
      "1276:\ttotal: 2m 32s\tremaining: 7m 25s\n",
      "1277:\ttotal: 2m 32s\tremaining: 7m 25s\n",
      "1278:\ttotal: 2m 33s\tremaining: 7m 25s\n",
      "1279:\ttotal: 2m 33s\tremaining: 7m 25s\n",
      "1280:\tlearn: 1.0080204\ttest: 1.1841396\tbest: 1.1841396 (1280)\ttotal: 2m 33s\tremaining: 7m 24s\n",
      "1281:\ttotal: 2m 33s\tremaining: 7m 24s\n",
      "1282:\ttotal: 2m 33s\tremaining: 7m 24s\n",
      "1283:\ttotal: 2m 33s\tremaining: 7m 24s\n",
      "1284:\ttotal: 2m 33s\tremaining: 7m 24s\n",
      "1285:\tlearn: 1.0066738\ttest: 1.1833834\tbest: 1.1833834 (1285)\ttotal: 2m 33s\tremaining: 7m 24s\n",
      "1286:\ttotal: 2m 33s\tremaining: 7m 24s\n",
      "1287:\ttotal: 2m 34s\tremaining: 7m 24s\n",
      "1288:\ttotal: 2m 34s\tremaining: 7m 23s\n",
      "1289:\ttotal: 2m 34s\tremaining: 7m 23s\n",
      "1290:\tlearn: 1.0054072\ttest: 1.1827271\tbest: 1.1827271 (1290)\ttotal: 2m 34s\tremaining: 7m 23s\n",
      "1291:\ttotal: 2m 34s\tremaining: 7m 23s\n",
      "1292:\ttotal: 2m 34s\tremaining: 7m 23s\n",
      "1293:\ttotal: 2m 34s\tremaining: 7m 23s\n",
      "1294:\ttotal: 2m 34s\tremaining: 7m 23s\n",
      "1295:\tlearn: 1.0040667\ttest: 1.1818621\tbest: 1.1818621 (1295)\ttotal: 2m 35s\tremaining: 7m 23s\n",
      "1296:\ttotal: 2m 35s\tremaining: 7m 23s\n",
      "1297:\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1298:\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1299:\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1300:\tlearn: 1.0027063\ttest: 1.1811317\tbest: 1.1811317 (1300)\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1301:\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1302:\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1303:\ttotal: 2m 35s\tremaining: 7m 22s\n",
      "1304:\ttotal: 2m 36s\tremaining: 7m 22s\n",
      "1305:\tlearn: 1.0013772\ttest: 1.1804051\tbest: 1.1804051 (1305)\ttotal: 2m 36s\tremaining: 7m 21s\n",
      "1306:\ttotal: 2m 36s\tremaining: 7m 21s\n",
      "1307:\ttotal: 2m 36s\tremaining: 7m 21s\n",
      "1308:\ttotal: 2m 36s\tremaining: 7m 21s\n",
      "1309:\ttotal: 2m 36s\tremaining: 7m 21s\n",
      "1310:\tlearn: 1.0001344\ttest: 1.1796654\tbest: 1.1796654 (1310)\ttotal: 2m 36s\tremaining: 7m 21s\n",
      "1311:\ttotal: 2m 36s\tremaining: 7m 21s\n",
      "1312:\ttotal: 2m 37s\tremaining: 7m 21s\n",
      "1313:\ttotal: 2m 37s\tremaining: 7m 21s\n",
      "1314:\ttotal: 2m 37s\tremaining: 7m 20s\n",
      "1315:\tlearn: 0.9988778\ttest: 1.1790334\tbest: 1.1790334 (1315)\ttotal: 2m 37s\tremaining: 7m 20s\n",
      "1316:\ttotal: 2m 37s\tremaining: 7m 20s\n",
      "1317:\ttotal: 2m 37s\tremaining: 7m 20s\n",
      "1318:\ttotal: 2m 37s\tremaining: 7m 20s\n",
      "1319:\ttotal: 2m 37s\tremaining: 7m 20s\n",
      "1320:\tlearn: 0.9975710\ttest: 1.1782833\tbest: 1.1782833 (1320)\ttotal: 2m 38s\tremaining: 7m 20s\n",
      "1321:\ttotal: 2m 38s\tremaining: 7m 19s\n",
      "1322:\ttotal: 2m 38s\tremaining: 7m 19s\n",
      "1323:\ttotal: 2m 38s\tremaining: 7m 19s\n",
      "1324:\ttotal: 2m 38s\tremaining: 7m 19s\n",
      "1325:\tlearn: 0.9962743\ttest: 1.1774284\tbest: 1.1774284 (1325)\ttotal: 2m 38s\tremaining: 7m 19s\n",
      "1326:\ttotal: 2m 38s\tremaining: 7m 19s\n",
      "1327:\ttotal: 2m 38s\tremaining: 7m 19s\n",
      "1328:\ttotal: 2m 38s\tremaining: 7m 18s\n",
      "1329:\ttotal: 2m 38s\tremaining: 7m 18s\n",
      "1330:\tlearn: 0.9949524\ttest: 1.1765331\tbest: 1.1765331 (1330)\ttotal: 2m 39s\tremaining: 7m 18s\n",
      "1331:\ttotal: 2m 39s\tremaining: 7m 18s\n",
      "1332:\ttotal: 2m 39s\tremaining: 7m 18s\n",
      "1333:\ttotal: 2m 39s\tremaining: 7m 18s\n",
      "1334:\ttotal: 2m 39s\tremaining: 7m 17s\n",
      "1335:\tlearn: 0.9936468\ttest: 1.1755917\tbest: 1.1755917 (1335)\ttotal: 2m 39s\tremaining: 7m 17s\n",
      "1336:\ttotal: 2m 39s\tremaining: 7m 17s\n",
      "1337:\ttotal: 2m 39s\tremaining: 7m 17s\n",
      "1338:\ttotal: 2m 39s\tremaining: 7m 17s\n",
      "1339:\ttotal: 2m 40s\tremaining: 7m 17s\n",
      "1340:\tlearn: 0.9923275\ttest: 1.1747250\tbest: 1.1747250 (1340)\ttotal: 2m 40s\tremaining: 7m 17s\n",
      "1341:\ttotal: 2m 40s\tremaining: 7m 17s\n",
      "1342:\ttotal: 2m 40s\tremaining: 7m 16s\n",
      "1343:\ttotal: 2m 40s\tremaining: 7m 16s\n",
      "1344:\ttotal: 2m 40s\tremaining: 7m 16s\n",
      "1345:\tlearn: 0.9910631\ttest: 1.1739807\tbest: 1.1739807 (1345)\ttotal: 2m 40s\tremaining: 7m 16s\n",
      "1346:\ttotal: 2m 40s\tremaining: 7m 16s\n",
      "1347:\ttotal: 2m 41s\tremaining: 7m 16s\n",
      "1348:\ttotal: 2m 41s\tremaining: 7m 16s\n",
      "1349:\ttotal: 2m 41s\tremaining: 7m 15s\n",
      "1350:\tlearn: 0.9898127\ttest: 1.1733706\tbest: 1.1733706 (1350)\ttotal: 2m 41s\tremaining: 7m 15s\n",
      "1351:\ttotal: 2m 41s\tremaining: 7m 15s\n",
      "1352:\ttotal: 2m 41s\tremaining: 7m 15s\n",
      "1353:\ttotal: 2m 41s\tremaining: 7m 15s\n",
      "1354:\ttotal: 2m 41s\tremaining: 7m 15s\n",
      "1355:\tlearn: 0.9885421\ttest: 1.1727516\tbest: 1.1727516 (1355)\ttotal: 2m 41s\tremaining: 7m 15s\n",
      "1356:\ttotal: 2m 42s\tremaining: 7m 14s\n",
      "1357:\ttotal: 2m 42s\tremaining: 7m 14s\n",
      "1358:\ttotal: 2m 42s\tremaining: 7m 14s\n",
      "1359:\ttotal: 2m 42s\tremaining: 7m 14s\n",
      "1360:\tlearn: 0.9872136\ttest: 1.1719580\tbest: 1.1719580 (1360)\ttotal: 2m 42s\tremaining: 7m 14s\n",
      "1361:\ttotal: 2m 42s\tremaining: 7m 14s\n",
      "1362:\ttotal: 2m 42s\tremaining: 7m 14s\n",
      "1363:\ttotal: 2m 42s\tremaining: 7m 14s\n",
      "1364:\ttotal: 2m 42s\tremaining: 7m 13s\n",
      "1365:\tlearn: 0.9859311\ttest: 1.1713091\tbest: 1.1713091 (1365)\ttotal: 2m 43s\tremaining: 7m 13s\n",
      "1366:\ttotal: 2m 43s\tremaining: 7m 13s\n",
      "1367:\ttotal: 2m 43s\tremaining: 7m 13s\n",
      "1368:\ttotal: 2m 43s\tremaining: 7m 13s\n",
      "1369:\ttotal: 2m 43s\tremaining: 7m 13s\n",
      "1370:\tlearn: 0.9846842\ttest: 1.1706213\tbest: 1.1706213 (1370)\ttotal: 2m 43s\tremaining: 7m 13s\n",
      "1371:\ttotal: 2m 43s\tremaining: 7m 13s\n",
      "1372:\ttotal: 2m 43s\tremaining: 7m 12s\n",
      "1373:\ttotal: 2m 44s\tremaining: 7m 12s\n",
      "1374:\ttotal: 2m 44s\tremaining: 7m 12s\n",
      "1375:\tlearn: 0.9833829\ttest: 1.1697979\tbest: 1.1697979 (1375)\ttotal: 2m 44s\tremaining: 7m 12s\n",
      "1376:\ttotal: 2m 44s\tremaining: 7m 12s\n",
      "1377:\ttotal: 2m 44s\tremaining: 7m 12s\n",
      "1378:\ttotal: 2m 44s\tremaining: 7m 12s\n",
      "1379:\ttotal: 2m 44s\tremaining: 7m 12s\n",
      "1380:\tlearn: 0.9821096\ttest: 1.1690594\tbest: 1.1690594 (1380)\ttotal: 2m 44s\tremaining: 7m 11s\n",
      "1381:\ttotal: 2m 44s\tremaining: 7m 11s\n",
      "1382:\ttotal: 2m 45s\tremaining: 7m 11s\n",
      "1383:\ttotal: 2m 45s\tremaining: 7m 11s\n",
      "1384:\ttotal: 2m 45s\tremaining: 7m 11s\n",
      "1385:\tlearn: 0.9808652\ttest: 1.1682548\tbest: 1.1682548 (1385)\ttotal: 2m 45s\tremaining: 7m 11s\n",
      "1386:\ttotal: 2m 45s\tremaining: 7m 11s\n",
      "1387:\ttotal: 2m 45s\tremaining: 7m 10s\n",
      "1388:\ttotal: 2m 45s\tremaining: 7m 10s\n",
      "1389:\ttotal: 2m 45s\tremaining: 7m 10s\n",
      "1390:\tlearn: 0.9795405\ttest: 1.1675984\tbest: 1.1675984 (1390)\ttotal: 2m 45s\tremaining: 7m 10s\n",
      "1391:\ttotal: 2m 46s\tremaining: 7m 10s\n",
      "1392:\ttotal: 2m 46s\tremaining: 7m 10s\n",
      "1393:\ttotal: 2m 46s\tremaining: 7m 10s\n",
      "1394:\ttotal: 2m 46s\tremaining: 7m 9s\n",
      "1395:\tlearn: 0.9783264\ttest: 1.1669709\tbest: 1.1669709 (1395)\ttotal: 2m 46s\tremaining: 7m 9s\n",
      "1396:\ttotal: 2m 46s\tremaining: 7m 9s\n",
      "1397:\ttotal: 2m 46s\tremaining: 7m 9s\n",
      "1398:\ttotal: 2m 46s\tremaining: 7m 9s\n",
      "1399:\ttotal: 2m 46s\tremaining: 7m 9s\n",
      "1400:\tlearn: 0.9770356\ttest: 1.1661124\tbest: 1.1661124 (1400)\ttotal: 2m 47s\tremaining: 7m 9s\n",
      "1401:\ttotal: 2m 47s\tremaining: 7m 9s\n",
      "1402:\ttotal: 2m 47s\tremaining: 7m 8s\n",
      "1403:\ttotal: 2m 47s\tremaining: 7m 8s\n",
      "1404:\ttotal: 2m 47s\tremaining: 7m 8s\n",
      "1405:\tlearn: 0.9758221\ttest: 1.1653338\tbest: 1.1653338 (1405)\ttotal: 2m 47s\tremaining: 7m 8s\n",
      "1406:\ttotal: 2m 47s\tremaining: 7m 8s\n",
      "1407:\ttotal: 2m 47s\tremaining: 7m 8s\n",
      "1408:\ttotal: 2m 47s\tremaining: 7m 8s\n",
      "1409:\ttotal: 2m 48s\tremaining: 7m 7s\n",
      "1410:\tlearn: 0.9746067\ttest: 1.1647288\tbest: 1.1647288 (1410)\ttotal: 2m 48s\tremaining: 7m 7s\n",
      "1411:\ttotal: 2m 48s\tremaining: 7m 7s\n",
      "1412:\ttotal: 2m 48s\tremaining: 7m 7s\n",
      "1413:\ttotal: 2m 48s\tremaining: 7m 7s\n",
      "1414:\ttotal: 2m 48s\tremaining: 7m 7s\n",
      "1415:\tlearn: 0.9734026\ttest: 1.1640412\tbest: 1.1640412 (1415)\ttotal: 2m 48s\tremaining: 7m 7s\n",
      "1416:\ttotal: 2m 48s\tremaining: 7m 7s\n",
      "1417:\ttotal: 2m 48s\tremaining: 7m 6s\n",
      "1418:\ttotal: 2m 49s\tremaining: 7m 6s\n",
      "1419:\ttotal: 2m 49s\tremaining: 7m 6s\n",
      "1420:\tlearn: 0.9722062\ttest: 1.1633513\tbest: 1.1633513 (1420)\ttotal: 2m 49s\tremaining: 7m 6s\n",
      "1421:\ttotal: 2m 49s\tremaining: 7m 6s\n",
      "1422:\ttotal: 2m 49s\tremaining: 7m 6s\n",
      "1423:\ttotal: 2m 49s\tremaining: 7m 6s\n",
      "1424:\ttotal: 2m 49s\tremaining: 7m 6s\n",
      "1425:\tlearn: 0.9710292\ttest: 1.1627004\tbest: 1.1627004 (1425)\ttotal: 2m 49s\tremaining: 7m 5s\n",
      "1426:\ttotal: 2m 50s\tremaining: 7m 5s\n",
      "1427:\ttotal: 2m 50s\tremaining: 7m 5s\n",
      "1428:\ttotal: 2m 50s\tremaining: 7m 5s\n",
      "1429:\ttotal: 2m 50s\tremaining: 7m 5s\n",
      "1430:\tlearn: 0.9698093\ttest: 1.1619670\tbest: 1.1619670 (1430)\ttotal: 2m 50s\tremaining: 7m 5s\n",
      "1431:\ttotal: 2m 50s\tremaining: 7m 5s\n",
      "1432:\ttotal: 2m 50s\tremaining: 7m 4s\n",
      "1433:\ttotal: 2m 50s\tremaining: 7m 4s\n",
      "1434:\ttotal: 2m 50s\tremaining: 7m 4s\n",
      "1435:\tlearn: 0.9685524\ttest: 1.1611976\tbest: 1.1611976 (1435)\ttotal: 2m 51s\tremaining: 7m 4s\n",
      "1436:\ttotal: 2m 51s\tremaining: 7m 4s\n",
      "1437:\ttotal: 2m 51s\tremaining: 7m 4s\n",
      "1438:\ttotal: 2m 51s\tremaining: 7m 4s\n",
      "1439:\ttotal: 2m 51s\tremaining: 7m 4s\n",
      "1440:\tlearn: 0.9673380\ttest: 1.1604783\tbest: 1.1604783 (1440)\ttotal: 2m 51s\tremaining: 7m 3s\n",
      "1441:\ttotal: 2m 51s\tremaining: 7m 3s\n",
      "1442:\ttotal: 2m 51s\tremaining: 7m 3s\n",
      "1443:\ttotal: 2m 51s\tremaining: 7m 3s\n",
      "1444:\ttotal: 2m 52s\tremaining: 7m 3s\n",
      "1445:\tlearn: 0.9661416\ttest: 1.1597382\tbest: 1.1597382 (1445)\ttotal: 2m 52s\tremaining: 7m 3s\n",
      "1446:\ttotal: 2m 52s\tremaining: 7m 3s\n",
      "1447:\ttotal: 2m 52s\tremaining: 7m 3s\n",
      "1448:\ttotal: 2m 52s\tremaining: 7m 2s\n",
      "1449:\ttotal: 2m 52s\tremaining: 7m 2s\n",
      "1450:\tlearn: 0.9649838\ttest: 1.1590783\tbest: 1.1590783 (1450)\ttotal: 2m 52s\tremaining: 7m 2s\n",
      "1451:\ttotal: 2m 52s\tremaining: 7m 2s\n",
      "1452:\ttotal: 2m 53s\tremaining: 7m 2s\n",
      "1453:\ttotal: 2m 53s\tremaining: 7m 2s\n",
      "1454:\ttotal: 2m 53s\tremaining: 7m 2s\n",
      "1455:\tlearn: 0.9637502\ttest: 1.1584609\tbest: 1.1584609 (1455)\ttotal: 2m 53s\tremaining: 7m 2s\n",
      "1456:\ttotal: 2m 53s\tremaining: 7m 1s\n",
      "1457:\ttotal: 2m 53s\tremaining: 7m 1s\n",
      "1458:\ttotal: 2m 53s\tremaining: 7m 1s\n",
      "1459:\ttotal: 2m 53s\tremaining: 7m 1s\n",
      "1460:\tlearn: 0.9625867\ttest: 1.1578146\tbest: 1.1578146 (1460)\ttotal: 2m 53s\tremaining: 7m 1s\n",
      "1461:\ttotal: 2m 54s\tremaining: 7m 1s\n",
      "1462:\ttotal: 2m 54s\tremaining: 7m 1s\n",
      "1463:\ttotal: 2m 54s\tremaining: 7m 1s\n",
      "1464:\ttotal: 2m 54s\tremaining: 7m\n",
      "1465:\tlearn: 0.9614432\ttest: 1.1572856\tbest: 1.1572856 (1465)\ttotal: 2m 54s\tremaining: 7m\n",
      "1466:\ttotal: 2m 54s\tremaining: 7m\n",
      "1467:\ttotal: 2m 54s\tremaining: 7m\n",
      "1468:\ttotal: 2m 54s\tremaining: 7m\n",
      "1469:\ttotal: 2m 54s\tremaining: 7m\n",
      "1470:\tlearn: 0.9602332\ttest: 1.1565695\tbest: 1.1565695 (1470)\ttotal: 2m 55s\tremaining: 7m\n",
      "1471:\ttotal: 2m 55s\tremaining: 7m\n",
      "1472:\ttotal: 2m 55s\tremaining: 6m 59s\n",
      "1473:\ttotal: 2m 55s\tremaining: 6m 59s\n",
      "1474:\ttotal: 2m 55s\tremaining: 6m 59s\n",
      "1475:\tlearn: 0.9590103\ttest: 1.1559699\tbest: 1.1559699 (1475)\ttotal: 2m 55s\tremaining: 6m 59s\n",
      "1476:\ttotal: 2m 55s\tremaining: 6m 59s\n",
      "1477:\ttotal: 2m 55s\tremaining: 6m 59s\n",
      "1478:\ttotal: 2m 56s\tremaining: 6m 59s\n",
      "1479:\ttotal: 2m 56s\tremaining: 6m 58s\n",
      "1480:\tlearn: 0.9577220\ttest: 1.1552198\tbest: 1.1552198 (1480)\ttotal: 2m 56s\tremaining: 6m 58s\n",
      "1481:\ttotal: 2m 56s\tremaining: 6m 58s\n",
      "1482:\ttotal: 2m 56s\tremaining: 6m 58s\n",
      "1483:\ttotal: 2m 56s\tremaining: 6m 58s\n",
      "1484:\ttotal: 2m 56s\tremaining: 6m 58s\n",
      "1485:\tlearn: 0.9565804\ttest: 1.1544646\tbest: 1.1544646 (1485)\ttotal: 2m 56s\tremaining: 6m 58s\n",
      "1486:\ttotal: 2m 56s\tremaining: 6m 58s\n",
      "1487:\ttotal: 2m 57s\tremaining: 6m 57s\n",
      "1488:\ttotal: 2m 57s\tremaining: 6m 57s\n",
      "1489:\ttotal: 2m 57s\tremaining: 6m 57s\n",
      "1490:\tlearn: 0.9554078\ttest: 1.1536956\tbest: 1.1536956 (1490)\ttotal: 2m 57s\tremaining: 6m 57s\n",
      "1491:\ttotal: 2m 57s\tremaining: 6m 57s\n",
      "1492:\ttotal: 2m 57s\tremaining: 6m 57s\n",
      "1493:\ttotal: 2m 57s\tremaining: 6m 56s\n",
      "1494:\ttotal: 2m 57s\tremaining: 6m 56s\n",
      "1495:\tlearn: 0.9542772\ttest: 1.1530891\tbest: 1.1530891 (1495)\ttotal: 2m 57s\tremaining: 6m 56s\n",
      "1496:\ttotal: 2m 58s\tremaining: 6m 56s\n",
      "1497:\ttotal: 2m 58s\tremaining: 6m 56s\n",
      "1498:\ttotal: 2m 58s\tremaining: 6m 56s\n",
      "1499:\ttotal: 2m 58s\tremaining: 6m 56s\n",
      "1500:\tlearn: 0.9531051\ttest: 1.1525637\tbest: 1.1525637 (1500)\ttotal: 2m 58s\tremaining: 6m 56s\n",
      "1501:\ttotal: 2m 58s\tremaining: 6m 56s\n",
      "1502:\ttotal: 2m 58s\tremaining: 6m 55s\n",
      "1503:\ttotal: 2m 58s\tremaining: 6m 55s\n",
      "1504:\ttotal: 2m 58s\tremaining: 6m 55s\n",
      "1505:\tlearn: 0.9519202\ttest: 1.1519665\tbest: 1.1519665 (1505)\ttotal: 2m 59s\tremaining: 6m 55s\n",
      "1506:\ttotal: 2m 59s\tremaining: 6m 55s\n",
      "1507:\ttotal: 2m 59s\tremaining: 6m 55s\n",
      "1508:\ttotal: 2m 59s\tremaining: 6m 55s\n",
      "1509:\ttotal: 2m 59s\tremaining: 6m 54s\n",
      "1510:\tlearn: 0.9506510\ttest: 1.1514508\tbest: 1.1514508 (1510)\ttotal: 2m 59s\tremaining: 6m 54s\n",
      "1511:\ttotal: 2m 59s\tremaining: 6m 54s\n",
      "1512:\ttotal: 2m 59s\tremaining: 6m 54s\n",
      "1513:\ttotal: 2m 59s\tremaining: 6m 54s\n",
      "1514:\ttotal: 3m\tremaining: 6m 54s\n",
      "1515:\tlearn: 0.9494462\ttest: 1.1507622\tbest: 1.1507622 (1515)\ttotal: 3m\tremaining: 6m 54s\n",
      "1516:\ttotal: 3m\tremaining: 6m 53s\n",
      "1517:\ttotal: 3m\tremaining: 6m 53s\n",
      "1518:\ttotal: 3m\tremaining: 6m 53s\n",
      "1519:\ttotal: 3m\tremaining: 6m 53s\n",
      "1520:\tlearn: 0.9483136\ttest: 1.1501832\tbest: 1.1501832 (1520)\ttotal: 3m\tremaining: 6m 53s\n",
      "1521:\ttotal: 3m\tremaining: 6m 53s\n",
      "1522:\ttotal: 3m 1s\tremaining: 6m 53s\n",
      "1523:\ttotal: 3m 1s\tremaining: 6m 53s\n",
      "1524:\ttotal: 3m 1s\tremaining: 6m 53s\n",
      "1525:\tlearn: 0.9471120\ttest: 1.1494900\tbest: 1.1494900 (1525)\ttotal: 3m 1s\tremaining: 6m 52s\n",
      "1526:\ttotal: 3m 1s\tremaining: 6m 52s\n",
      "1527:\ttotal: 3m 1s\tremaining: 6m 52s\n",
      "1528:\ttotal: 3m 1s\tremaining: 6m 52s\n",
      "1529:\ttotal: 3m 1s\tremaining: 6m 52s\n",
      "1530:\tlearn: 0.9459635\ttest: 1.1489286\tbest: 1.1489286 (1530)\ttotal: 3m 1s\tremaining: 6m 52s\n",
      "1531:\ttotal: 3m 2s\tremaining: 6m 52s\n",
      "1532:\ttotal: 3m 2s\tremaining: 6m 51s\n",
      "1533:\ttotal: 3m 2s\tremaining: 6m 51s\n",
      "1534:\ttotal: 3m 2s\tremaining: 6m 51s\n",
      "1535:\tlearn: 0.9447862\ttest: 1.1483705\tbest: 1.1483705 (1535)\ttotal: 3m 2s\tremaining: 6m 51s\n",
      "1536:\ttotal: 3m 2s\tremaining: 6m 51s\n",
      "1537:\ttotal: 3m 2s\tremaining: 6m 51s\n",
      "1538:\ttotal: 3m 2s\tremaining: 6m 51s\n",
      "1539:\ttotal: 3m 3s\tremaining: 6m 51s\n",
      "1540:\tlearn: 0.9436675\ttest: 1.1478702\tbest: 1.1478702 (1540)\ttotal: 3m 3s\tremaining: 6m 51s\n",
      "1541:\ttotal: 3m 3s\tremaining: 6m 50s\n",
      "1542:\ttotal: 3m 3s\tremaining: 6m 50s\n",
      "1543:\ttotal: 3m 3s\tremaining: 6m 50s\n",
      "1544:\ttotal: 3m 3s\tremaining: 6m 50s\n",
      "1545:\tlearn: 0.9425418\ttest: 1.1471849\tbest: 1.1471849 (1545)\ttotal: 3m 3s\tremaining: 6m 50s\n",
      "1546:\ttotal: 3m 3s\tremaining: 6m 50s\n",
      "1547:\ttotal: 3m 3s\tremaining: 6m 50s\n",
      "1548:\ttotal: 3m 4s\tremaining: 6m 49s\n",
      "1549:\ttotal: 3m 4s\tremaining: 6m 49s\n",
      "1550:\tlearn: 0.9414550\ttest: 1.1465981\tbest: 1.1465981 (1550)\ttotal: 3m 4s\tremaining: 6m 49s\n",
      "1551:\ttotal: 3m 4s\tremaining: 6m 49s\n",
      "1552:\ttotal: 3m 4s\tremaining: 6m 49s\n",
      "1553:\ttotal: 3m 4s\tremaining: 6m 49s\n",
      "1554:\ttotal: 3m 4s\tremaining: 6m 49s\n",
      "1555:\tlearn: 0.9403178\ttest: 1.1459629\tbest: 1.1459629 (1555)\ttotal: 3m 4s\tremaining: 6m 49s\n",
      "1556:\ttotal: 3m 4s\tremaining: 6m 48s\n",
      "1557:\ttotal: 3m 5s\tremaining: 6m 48s\n",
      "1558:\ttotal: 3m 5s\tremaining: 6m 48s\n",
      "1559:\ttotal: 3m 5s\tremaining: 6m 48s\n",
      "1560:\tlearn: 0.9392736\ttest: 1.1453598\tbest: 1.1453598 (1560)\ttotal: 3m 5s\tremaining: 6m 48s\n",
      "1561:\ttotal: 3m 5s\tremaining: 6m 48s\n",
      "1562:\ttotal: 3m 5s\tremaining: 6m 48s\n",
      "1563:\ttotal: 3m 5s\tremaining: 6m 48s\n",
      "1564:\ttotal: 3m 5s\tremaining: 6m 47s\n",
      "1565:\tlearn: 0.9381337\ttest: 1.1448287\tbest: 1.1448287 (1565)\ttotal: 3m 5s\tremaining: 6m 47s\n",
      "1566:\ttotal: 3m 6s\tremaining: 6m 47s\n",
      "1567:\ttotal: 3m 6s\tremaining: 6m 47s\n",
      "1568:\ttotal: 3m 6s\tremaining: 6m 47s\n",
      "1569:\ttotal: 3m 6s\tremaining: 6m 47s\n",
      "1570:\tlearn: 0.9369606\ttest: 1.1443003\tbest: 1.1443003 (1570)\ttotal: 3m 6s\tremaining: 6m 47s\n",
      "1571:\ttotal: 3m 6s\tremaining: 6m 47s\n",
      "1572:\ttotal: 3m 6s\tremaining: 6m 47s\n",
      "1573:\ttotal: 3m 6s\tremaining: 6m 46s\n",
      "1574:\ttotal: 3m 7s\tremaining: 6m 46s\n",
      "1575:\tlearn: 0.9358684\ttest: 1.1437221\tbest: 1.1437221 (1575)\ttotal: 3m 7s\tremaining: 6m 46s\n",
      "1576:\ttotal: 3m 7s\tremaining: 6m 46s\n",
      "1577:\ttotal: 3m 7s\tremaining: 6m 46s\n",
      "1578:\ttotal: 3m 7s\tremaining: 6m 46s\n",
      "1579:\ttotal: 3m 7s\tremaining: 6m 46s\n",
      "1580:\tlearn: 0.9348014\ttest: 1.1429828\tbest: 1.1429828 (1580)\ttotal: 3m 7s\tremaining: 6m 45s\n",
      "1581:\ttotal: 3m 7s\tremaining: 6m 45s\n",
      "1582:\ttotal: 3m 7s\tremaining: 6m 45s\n",
      "1583:\ttotal: 3m 8s\tremaining: 6m 45s\n",
      "1584:\ttotal: 3m 8s\tremaining: 6m 45s\n",
      "1585:\tlearn: 0.9336994\ttest: 1.1424371\tbest: 1.1424371 (1585)\ttotal: 3m 8s\tremaining: 6m 45s\n",
      "1586:\ttotal: 3m 8s\tremaining: 6m 45s\n",
      "1587:\ttotal: 3m 8s\tremaining: 6m 44s\n",
      "1588:\ttotal: 3m 8s\tremaining: 6m 44s\n",
      "1589:\ttotal: 3m 8s\tremaining: 6m 44s\n",
      "1590:\tlearn: 0.9326454\ttest: 1.1418273\tbest: 1.1418273 (1590)\ttotal: 3m 8s\tremaining: 6m 44s\n",
      "1591:\ttotal: 3m 8s\tremaining: 6m 44s\n",
      "1592:\ttotal: 3m 9s\tremaining: 6m 44s\n",
      "1593:\ttotal: 3m 9s\tremaining: 6m 44s\n",
      "1594:\ttotal: 3m 9s\tremaining: 6m 44s\n",
      "1595:\tlearn: 0.9316011\ttest: 1.1413441\tbest: 1.1413441 (1595)\ttotal: 3m 9s\tremaining: 6m 44s\n",
      "1596:\ttotal: 3m 9s\tremaining: 6m 44s\n",
      "1597:\ttotal: 3m 9s\tremaining: 6m 43s\n",
      "1598:\ttotal: 3m 9s\tremaining: 6m 43s\n",
      "1599:\ttotal: 3m 9s\tremaining: 6m 43s\n",
      "1600:\tlearn: 0.9304940\ttest: 1.1407753\tbest: 1.1407753 (1600)\ttotal: 3m 10s\tremaining: 6m 43s\n",
      "1601:\ttotal: 3m 10s\tremaining: 6m 43s\n",
      "1602:\ttotal: 3m 10s\tremaining: 6m 43s\n",
      "1603:\ttotal: 3m 10s\tremaining: 6m 43s\n",
      "1604:\ttotal: 3m 10s\tremaining: 6m 43s\n",
      "1605:\tlearn: 0.9294093\ttest: 1.1402118\tbest: 1.1402118 (1605)\ttotal: 3m 10s\tremaining: 6m 42s\n",
      "1606:\ttotal: 3m 10s\tremaining: 6m 42s\n",
      "1607:\ttotal: 3m 10s\tremaining: 6m 42s\n",
      "1608:\ttotal: 3m 10s\tremaining: 6m 42s\n",
      "1609:\ttotal: 3m 11s\tremaining: 6m 42s\n",
      "1610:\tlearn: 0.9283442\ttest: 1.1396239\tbest: 1.1396239 (1610)\ttotal: 3m 11s\tremaining: 6m 42s\n",
      "1611:\ttotal: 3m 11s\tremaining: 6m 42s\n",
      "1612:\ttotal: 3m 11s\tremaining: 6m 42s\n",
      "1613:\ttotal: 3m 11s\tremaining: 6m 41s\n",
      "1614:\ttotal: 3m 11s\tremaining: 6m 41s\n",
      "1615:\tlearn: 0.9272399\ttest: 1.1390446\tbest: 1.1390446 (1615)\ttotal: 3m 11s\tremaining: 6m 41s\n",
      "1616:\ttotal: 3m 11s\tremaining: 6m 41s\n",
      "1617:\ttotal: 3m 12s\tremaining: 6m 41s\n",
      "1618:\ttotal: 3m 12s\tremaining: 6m 41s\n",
      "1619:\ttotal: 3m 12s\tremaining: 6m 41s\n",
      "1620:\tlearn: 0.9261303\ttest: 1.1385386\tbest: 1.1385386 (1620)\ttotal: 3m 12s\tremaining: 6m 41s\n",
      "1621:\ttotal: 3m 12s\tremaining: 6m 40s\n",
      "1622:\ttotal: 3m 12s\tremaining: 6m 40s\n",
      "1623:\ttotal: 3m 12s\tremaining: 6m 40s\n",
      "1624:\ttotal: 3m 12s\tremaining: 6m 40s\n",
      "1625:\tlearn: 0.9250182\ttest: 1.1378341\tbest: 1.1378341 (1625)\ttotal: 3m 12s\tremaining: 6m 40s\n",
      "1626:\ttotal: 3m 13s\tremaining: 6m 40s\n",
      "1627:\ttotal: 3m 13s\tremaining: 6m 40s\n",
      "1628:\ttotal: 3m 13s\tremaining: 6m 39s\n",
      "1629:\ttotal: 3m 13s\tremaining: 6m 39s\n",
      "1630:\tlearn: 0.9238901\ttest: 1.1373037\tbest: 1.1373037 (1630)\ttotal: 3m 13s\tremaining: 6m 39s\n",
      "1631:\ttotal: 3m 13s\tremaining: 6m 39s\n",
      "1632:\ttotal: 3m 13s\tremaining: 6m 39s\n",
      "1633:\ttotal: 3m 13s\tremaining: 6m 39s\n",
      "1634:\ttotal: 3m 13s\tremaining: 6m 39s\n",
      "1635:\tlearn: 0.9228063\ttest: 1.1367331\tbest: 1.1367331 (1635)\ttotal: 3m 14s\tremaining: 6m 39s\n",
      "1636:\ttotal: 3m 14s\tremaining: 6m 38s\n",
      "1637:\ttotal: 3m 14s\tremaining: 6m 38s\n",
      "1638:\ttotal: 3m 14s\tremaining: 6m 38s\n",
      "1639:\ttotal: 3m 14s\tremaining: 6m 38s\n",
      "1640:\tlearn: 0.9216781\ttest: 1.1361542\tbest: 1.1361542 (1640)\ttotal: 3m 14s\tremaining: 6m 38s\n",
      "1641:\ttotal: 3m 14s\tremaining: 6m 38s\n",
      "1642:\ttotal: 3m 14s\tremaining: 6m 38s\n",
      "1643:\ttotal: 3m 15s\tremaining: 6m 38s\n",
      "1644:\ttotal: 3m 15s\tremaining: 6m 37s\n",
      "1645:\tlearn: 0.9206034\ttest: 1.1356425\tbest: 1.1356425 (1645)\ttotal: 3m 15s\tremaining: 6m 37s\n",
      "1646:\ttotal: 3m 15s\tremaining: 6m 37s\n",
      "1647:\ttotal: 3m 15s\tremaining: 6m 37s\n",
      "1648:\ttotal: 3m 15s\tremaining: 6m 37s\n",
      "1649:\ttotal: 3m 15s\tremaining: 6m 37s\n",
      "1650:\tlearn: 0.9195185\ttest: 1.1350997\tbest: 1.1350997 (1650)\ttotal: 3m 15s\tremaining: 6m 37s\n",
      "1651:\ttotal: 3m 15s\tremaining: 6m 37s\n",
      "1652:\ttotal: 3m 16s\tremaining: 6m 36s\n",
      "1653:\ttotal: 3m 16s\tremaining: 6m 36s\n",
      "1654:\ttotal: 3m 16s\tremaining: 6m 36s\n",
      "1655:\tlearn: 0.9184342\ttest: 1.1345806\tbest: 1.1345806 (1655)\ttotal: 3m 16s\tremaining: 6m 36s\n",
      "1656:\ttotal: 3m 16s\tremaining: 6m 36s\n",
      "1657:\ttotal: 3m 16s\tremaining: 6m 36s\n",
      "1658:\ttotal: 3m 16s\tremaining: 6m 36s\n",
      "1659:\ttotal: 3m 16s\tremaining: 6m 36s\n",
      "1660:\tlearn: 0.9173891\ttest: 1.1340601\tbest: 1.1340601 (1660)\ttotal: 3m 17s\tremaining: 6m 36s\n",
      "1661:\ttotal: 3m 17s\tremaining: 6m 35s\n",
      "1662:\ttotal: 3m 17s\tremaining: 6m 35s\n",
      "1663:\ttotal: 3m 17s\tremaining: 6m 35s\n",
      "1664:\ttotal: 3m 17s\tremaining: 6m 35s\n",
      "1665:\tlearn: 0.9162729\ttest: 1.1336270\tbest: 1.1336270 (1665)\ttotal: 3m 17s\tremaining: 6m 35s\n",
      "1666:\ttotal: 3m 17s\tremaining: 6m 35s\n",
      "1667:\ttotal: 3m 17s\tremaining: 6m 35s\n",
      "1668:\ttotal: 3m 17s\tremaining: 6m 35s\n",
      "1669:\ttotal: 3m 18s\tremaining: 6m 34s\n",
      "1670:\tlearn: 0.9152097\ttest: 1.1329467\tbest: 1.1329467 (1670)\ttotal: 3m 18s\tremaining: 6m 34s\n",
      "1671:\ttotal: 3m 18s\tremaining: 6m 34s\n",
      "1672:\ttotal: 3m 18s\tremaining: 6m 34s\n",
      "1673:\ttotal: 3m 18s\tremaining: 6m 34s\n",
      "1674:\ttotal: 3m 18s\tremaining: 6m 34s\n",
      "1675:\tlearn: 0.9141477\ttest: 1.1324555\tbest: 1.1324555 (1675)\ttotal: 3m 18s\tremaining: 6m 34s\n",
      "1676:\ttotal: 3m 18s\tremaining: 6m 34s\n",
      "1677:\ttotal: 3m 19s\tremaining: 6m 34s\n",
      "1678:\ttotal: 3m 19s\tremaining: 6m 33s\n",
      "1679:\ttotal: 3m 19s\tremaining: 6m 33s\n",
      "1680:\tlearn: 0.9130852\ttest: 1.1317950\tbest: 1.1317950 (1680)\ttotal: 3m 19s\tremaining: 6m 33s\n",
      "1681:\ttotal: 3m 19s\tremaining: 6m 33s\n",
      "1682:\ttotal: 3m 19s\tremaining: 6m 33s\n",
      "1683:\ttotal: 3m 19s\tremaining: 6m 33s\n",
      "1684:\ttotal: 3m 19s\tremaining: 6m 33s\n",
      "1685:\tlearn: 0.9120187\ttest: 1.1313006\tbest: 1.1313006 (1685)\ttotal: 3m 19s\tremaining: 6m 33s\n",
      "1686:\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "1687:\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "1688:\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "1689:\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "1690:\tlearn: 0.9109086\ttest: 1.1308405\tbest: 1.1308405 (1690)\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "1691:\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "1692:\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "1693:\ttotal: 3m 20s\tremaining: 6m 32s\n",
      "1694:\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1695:\tlearn: 0.9098823\ttest: 1.1304542\tbest: 1.1304542 (1695)\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1696:\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1697:\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1698:\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1699:\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1700:\tlearn: 0.9088302\ttest: 1.1299993\tbest: 1.1299993 (1700)\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1701:\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1702:\ttotal: 3m 21s\tremaining: 6m 31s\n",
      "1703:\ttotal: 3m 22s\tremaining: 6m 30s\n",
      "1704:\ttotal: 3m 22s\tremaining: 6m 30s\n",
      "1705:\tlearn: 0.9078846\ttest: 1.1295071\tbest: 1.1295071 (1705)\ttotal: 3m 22s\tremaining: 6m 30s\n",
      "1706:\ttotal: 3m 22s\tremaining: 6m 30s\n",
      "1707:\ttotal: 3m 22s\tremaining: 6m 30s\n",
      "1708:\ttotal: 3m 22s\tremaining: 6m 30s\n",
      "1709:\ttotal: 3m 22s\tremaining: 6m 30s\n",
      "1710:\tlearn: 0.9068734\ttest: 1.1290152\tbest: 1.1290152 (1710)\ttotal: 3m 22s\tremaining: 6m 29s\n",
      "1711:\ttotal: 3m 23s\tremaining: 6m 29s\n",
      "1712:\ttotal: 3m 23s\tremaining: 6m 29s\n",
      "1713:\ttotal: 3m 23s\tremaining: 6m 29s\n",
      "1714:\ttotal: 3m 23s\tremaining: 6m 29s\n",
      "1715:\tlearn: 0.9058487\ttest: 1.1285720\tbest: 1.1285720 (1715)\ttotal: 3m 23s\tremaining: 6m 29s\n",
      "1716:\ttotal: 3m 23s\tremaining: 6m 29s\n",
      "1717:\ttotal: 3m 23s\tremaining: 6m 29s\n",
      "1718:\ttotal: 3m 23s\tremaining: 6m 29s\n",
      "1719:\ttotal: 3m 23s\tremaining: 6m 28s\n",
      "1720:\tlearn: 0.9047951\ttest: 1.1281302\tbest: 1.1281302 (1720)\ttotal: 3m 24s\tremaining: 6m 28s\n",
      "1721:\ttotal: 3m 24s\tremaining: 6m 28s\n",
      "1722:\ttotal: 3m 24s\tremaining: 6m 28s\n",
      "1723:\ttotal: 3m 24s\tremaining: 6m 28s\n",
      "1724:\ttotal: 3m 24s\tremaining: 6m 28s\n",
      "1725:\tlearn: 0.9037336\ttest: 1.1276112\tbest: 1.1276112 (1725)\ttotal: 3m 24s\tremaining: 6m 28s\n",
      "1726:\ttotal: 3m 24s\tremaining: 6m 28s\n",
      "1727:\ttotal: 3m 24s\tremaining: 6m 27s\n",
      "1728:\ttotal: 3m 25s\tremaining: 6m 27s\n",
      "1729:\ttotal: 3m 25s\tremaining: 6m 27s\n",
      "1730:\tlearn: 0.9027344\ttest: 1.1271461\tbest: 1.1271461 (1730)\ttotal: 3m 25s\tremaining: 6m 27s\n",
      "1731:\ttotal: 3m 25s\tremaining: 6m 27s\n",
      "1732:\ttotal: 3m 25s\tremaining: 6m 27s\n",
      "1733:\ttotal: 3m 25s\tremaining: 6m 27s\n",
      "1734:\ttotal: 3m 25s\tremaining: 6m 27s\n",
      "1735:\tlearn: 0.9016889\ttest: 1.1266682\tbest: 1.1266682 (1735)\ttotal: 3m 25s\tremaining: 6m 27s\n",
      "1736:\ttotal: 3m 26s\tremaining: 6m 27s\n",
      "1737:\ttotal: 3m 26s\tremaining: 6m 26s\n",
      "1738:\ttotal: 3m 26s\tremaining: 6m 26s\n",
      "1739:\ttotal: 3m 26s\tremaining: 6m 26s\n",
      "1740:\tlearn: 0.9007042\ttest: 1.1261402\tbest: 1.1261402 (1740)\ttotal: 3m 26s\tremaining: 6m 26s\n",
      "1741:\ttotal: 3m 26s\tremaining: 6m 26s\n",
      "1742:\ttotal: 3m 26s\tremaining: 6m 26s\n",
      "1743:\ttotal: 3m 26s\tremaining: 6m 26s\n",
      "1744:\ttotal: 3m 26s\tremaining: 6m 26s\n",
      "1745:\tlearn: 0.8996406\ttest: 1.1257976\tbest: 1.1257976 (1745)\ttotal: 3m 27s\tremaining: 6m 25s\n",
      "1746:\ttotal: 3m 27s\tremaining: 6m 25s\n",
      "1747:\ttotal: 3m 27s\tremaining: 6m 25s\n",
      "1748:\ttotal: 3m 27s\tremaining: 6m 25s\n",
      "1749:\ttotal: 3m 27s\tremaining: 6m 25s\n",
      "1750:\tlearn: 0.8986079\ttest: 1.1252664\tbest: 1.1252664 (1750)\ttotal: 3m 27s\tremaining: 6m 25s\n",
      "1751:\ttotal: 3m 27s\tremaining: 6m 25s\n",
      "1752:\ttotal: 3m 27s\tremaining: 6m 25s\n",
      "1753:\ttotal: 3m 28s\tremaining: 6m 24s\n",
      "1754:\ttotal: 3m 28s\tremaining: 6m 24s\n",
      "1755:\tlearn: 0.8975851\ttest: 1.1248262\tbest: 1.1248262 (1755)\ttotal: 3m 28s\tremaining: 6m 24s\n",
      "1756:\ttotal: 3m 28s\tremaining: 6m 24s\n",
      "1757:\ttotal: 3m 28s\tremaining: 6m 24s\n",
      "1758:\ttotal: 3m 28s\tremaining: 6m 24s\n",
      "1759:\ttotal: 3m 28s\tremaining: 6m 24s\n",
      "1760:\tlearn: 0.8965882\ttest: 1.1240783\tbest: 1.1240783 (1760)\ttotal: 3m 28s\tremaining: 6m 23s\n",
      "1761:\ttotal: 3m 28s\tremaining: 6m 23s\n",
      "1762:\ttotal: 3m 28s\tremaining: 6m 23s\n",
      "1763:\ttotal: 3m 29s\tremaining: 6m 23s\n",
      "1764:\ttotal: 3m 29s\tremaining: 6m 23s\n",
      "1765:\tlearn: 0.8956128\ttest: 1.1235657\tbest: 1.1235657 (1765)\ttotal: 3m 29s\tremaining: 6m 23s\n",
      "1766:\ttotal: 3m 29s\tremaining: 6m 23s\n",
      "1767:\ttotal: 3m 29s\tremaining: 6m 23s\n",
      "1768:\ttotal: 3m 29s\tremaining: 6m 23s\n",
      "1769:\ttotal: 3m 29s\tremaining: 6m 22s\n",
      "1770:\tlearn: 0.8945850\ttest: 1.1231363\tbest: 1.1231363 (1770)\ttotal: 3m 29s\tremaining: 6m 22s\n",
      "1771:\ttotal: 3m 30s\tremaining: 6m 22s\n",
      "1772:\ttotal: 3m 30s\tremaining: 6m 22s\n",
      "1773:\ttotal: 3m 30s\tremaining: 6m 22s\n",
      "1774:\ttotal: 3m 30s\tremaining: 6m 22s\n",
      "1775:\tlearn: 0.8935941\ttest: 1.1225228\tbest: 1.1225228 (1775)\ttotal: 3m 30s\tremaining: 6m 22s\n",
      "1776:\ttotal: 3m 30s\tremaining: 6m 22s\n",
      "1777:\ttotal: 3m 30s\tremaining: 6m 21s\n",
      "1778:\ttotal: 3m 30s\tremaining: 6m 21s\n",
      "1779:\ttotal: 3m 30s\tremaining: 6m 21s\n",
      "1780:\tlearn: 0.8926531\ttest: 1.1220767\tbest: 1.1220767 (1780)\ttotal: 3m 31s\tremaining: 6m 21s\n",
      "1781:\ttotal: 3m 31s\tremaining: 6m 21s\n",
      "1782:\ttotal: 3m 31s\tremaining: 6m 21s\n",
      "1783:\ttotal: 3m 31s\tremaining: 6m 21s\n",
      "1784:\ttotal: 3m 31s\tremaining: 6m 21s\n",
      "1785:\tlearn: 0.8916681\ttest: 1.1216661\tbest: 1.1216661 (1785)\ttotal: 3m 31s\tremaining: 6m 21s\n",
      "1786:\ttotal: 3m 31s\tremaining: 6m 20s\n",
      "1787:\ttotal: 3m 31s\tremaining: 6m 20s\n",
      "1788:\ttotal: 3m 32s\tremaining: 6m 20s\n",
      "1789:\ttotal: 3m 32s\tremaining: 6m 20s\n",
      "1790:\tlearn: 0.8906942\ttest: 1.1210944\tbest: 1.1210944 (1790)\ttotal: 3m 32s\tremaining: 6m 20s\n",
      "1791:\ttotal: 3m 32s\tremaining: 6m 20s\n",
      "1792:\ttotal: 3m 32s\tremaining: 6m 20s\n",
      "1793:\ttotal: 3m 32s\tremaining: 6m 20s\n",
      "1794:\ttotal: 3m 32s\tremaining: 6m 19s\n",
      "1795:\tlearn: 0.8896997\ttest: 1.1206353\tbest: 1.1206353 (1795)\ttotal: 3m 32s\tremaining: 6m 19s\n",
      "1796:\ttotal: 3m 32s\tremaining: 6m 19s\n",
      "1797:\ttotal: 3m 33s\tremaining: 6m 19s\n",
      "1798:\ttotal: 3m 33s\tremaining: 6m 19s\n",
      "1799:\ttotal: 3m 33s\tremaining: 6m 19s\n",
      "1800:\tlearn: 0.8886798\ttest: 1.1201973\tbest: 1.1201973 (1800)\ttotal: 3m 33s\tremaining: 6m 19s\n",
      "1801:\ttotal: 3m 33s\tremaining: 6m 19s\n",
      "1802:\ttotal: 3m 33s\tremaining: 6m 18s\n",
      "1803:\ttotal: 3m 33s\tremaining: 6m 18s\n",
      "1804:\ttotal: 3m 33s\tremaining: 6m 18s\n",
      "1805:\tlearn: 0.8875994\ttest: 1.1197187\tbest: 1.1197187 (1805)\ttotal: 3m 34s\tremaining: 6m 18s\n",
      "1806:\ttotal: 3m 34s\tremaining: 6m 18s\n",
      "1807:\ttotal: 3m 34s\tremaining: 6m 18s\n",
      "1808:\ttotal: 3m 34s\tremaining: 6m 18s\n",
      "1809:\ttotal: 3m 34s\tremaining: 6m 18s\n",
      "1810:\tlearn: 0.8866787\ttest: 1.1192024\tbest: 1.1192024 (1810)\ttotal: 3m 34s\tremaining: 6m 17s\n",
      "1811:\ttotal: 3m 34s\tremaining: 6m 17s\n",
      "1812:\ttotal: 3m 34s\tremaining: 6m 17s\n",
      "1813:\ttotal: 3m 34s\tremaining: 6m 17s\n",
      "1814:\ttotal: 3m 35s\tremaining: 6m 17s\n",
      "1815:\tlearn: 0.8856402\ttest: 1.1187848\tbest: 1.1187848 (1815)\ttotal: 3m 35s\tremaining: 6m 17s\n",
      "1816:\ttotal: 3m 35s\tremaining: 6m 17s\n",
      "1817:\ttotal: 3m 35s\tremaining: 6m 17s\n",
      "1818:\ttotal: 3m 35s\tremaining: 6m 16s\n",
      "1819:\ttotal: 3m 35s\tremaining: 6m 16s\n",
      "1820:\tlearn: 0.8846855\ttest: 1.1183686\tbest: 1.1183686 (1820)\ttotal: 3m 35s\tremaining: 6m 16s\n",
      "1821:\ttotal: 3m 35s\tremaining: 6m 16s\n",
      "1822:\ttotal: 3m 36s\tremaining: 6m 16s\n",
      "1823:\ttotal: 3m 36s\tremaining: 6m 16s\n",
      "1824:\ttotal: 3m 36s\tremaining: 6m 16s\n",
      "1825:\tlearn: 0.8836831\ttest: 1.1178318\tbest: 1.1178318 (1825)\ttotal: 3m 36s\tremaining: 6m 16s\n",
      "1826:\ttotal: 3m 36s\tremaining: 6m 15s\n",
      "1827:\ttotal: 3m 36s\tremaining: 6m 15s\n",
      "1828:\ttotal: 3m 36s\tremaining: 6m 15s\n",
      "1829:\ttotal: 3m 36s\tremaining: 6m 15s\n",
      "1830:\tlearn: 0.8827418\ttest: 1.1174231\tbest: 1.1174231 (1830)\ttotal: 3m 36s\tremaining: 6m 15s\n",
      "1831:\ttotal: 3m 37s\tremaining: 6m 15s\n",
      "1832:\ttotal: 3m 37s\tremaining: 6m 15s\n",
      "1833:\ttotal: 3m 37s\tremaining: 6m 15s\n",
      "1834:\ttotal: 3m 37s\tremaining: 6m 14s\n",
      "1835:\tlearn: 0.8818688\ttest: 1.1170013\tbest: 1.1170013 (1835)\ttotal: 3m 37s\tremaining: 6m 14s\n",
      "1836:\ttotal: 3m 37s\tremaining: 6m 14s\n",
      "1837:\ttotal: 3m 37s\tremaining: 6m 14s\n",
      "1838:\ttotal: 3m 37s\tremaining: 6m 14s\n",
      "1839:\ttotal: 3m 37s\tremaining: 6m 14s\n",
      "1840:\tlearn: 0.8809132\ttest: 1.1164703\tbest: 1.1164703 (1840)\ttotal: 3m 38s\tremaining: 6m 14s\n",
      "1841:\ttotal: 3m 38s\tremaining: 6m 14s\n",
      "1842:\ttotal: 3m 38s\tremaining: 6m 13s\n",
      "1843:\ttotal: 3m 38s\tremaining: 6m 13s\n",
      "1844:\ttotal: 3m 38s\tremaining: 6m 13s\n",
      "1845:\tlearn: 0.8799098\ttest: 1.1159313\tbest: 1.1159313 (1845)\ttotal: 3m 38s\tremaining: 6m 13s\n",
      "1846:\ttotal: 3m 38s\tremaining: 6m 13s\n",
      "1847:\ttotal: 3m 38s\tremaining: 6m 13s\n",
      "1848:\ttotal: 3m 38s\tremaining: 6m 13s\n",
      "1849:\ttotal: 3m 39s\tremaining: 6m 13s\n",
      "1850:\tlearn: 0.8789352\ttest: 1.1153635\tbest: 1.1153635 (1850)\ttotal: 3m 39s\tremaining: 6m 12s\n",
      "1851:\ttotal: 3m 39s\tremaining: 6m 12s\n",
      "1852:\ttotal: 3m 39s\tremaining: 6m 12s\n",
      "1853:\ttotal: 3m 39s\tremaining: 6m 12s\n",
      "1854:\ttotal: 3m 39s\tremaining: 6m 12s\n",
      "1855:\tlearn: 0.8779827\ttest: 1.1148927\tbest: 1.1148927 (1855)\ttotal: 3m 39s\tremaining: 6m 12s\n",
      "1856:\ttotal: 3m 39s\tremaining: 6m 12s\n",
      "1857:\ttotal: 3m 39s\tremaining: 6m 12s\n",
      "1858:\ttotal: 3m 40s\tremaining: 6m 11s\n",
      "1859:\ttotal: 3m 40s\tremaining: 6m 11s\n",
      "1860:\tlearn: 0.8770177\ttest: 1.1144539\tbest: 1.1144539 (1860)\ttotal: 3m 40s\tremaining: 6m 11s\n",
      "1861:\ttotal: 3m 40s\tremaining: 6m 11s\n",
      "1862:\ttotal: 3m 40s\tremaining: 6m 11s\n",
      "1863:\ttotal: 3m 40s\tremaining: 6m 11s\n",
      "1864:\ttotal: 3m 40s\tremaining: 6m 11s\n",
      "1865:\tlearn: 0.8761000\ttest: 1.1140867\tbest: 1.1140867 (1865)\ttotal: 3m 40s\tremaining: 6m 11s\n",
      "1866:\ttotal: 3m 41s\tremaining: 6m 10s\n",
      "1867:\ttotal: 3m 41s\tremaining: 6m 10s\n",
      "1868:\ttotal: 3m 41s\tremaining: 6m 10s\n",
      "1869:\ttotal: 3m 41s\tremaining: 6m 10s\n",
      "1870:\tlearn: 0.8751451\ttest: 1.1135303\tbest: 1.1135303 (1870)\ttotal: 3m 41s\tremaining: 6m 10s\n",
      "1871:\ttotal: 3m 41s\tremaining: 6m 10s\n",
      "1872:\ttotal: 3m 41s\tremaining: 6m 10s\n",
      "1873:\ttotal: 3m 41s\tremaining: 6m 9s\n",
      "1874:\ttotal: 3m 41s\tremaining: 6m 9s\n",
      "1875:\tlearn: 0.8742314\ttest: 1.1131663\tbest: 1.1131663 (1875)\ttotal: 3m 42s\tremaining: 6m 9s\n",
      "1876:\ttotal: 3m 42s\tremaining: 6m 9s\n",
      "1877:\ttotal: 3m 42s\tremaining: 6m 9s\n",
      "1878:\ttotal: 3m 42s\tremaining: 6m 9s\n",
      "1879:\ttotal: 3m 42s\tremaining: 6m 9s\n",
      "1880:\tlearn: 0.8732779\ttest: 1.1127252\tbest: 1.1127252 (1880)\ttotal: 3m 42s\tremaining: 6m 9s\n",
      "1881:\ttotal: 3m 42s\tremaining: 6m 8s\n",
      "1882:\ttotal: 3m 42s\tremaining: 6m 8s\n",
      "1883:\ttotal: 3m 42s\tremaining: 6m 8s\n",
      "1884:\ttotal: 3m 43s\tremaining: 6m 8s\n",
      "1885:\tlearn: 0.8722999\ttest: 1.1123459\tbest: 1.1123459 (1885)\ttotal: 3m 43s\tremaining: 6m 8s\n",
      "1886:\ttotal: 3m 43s\tremaining: 6m 8s\n",
      "1887:\ttotal: 3m 43s\tremaining: 6m 8s\n",
      "1888:\ttotal: 3m 43s\tremaining: 6m 8s\n",
      "1889:\ttotal: 3m 43s\tremaining: 6m 7s\n",
      "1890:\tlearn: 0.8714449\ttest: 1.1118697\tbest: 1.1118697 (1890)\ttotal: 3m 43s\tremaining: 6m 7s\n",
      "1891:\ttotal: 3m 43s\tremaining: 6m 7s\n",
      "1892:\ttotal: 3m 43s\tremaining: 6m 7s\n",
      "1893:\ttotal: 3m 44s\tremaining: 6m 7s\n",
      "1894:\ttotal: 3m 44s\tremaining: 6m 7s\n",
      "1895:\tlearn: 0.8704671\ttest: 1.1114437\tbest: 1.1114437 (1895)\ttotal: 3m 44s\tremaining: 6m 7s\n",
      "1896:\ttotal: 3m 44s\tremaining: 6m 7s\n",
      "1897:\ttotal: 3m 44s\tremaining: 6m 7s\n",
      "1898:\ttotal: 3m 44s\tremaining: 6m 6s\n",
      "1899:\ttotal: 3m 44s\tremaining: 6m 6s\n",
      "1900:\tlearn: 0.8695519\ttest: 1.1110216\tbest: 1.1110216 (1900)\ttotal: 3m 44s\tremaining: 6m 6s\n",
      "1901:\ttotal: 3m 45s\tremaining: 6m 6s\n",
      "1902:\ttotal: 3m 45s\tremaining: 6m 6s\n",
      "1903:\ttotal: 3m 45s\tremaining: 6m 6s\n",
      "1904:\ttotal: 3m 45s\tremaining: 6m 6s\n",
      "1905:\tlearn: 0.8686289\ttest: 1.1105201\tbest: 1.1105201 (1905)\ttotal: 3m 45s\tremaining: 6m 5s\n",
      "1906:\ttotal: 3m 45s\tremaining: 6m 5s\n",
      "1907:\ttotal: 3m 45s\tremaining: 6m 5s\n",
      "1908:\ttotal: 3m 45s\tremaining: 6m 5s\n",
      "1909:\ttotal: 3m 45s\tremaining: 6m 5s\n",
      "1910:\tlearn: 0.8676938\ttest: 1.1101060\tbest: 1.1101060 (1910)\ttotal: 3m 46s\tremaining: 6m 5s\n",
      "1911:\ttotal: 3m 46s\tremaining: 6m 5s\n",
      "1912:\ttotal: 3m 46s\tremaining: 6m 5s\n",
      "1913:\ttotal: 3m 46s\tremaining: 6m 4s\n",
      "1914:\ttotal: 3m 46s\tremaining: 6m 4s\n",
      "1915:\tlearn: 0.8667619\ttest: 1.1097609\tbest: 1.1097609 (1915)\ttotal: 3m 46s\tremaining: 6m 4s\n",
      "1916:\ttotal: 3m 46s\tremaining: 6m 4s\n",
      "1917:\ttotal: 3m 46s\tremaining: 6m 4s\n",
      "1918:\ttotal: 3m 46s\tremaining: 6m 4s\n",
      "1919:\ttotal: 3m 47s\tremaining: 6m 4s\n",
      "1920:\tlearn: 0.8658610\ttest: 1.1092610\tbest: 1.1092610 (1920)\ttotal: 3m 47s\tremaining: 6m 4s\n",
      "1921:\ttotal: 3m 47s\tremaining: 6m 3s\n",
      "1922:\ttotal: 3m 47s\tremaining: 6m 3s\n",
      "1923:\ttotal: 3m 47s\tremaining: 6m 3s\n",
      "1924:\ttotal: 3m 47s\tremaining: 6m 3s\n",
      "1925:\tlearn: 0.8649167\ttest: 1.1087513\tbest: 1.1087513 (1925)\ttotal: 3m 47s\tremaining: 6m 3s\n",
      "1926:\ttotal: 3m 47s\tremaining: 6m 3s\n",
      "1927:\ttotal: 3m 47s\tremaining: 6m 3s\n",
      "1928:\ttotal: 3m 48s\tremaining: 6m 3s\n",
      "1929:\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "1930:\tlearn: 0.8639794\ttest: 1.1083259\tbest: 1.1083259 (1930)\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "1931:\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "1932:\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "1933:\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "1934:\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "1935:\tlearn: 0.8630271\ttest: 1.1078825\tbest: 1.1078825 (1935)\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "1936:\ttotal: 3m 48s\tremaining: 6m 2s\n",
      "1937:\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "1938:\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "1939:\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "1940:\tlearn: 0.8621469\ttest: 1.1074113\tbest: 1.1074113 (1940)\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "1941:\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "1942:\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "1943:\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "1944:\ttotal: 3m 49s\tremaining: 6m 1s\n",
      "1945:\tlearn: 0.8612081\ttest: 1.1068670\tbest: 1.1068670 (1945)\ttotal: 3m 49s\tremaining: 6m\n",
      "1946:\ttotal: 3m 50s\tremaining: 6m\n",
      "1947:\ttotal: 3m 50s\tremaining: 6m\n",
      "1948:\ttotal: 3m 50s\tremaining: 6m\n",
      "1949:\ttotal: 3m 50s\tremaining: 6m\n",
      "1950:\tlearn: 0.8603219\ttest: 1.1064292\tbest: 1.1064292 (1950)\ttotal: 3m 50s\tremaining: 6m\n",
      "1951:\ttotal: 3m 50s\tremaining: 6m\n",
      "1952:\ttotal: 3m 50s\tremaining: 6m\n",
      "1953:\ttotal: 3m 50s\tremaining: 5m 59s\n",
      "1954:\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "1955:\tlearn: 0.8593674\ttest: 1.1061246\tbest: 1.1061246 (1955)\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "1956:\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "1957:\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "1958:\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "1959:\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "1960:\tlearn: 0.8584398\ttest: 1.1057390\tbest: 1.1057390 (1960)\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "1961:\ttotal: 3m 51s\tremaining: 5m 59s\n",
      "1962:\ttotal: 3m 51s\tremaining: 5m 58s\n",
      "1963:\ttotal: 3m 52s\tremaining: 5m 58s\n",
      "1964:\ttotal: 3m 52s\tremaining: 5m 58s\n",
      "1965:\tlearn: 0.8574711\ttest: 1.1052914\tbest: 1.1052914 (1965)\ttotal: 3m 52s\tremaining: 5m 58s\n",
      "1966:\ttotal: 3m 52s\tremaining: 5m 58s\n",
      "1967:\ttotal: 3m 52s\tremaining: 5m 58s\n",
      "1968:\ttotal: 3m 52s\tremaining: 5m 58s\n",
      "1969:\ttotal: 3m 52s\tremaining: 5m 58s\n",
      "1970:\tlearn: 0.8566266\ttest: 1.1048566\tbest: 1.1048566 (1970)\ttotal: 3m 52s\tremaining: 5m 57s\n",
      "1971:\ttotal: 3m 53s\tremaining: 5m 57s\n",
      "1972:\ttotal: 3m 53s\tremaining: 5m 57s\n",
      "1973:\ttotal: 3m 53s\tremaining: 5m 57s\n",
      "1974:\ttotal: 3m 53s\tremaining: 5m 57s\n",
      "1975:\tlearn: 0.8556951\ttest: 1.1044348\tbest: 1.1044348 (1975)\ttotal: 3m 53s\tremaining: 5m 57s\n",
      "1976:\ttotal: 3m 53s\tremaining: 5m 57s\n",
      "1977:\ttotal: 3m 53s\tremaining: 5m 57s\n",
      "1978:\ttotal: 3m 53s\tremaining: 5m 56s\n",
      "1979:\ttotal: 3m 53s\tremaining: 5m 56s\n",
      "1980:\tlearn: 0.8547674\ttest: 1.1040204\tbest: 1.1040204 (1980)\ttotal: 3m 54s\tremaining: 5m 56s\n",
      "1981:\ttotal: 3m 54s\tremaining: 5m 56s\n",
      "1982:\ttotal: 3m 54s\tremaining: 5m 56s\n",
      "1983:\ttotal: 3m 54s\tremaining: 5m 56s\n",
      "1984:\ttotal: 3m 54s\tremaining: 5m 56s\n",
      "1985:\tlearn: 0.8538845\ttest: 1.1036677\tbest: 1.1036677 (1985)\ttotal: 3m 54s\tremaining: 5m 56s\n",
      "1986:\ttotal: 3m 54s\tremaining: 5m 55s\n",
      "1987:\ttotal: 3m 54s\tremaining: 5m 55s\n",
      "1988:\ttotal: 3m 54s\tremaining: 5m 55s\n",
      "1989:\ttotal: 3m 55s\tremaining: 5m 55s\n",
      "1990:\tlearn: 0.8530412\ttest: 1.1032421\tbest: 1.1032421 (1990)\ttotal: 3m 55s\tremaining: 5m 55s\n",
      "1991:\ttotal: 3m 55s\tremaining: 5m 55s\n",
      "1992:\ttotal: 3m 55s\tremaining: 5m 55s\n",
      "1993:\ttotal: 3m 55s\tremaining: 5m 55s\n",
      "1994:\ttotal: 3m 55s\tremaining: 5m 54s\n",
      "1995:\tlearn: 0.8521656\ttest: 1.1027628\tbest: 1.1027628 (1995)\ttotal: 3m 55s\tremaining: 5m 54s\n",
      "1996:\ttotal: 3m 55s\tremaining: 5m 54s\n",
      "1997:\ttotal: 3m 55s\tremaining: 5m 54s\n",
      "1998:\ttotal: 3m 55s\tremaining: 5m 54s\n",
      "1999:\ttotal: 3m 56s\tremaining: 5m 54s\n",
      "2000:\tlearn: 0.8512108\ttest: 1.1022769\tbest: 1.1022769 (2000)\ttotal: 3m 56s\tremaining: 5m 54s\n",
      "2001:\ttotal: 3m 56s\tremaining: 5m 53s\n",
      "2002:\ttotal: 3m 56s\tremaining: 5m 53s\n",
      "2003:\ttotal: 3m 56s\tremaining: 5m 53s\n",
      "2004:\ttotal: 3m 56s\tremaining: 5m 53s\n",
      "2005:\tlearn: 0.8503246\ttest: 1.1018669\tbest: 1.1018669 (2005)\ttotal: 3m 56s\tremaining: 5m 53s\n",
      "2006:\ttotal: 3m 56s\tremaining: 5m 53s\n",
      "2007:\ttotal: 3m 56s\tremaining: 5m 53s\n",
      "2008:\ttotal: 3m 57s\tremaining: 5m 52s\n",
      "2009:\ttotal: 3m 57s\tremaining: 5m 52s\n",
      "2010:\tlearn: 0.8494111\ttest: 1.1013248\tbest: 1.1013248 (2010)\ttotal: 3m 57s\tremaining: 5m 52s\n",
      "2011:\ttotal: 3m 57s\tremaining: 5m 52s\n",
      "2012:\ttotal: 3m 57s\tremaining: 5m 52s\n",
      "2013:\ttotal: 3m 57s\tremaining: 5m 52s\n",
      "2014:\ttotal: 3m 57s\tremaining: 5m 52s\n",
      "2015:\tlearn: 0.8485651\ttest: 1.1009627\tbest: 1.1009627 (2015)\ttotal: 3m 57s\tremaining: 5m 52s\n",
      "2016:\ttotal: 3m 57s\tremaining: 5m 51s\n",
      "2017:\ttotal: 3m 58s\tremaining: 5m 51s\n",
      "2018:\ttotal: 3m 58s\tremaining: 5m 51s\n",
      "2019:\ttotal: 3m 58s\tremaining: 5m 51s\n",
      "2020:\tlearn: 0.8477497\ttest: 1.1006106\tbest: 1.1006106 (2020)\ttotal: 3m 58s\tremaining: 5m 51s\n",
      "2021:\ttotal: 3m 58s\tremaining: 5m 51s\n",
      "2022:\ttotal: 3m 58s\tremaining: 5m 51s\n",
      "2023:\ttotal: 3m 58s\tremaining: 5m 51s\n",
      "2024:\ttotal: 3m 58s\tremaining: 5m 50s\n",
      "2025:\tlearn: 0.8468773\ttest: 1.1002399\tbest: 1.1002399 (2025)\ttotal: 3m 58s\tremaining: 5m 50s\n",
      "2026:\ttotal: 3m 59s\tremaining: 5m 50s\n",
      "2027:\ttotal: 3m 59s\tremaining: 5m 50s\n",
      "2028:\ttotal: 3m 59s\tremaining: 5m 50s\n",
      "2029:\ttotal: 3m 59s\tremaining: 5m 50s\n",
      "2030:\tlearn: 0.8459929\ttest: 1.0999328\tbest: 1.0999328 (2030)\ttotal: 3m 59s\tremaining: 5m 50s\n",
      "2031:\ttotal: 3m 59s\tremaining: 5m 49s\n",
      "2032:\ttotal: 3m 59s\tremaining: 5m 49s\n",
      "2033:\ttotal: 3m 59s\tremaining: 5m 49s\n",
      "2034:\ttotal: 3m 59s\tremaining: 5m 49s\n",
      "2035:\tlearn: 0.8451353\ttest: 1.0996664\tbest: 1.0996664 (2035)\ttotal: 4m\tremaining: 5m 49s\n",
      "2036:\ttotal: 4m\tremaining: 5m 49s\n",
      "2037:\ttotal: 4m\tremaining: 5m 49s\n",
      "2038:\ttotal: 4m\tremaining: 5m 49s\n",
      "2039:\ttotal: 4m\tremaining: 5m 48s\n",
      "2040:\tlearn: 0.8442536\ttest: 1.0992310\tbest: 1.0992310 (2040)\ttotal: 4m\tremaining: 5m 48s\n",
      "2041:\ttotal: 4m\tremaining: 5m 48s\n",
      "2042:\ttotal: 4m\tremaining: 5m 48s\n",
      "2043:\ttotal: 4m\tremaining: 5m 48s\n",
      "2044:\ttotal: 4m 1s\tremaining: 5m 48s\n",
      "2045:\tlearn: 0.8433884\ttest: 1.0987905\tbest: 1.0987905 (2045)\ttotal: 4m 1s\tremaining: 5m 48s\n",
      "2046:\ttotal: 4m 1s\tremaining: 5m 48s\n",
      "2047:\ttotal: 4m 1s\tremaining: 5m 47s\n",
      "2048:\ttotal: 4m 1s\tremaining: 5m 47s\n",
      "2049:\ttotal: 4m 1s\tremaining: 5m 47s\n",
      "2050:\tlearn: 0.8425604\ttest: 1.0983193\tbest: 1.0983193 (2050)\ttotal: 4m 1s\tremaining: 5m 47s\n",
      "2051:\ttotal: 4m 1s\tremaining: 5m 47s\n",
      "2052:\ttotal: 4m 1s\tremaining: 5m 47s\n",
      "2053:\ttotal: 4m 2s\tremaining: 5m 47s\n",
      "2054:\ttotal: 4m 2s\tremaining: 5m 47s\n",
      "2055:\tlearn: 0.8417084\ttest: 1.0979710\tbest: 1.0979710 (2055)\ttotal: 4m 2s\tremaining: 5m 46s\n",
      "2056:\ttotal: 4m 2s\tremaining: 5m 46s\n",
      "2057:\ttotal: 4m 2s\tremaining: 5m 46s\n",
      "2058:\ttotal: 4m 2s\tremaining: 5m 46s\n",
      "2059:\ttotal: 4m 2s\tremaining: 5m 46s\n",
      "2060:\tlearn: 0.8408687\ttest: 1.0974129\tbest: 1.0974129 (2060)\ttotal: 4m 2s\tremaining: 5m 46s\n",
      "2061:\ttotal: 4m 3s\tremaining: 5m 46s\n",
      "2062:\ttotal: 4m 3s\tremaining: 5m 46s\n",
      "2063:\ttotal: 4m 3s\tremaining: 5m 46s\n",
      "2064:\ttotal: 4m 3s\tremaining: 5m 45s\n",
      "2065:\tlearn: 0.8399443\ttest: 1.0970676\tbest: 1.0970676 (2065)\ttotal: 4m 3s\tremaining: 5m 45s\n",
      "2066:\ttotal: 4m 3s\tremaining: 5m 45s\n",
      "2067:\ttotal: 4m 3s\tremaining: 5m 45s\n",
      "2068:\ttotal: 4m 3s\tremaining: 5m 45s\n",
      "2069:\ttotal: 4m 3s\tremaining: 5m 45s\n",
      "2070:\tlearn: 0.8391130\ttest: 1.0966794\tbest: 1.0966794 (2070)\ttotal: 4m 4s\tremaining: 5m 45s\n",
      "2071:\ttotal: 4m 4s\tremaining: 5m 45s\n",
      "2072:\ttotal: 4m 4s\tremaining: 5m 44s\n",
      "2073:\ttotal: 4m 4s\tremaining: 5m 44s\n",
      "2074:\ttotal: 4m 4s\tremaining: 5m 44s\n",
      "2075:\tlearn: 0.8382267\ttest: 1.0962227\tbest: 1.0962227 (2075)\ttotal: 4m 4s\tremaining: 5m 44s\n",
      "2076:\ttotal: 4m 4s\tremaining: 5m 44s\n",
      "2077:\ttotal: 4m 4s\tremaining: 5m 44s\n",
      "2078:\ttotal: 4m 5s\tremaining: 5m 44s\n",
      "2079:\ttotal: 4m 5s\tremaining: 5m 44s\n",
      "2080:\tlearn: 0.8373580\ttest: 1.0957768\tbest: 1.0957768 (2080)\ttotal: 4m 5s\tremaining: 5m 43s\n",
      "2081:\ttotal: 4m 5s\tremaining: 5m 43s\n",
      "2082:\ttotal: 4m 5s\tremaining: 5m 43s\n",
      "2083:\ttotal: 4m 5s\tremaining: 5m 43s\n",
      "2084:\ttotal: 4m 5s\tremaining: 5m 43s\n",
      "2085:\tlearn: 0.8365159\ttest: 1.0953345\tbest: 1.0953345 (2085)\ttotal: 4m 5s\tremaining: 5m 43s\n",
      "2086:\ttotal: 4m 5s\tremaining: 5m 43s\n",
      "2087:\ttotal: 4m 5s\tremaining: 5m 42s\n",
      "2088:\ttotal: 4m 6s\tremaining: 5m 42s\n",
      "2089:\ttotal: 4m 6s\tremaining: 5m 42s\n",
      "2090:\tlearn: 0.8356870\ttest: 1.0950322\tbest: 1.0950322 (2090)\ttotal: 4m 6s\tremaining: 5m 42s\n",
      "2091:\ttotal: 4m 6s\tremaining: 5m 42s\n",
      "2092:\ttotal: 4m 6s\tremaining: 5m 42s\n",
      "2093:\ttotal: 4m 6s\tremaining: 5m 42s\n",
      "2094:\ttotal: 4m 6s\tremaining: 5m 42s\n",
      "2095:\tlearn: 0.8348348\ttest: 1.0946619\tbest: 1.0946619 (2095)\ttotal: 4m 6s\tremaining: 5m 41s\n",
      "2096:\ttotal: 4m 6s\tremaining: 5m 41s\n",
      "2097:\ttotal: 4m 7s\tremaining: 5m 41s\n",
      "2098:\ttotal: 4m 7s\tremaining: 5m 41s\n",
      "2099:\ttotal: 4m 7s\tremaining: 5m 41s\n",
      "2100:\tlearn: 0.8339819\ttest: 1.0943210\tbest: 1.0943210 (2100)\ttotal: 4m 7s\tremaining: 5m 41s\n",
      "2101:\ttotal: 4m 7s\tremaining: 5m 41s\n",
      "2102:\ttotal: 4m 7s\tremaining: 5m 41s\n",
      "2103:\ttotal: 4m 7s\tremaining: 5m 40s\n",
      "2104:\ttotal: 4m 7s\tremaining: 5m 40s\n",
      "2105:\tlearn: 0.8331360\ttest: 1.0937894\tbest: 1.0937894 (2105)\ttotal: 4m 7s\tremaining: 5m 40s\n",
      "2106:\ttotal: 4m 8s\tremaining: 5m 40s\n",
      "2107:\ttotal: 4m 8s\tremaining: 5m 40s\n",
      "2108:\ttotal: 4m 8s\tremaining: 5m 40s\n",
      "2109:\ttotal: 4m 8s\tremaining: 5m 40s\n",
      "2110:\tlearn: 0.8322814\ttest: 1.0933359\tbest: 1.0933359 (2110)\ttotal: 4m 8s\tremaining: 5m 39s\n",
      "2111:\ttotal: 4m 8s\tremaining: 5m 39s\n",
      "2112:\ttotal: 4m 8s\tremaining: 5m 39s\n",
      "2113:\ttotal: 4m 8s\tremaining: 5m 39s\n",
      "2114:\ttotal: 4m 8s\tremaining: 5m 39s\n",
      "2115:\tlearn: 0.8314447\ttest: 1.0929919\tbest: 1.0929919 (2115)\ttotal: 4m 8s\tremaining: 5m 39s\n",
      "2116:\ttotal: 4m 9s\tremaining: 5m 39s\n",
      "2117:\ttotal: 4m 9s\tremaining: 5m 39s\n",
      "2118:\ttotal: 4m 9s\tremaining: 5m 38s\n",
      "2119:\ttotal: 4m 9s\tremaining: 5m 38s\n",
      "2120:\tlearn: 0.8306383\ttest: 1.0926036\tbest: 1.0926036 (2120)\ttotal: 4m 9s\tremaining: 5m 38s\n",
      "2121:\ttotal: 4m 9s\tremaining: 5m 38s\n",
      "2122:\ttotal: 4m 9s\tremaining: 5m 38s\n",
      "2123:\ttotal: 4m 9s\tremaining: 5m 38s\n",
      "2124:\ttotal: 4m 9s\tremaining: 5m 38s\n",
      "2125:\tlearn: 0.8297707\ttest: 1.0922481\tbest: 1.0922481 (2125)\ttotal: 4m 10s\tremaining: 5m 38s\n",
      "2126:\ttotal: 4m 10s\tremaining: 5m 37s\n",
      "2127:\ttotal: 4m 10s\tremaining: 5m 37s\n",
      "2128:\ttotal: 4m 10s\tremaining: 5m 37s\n",
      "2129:\ttotal: 4m 10s\tremaining: 5m 37s\n",
      "2130:\tlearn: 0.8289839\ttest: 1.0917979\tbest: 1.0917979 (2130)\ttotal: 4m 10s\tremaining: 5m 37s\n",
      "2131:\ttotal: 4m 10s\tremaining: 5m 37s\n",
      "2132:\ttotal: 4m 10s\tremaining: 5m 37s\n",
      "2133:\ttotal: 4m 10s\tremaining: 5m 36s\n",
      "2134:\ttotal: 4m 10s\tremaining: 5m 36s\n",
      "2135:\tlearn: 0.8281728\ttest: 1.0914400\tbest: 1.0914400 (2135)\ttotal: 4m 11s\tremaining: 5m 36s\n",
      "2136:\ttotal: 4m 11s\tremaining: 5m 36s\n",
      "2137:\ttotal: 4m 11s\tremaining: 5m 36s\n",
      "2138:\ttotal: 4m 11s\tremaining: 5m 36s\n",
      "2139:\ttotal: 4m 11s\tremaining: 5m 36s\n",
      "2140:\tlearn: 0.8273189\ttest: 1.0910063\tbest: 1.0910063 (2140)\ttotal: 4m 11s\tremaining: 5m 36s\n",
      "2141:\ttotal: 4m 11s\tremaining: 5m 35s\n",
      "2142:\ttotal: 4m 11s\tremaining: 5m 35s\n",
      "2143:\ttotal: 4m 11s\tremaining: 5m 35s\n",
      "2144:\ttotal: 4m 12s\tremaining: 5m 35s\n",
      "2145:\tlearn: 0.8264093\ttest: 1.0906712\tbest: 1.0906712 (2145)\ttotal: 4m 12s\tremaining: 5m 35s\n",
      "2146:\ttotal: 4m 12s\tremaining: 5m 35s\n",
      "2147:\ttotal: 4m 12s\tremaining: 5m 35s\n",
      "2148:\ttotal: 4m 12s\tremaining: 5m 35s\n",
      "2149:\ttotal: 4m 12s\tremaining: 5m 34s\n",
      "2150:\tlearn: 0.8255633\ttest: 1.0902461\tbest: 1.0902461 (2150)\ttotal: 4m 12s\tremaining: 5m 34s\n",
      "2151:\ttotal: 4m 12s\tremaining: 5m 34s\n",
      "2152:\ttotal: 4m 12s\tremaining: 5m 34s\n",
      "2153:\ttotal: 4m 13s\tremaining: 5m 34s\n",
      "2154:\ttotal: 4m 13s\tremaining: 5m 34s\n",
      "2155:\tlearn: 0.8247163\ttest: 1.0898957\tbest: 1.0898957 (2155)\ttotal: 4m 13s\tremaining: 5m 34s\n",
      "2156:\ttotal: 4m 13s\tremaining: 5m 34s\n",
      "2157:\ttotal: 4m 13s\tremaining: 5m 33s\n",
      "2158:\ttotal: 4m 13s\tremaining: 5m 33s\n",
      "2159:\ttotal: 4m 13s\tremaining: 5m 33s\n",
      "2160:\tlearn: 0.8238870\ttest: 1.0895600\tbest: 1.0895600 (2160)\ttotal: 4m 13s\tremaining: 5m 33s\n",
      "2161:\ttotal: 4m 13s\tremaining: 5m 33s\n",
      "2162:\ttotal: 4m 14s\tremaining: 5m 33s\n",
      "2163:\ttotal: 4m 14s\tremaining: 5m 33s\n",
      "2164:\ttotal: 4m 14s\tremaining: 5m 33s\n",
      "2165:\tlearn: 0.8230250\ttest: 1.0891599\tbest: 1.0891599 (2165)\ttotal: 4m 14s\tremaining: 5m 32s\n",
      "2166:\ttotal: 4m 14s\tremaining: 5m 32s\n",
      "2167:\ttotal: 4m 14s\tremaining: 5m 32s\n",
      "2168:\ttotal: 4m 14s\tremaining: 5m 32s\n",
      "2169:\ttotal: 4m 14s\tremaining: 5m 32s\n",
      "2170:\tlearn: 0.8222289\ttest: 1.0887704\tbest: 1.0887704 (2170)\ttotal: 4m 14s\tremaining: 5m 32s\n",
      "2171:\ttotal: 4m 15s\tremaining: 5m 32s\n",
      "2172:\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "2173:\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "2174:\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "2175:\tlearn: 0.8213590\ttest: 1.0884405\tbest: 1.0884405 (2175)\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "2176:\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "2177:\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "2178:\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "2179:\ttotal: 4m 15s\tremaining: 5m 31s\n",
      "2180:\tlearn: 0.8205458\ttest: 1.0880453\tbest: 1.0880453 (2180)\ttotal: 4m 16s\tremaining: 5m 30s\n",
      "2181:\ttotal: 4m 16s\tremaining: 5m 30s\n",
      "2182:\ttotal: 4m 16s\tremaining: 5m 30s\n",
      "2183:\ttotal: 4m 16s\tremaining: 5m 30s\n",
      "2184:\ttotal: 4m 16s\tremaining: 5m 30s\n",
      "2185:\tlearn: 0.8197430\ttest: 1.0876917\tbest: 1.0876917 (2185)\ttotal: 4m 16s\tremaining: 5m 30s\n",
      "2186:\ttotal: 4m 16s\tremaining: 5m 30s\n",
      "2187:\ttotal: 4m 16s\tremaining: 5m 30s\n",
      "2188:\ttotal: 4m 16s\tremaining: 5m 29s\n",
      "2189:\ttotal: 4m 17s\tremaining: 5m 29s\n",
      "2190:\tlearn: 0.8188815\ttest: 1.0873706\tbest: 1.0873706 (2190)\ttotal: 4m 17s\tremaining: 5m 29s\n",
      "2191:\ttotal: 4m 17s\tremaining: 5m 29s\n",
      "2192:\ttotal: 4m 17s\tremaining: 5m 29s\n",
      "2193:\ttotal: 4m 17s\tremaining: 5m 29s\n",
      "2194:\ttotal: 4m 17s\tremaining: 5m 29s\n",
      "2195:\tlearn: 0.8179508\ttest: 1.0870469\tbest: 1.0870469 (2195)\ttotal: 4m 17s\tremaining: 5m 29s\n",
      "2196:\ttotal: 4m 17s\tremaining: 5m 28s\n",
      "2197:\ttotal: 4m 17s\tremaining: 5m 28s\n",
      "2198:\ttotal: 4m 18s\tremaining: 5m 28s\n",
      "2199:\ttotal: 4m 18s\tremaining: 5m 28s\n",
      "2200:\tlearn: 0.8171264\ttest: 1.0867170\tbest: 1.0867170 (2200)\ttotal: 4m 18s\tremaining: 5m 28s\n",
      "2201:\ttotal: 4m 18s\tremaining: 5m 28s\n",
      "2202:\ttotal: 4m 18s\tremaining: 5m 28s\n",
      "2203:\ttotal: 4m 18s\tremaining: 5m 28s\n",
      "2204:\ttotal: 4m 18s\tremaining: 5m 27s\n",
      "2205:\tlearn: 0.8163041\ttest: 1.0862805\tbest: 1.0862805 (2205)\ttotal: 4m 18s\tremaining: 5m 27s\n",
      "2206:\ttotal: 4m 18s\tremaining: 5m 27s\n",
      "2207:\ttotal: 4m 19s\tremaining: 5m 27s\n",
      "2208:\ttotal: 4m 19s\tremaining: 5m 27s\n",
      "2209:\ttotal: 4m 19s\tremaining: 5m 27s\n",
      "2210:\tlearn: 0.8155376\ttest: 1.0859384\tbest: 1.0859384 (2210)\ttotal: 4m 19s\tremaining: 5m 27s\n",
      "2211:\ttotal: 4m 19s\tremaining: 5m 27s\n",
      "2212:\ttotal: 4m 19s\tremaining: 5m 26s\n",
      "2213:\ttotal: 4m 19s\tremaining: 5m 26s\n",
      "2214:\ttotal: 4m 19s\tremaining: 5m 26s\n",
      "2215:\tlearn: 0.8147620\ttest: 1.0855762\tbest: 1.0855762 (2215)\ttotal: 4m 19s\tremaining: 5m 26s\n",
      "2216:\ttotal: 4m 20s\tremaining: 5m 26s\n",
      "2217:\ttotal: 4m 20s\tremaining: 5m 26s\n",
      "2218:\ttotal: 4m 20s\tremaining: 5m 26s\n",
      "2219:\ttotal: 4m 20s\tremaining: 5m 26s\n",
      "2220:\tlearn: 0.8139933\ttest: 1.0853547\tbest: 1.0853547 (2220)\ttotal: 4m 20s\tremaining: 5m 26s\n",
      "2221:\ttotal: 4m 20s\tremaining: 5m 25s\n",
      "2222:\ttotal: 4m 20s\tremaining: 5m 25s\n",
      "2223:\ttotal: 4m 20s\tremaining: 5m 25s\n",
      "2224:\ttotal: 4m 21s\tremaining: 5m 25s\n",
      "2225:\tlearn: 0.8132351\ttest: 1.0849801\tbest: 1.0849801 (2225)\ttotal: 4m 21s\tremaining: 5m 25s\n",
      "2226:\ttotal: 4m 21s\tremaining: 5m 25s\n",
      "2227:\ttotal: 4m 21s\tremaining: 5m 25s\n",
      "2228:\ttotal: 4m 21s\tremaining: 5m 25s\n",
      "2229:\ttotal: 4m 21s\tremaining: 5m 24s\n",
      "2230:\tlearn: 0.8124558\ttest: 1.0845502\tbest: 1.0845502 (2230)\ttotal: 4m 21s\tremaining: 5m 24s\n",
      "2231:\ttotal: 4m 21s\tremaining: 5m 24s\n",
      "2232:\ttotal: 4m 21s\tremaining: 5m 24s\n",
      "2233:\ttotal: 4m 22s\tremaining: 5m 24s\n",
      "2234:\ttotal: 4m 22s\tremaining: 5m 24s\n",
      "2235:\tlearn: 0.8116473\ttest: 1.0841949\tbest: 1.0841949 (2235)\ttotal: 4m 22s\tremaining: 5m 24s\n",
      "2236:\ttotal: 4m 22s\tremaining: 5m 24s\n",
      "2237:\ttotal: 4m 22s\tremaining: 5m 23s\n",
      "2238:\ttotal: 4m 22s\tremaining: 5m 23s\n",
      "2239:\ttotal: 4m 22s\tremaining: 5m 23s\n",
      "2240:\tlearn: 0.8108654\ttest: 1.0837583\tbest: 1.0837583 (2240)\ttotal: 4m 22s\tremaining: 5m 23s\n",
      "2241:\ttotal: 4m 22s\tremaining: 5m 23s\n",
      "2242:\ttotal: 4m 22s\tremaining: 5m 23s\n",
      "2243:\ttotal: 4m 23s\tremaining: 5m 23s\n",
      "2244:\ttotal: 4m 23s\tremaining: 5m 22s\n",
      "2245:\tlearn: 0.8100592\ttest: 1.0834340\tbest: 1.0834340 (2245)\ttotal: 4m 23s\tremaining: 5m 22s\n",
      "2246:\ttotal: 4m 23s\tremaining: 5m 22s\n",
      "2247:\ttotal: 4m 23s\tremaining: 5m 22s\n",
      "2248:\ttotal: 4m 23s\tremaining: 5m 22s\n",
      "2249:\ttotal: 4m 23s\tremaining: 5m 22s\n",
      "2250:\tlearn: 0.8092594\ttest: 1.0830769\tbest: 1.0830769 (2250)\ttotal: 4m 23s\tremaining: 5m 22s\n",
      "2251:\ttotal: 4m 23s\tremaining: 5m 22s\n",
      "2252:\ttotal: 4m 24s\tremaining: 5m 21s\n",
      "2253:\ttotal: 4m 24s\tremaining: 5m 21s\n",
      "2254:\ttotal: 4m 24s\tremaining: 5m 21s\n",
      "2255:\tlearn: 0.8084710\ttest: 1.0827457\tbest: 1.0827457 (2255)\ttotal: 4m 24s\tremaining: 5m 21s\n",
      "2256:\ttotal: 4m 24s\tremaining: 5m 21s\n",
      "2257:\ttotal: 4m 24s\tremaining: 5m 21s\n",
      "2258:\ttotal: 4m 24s\tremaining: 5m 21s\n",
      "2259:\ttotal: 4m 24s\tremaining: 5m 20s\n",
      "2260:\tlearn: 0.8076387\ttest: 1.0823842\tbest: 1.0823842 (2260)\ttotal: 4m 24s\tremaining: 5m 20s\n",
      "2261:\ttotal: 4m 24s\tremaining: 5m 20s\n",
      "2262:\ttotal: 4m 25s\tremaining: 5m 20s\n",
      "2263:\ttotal: 4m 25s\tremaining: 5m 20s\n",
      "2264:\ttotal: 4m 25s\tremaining: 5m 20s\n",
      "2265:\tlearn: 0.8068388\ttest: 1.0820190\tbest: 1.0820190 (2265)\ttotal: 4m 25s\tremaining: 5m 20s\n",
      "2266:\ttotal: 4m 25s\tremaining: 5m 19s\n",
      "2267:\ttotal: 4m 25s\tremaining: 5m 19s\n",
      "2268:\ttotal: 4m 25s\tremaining: 5m 19s\n",
      "2269:\ttotal: 4m 25s\tremaining: 5m 19s\n",
      "2270:\tlearn: 0.8061321\ttest: 1.0816505\tbest: 1.0816505 (2270)\ttotal: 4m 25s\tremaining: 5m 19s\n",
      "2271:\ttotal: 4m 25s\tremaining: 5m 19s\n",
      "2272:\ttotal: 4m 26s\tremaining: 5m 19s\n",
      "2273:\ttotal: 4m 26s\tremaining: 5m 19s\n",
      "2274:\ttotal: 4m 26s\tremaining: 5m 18s\n",
      "2275:\tlearn: 0.8053769\ttest: 1.0813207\tbest: 1.0813207 (2275)\ttotal: 4m 26s\tremaining: 5m 18s\n",
      "2276:\ttotal: 4m 26s\tremaining: 5m 18s\n",
      "2277:\ttotal: 4m 26s\tremaining: 5m 18s\n",
      "2278:\ttotal: 4m 26s\tremaining: 5m 18s\n",
      "2279:\ttotal: 4m 26s\tremaining: 5m 18s\n",
      "2280:\tlearn: 0.8045759\ttest: 1.0810130\tbest: 1.0810130 (2280)\ttotal: 4m 26s\tremaining: 5m 18s\n",
      "2281:\ttotal: 4m 27s\tremaining: 5m 18s\n",
      "2282:\ttotal: 4m 27s\tremaining: 5m 17s\n",
      "2283:\ttotal: 4m 27s\tremaining: 5m 17s\n",
      "2284:\ttotal: 4m 27s\tremaining: 5m 17s\n",
      "2285:\tlearn: 0.8038492\ttest: 1.0806316\tbest: 1.0806316 (2285)\ttotal: 4m 27s\tremaining: 5m 17s\n",
      "2286:\ttotal: 4m 27s\tremaining: 5m 17s\n",
      "2287:\ttotal: 4m 27s\tremaining: 5m 17s\n",
      "2288:\ttotal: 4m 27s\tremaining: 5m 17s\n",
      "2289:\ttotal: 4m 27s\tremaining: 5m 16s\n",
      "2290:\tlearn: 0.8031310\ttest: 1.0803842\tbest: 1.0803842 (2290)\ttotal: 4m 27s\tremaining: 5m 16s\n",
      "2291:\ttotal: 4m 28s\tremaining: 5m 16s\n",
      "2292:\ttotal: 4m 28s\tremaining: 5m 16s\n",
      "2293:\ttotal: 4m 28s\tremaining: 5m 16s\n",
      "2294:\ttotal: 4m 28s\tremaining: 5m 16s\n",
      "2295:\tlearn: 0.8023693\ttest: 1.0800346\tbest: 1.0800346 (2295)\ttotal: 4m 28s\tremaining: 5m 16s\n",
      "2296:\ttotal: 4m 28s\tremaining: 5m 16s\n",
      "2297:\ttotal: 4m 28s\tremaining: 5m 15s\n",
      "2298:\ttotal: 4m 28s\tremaining: 5m 15s\n",
      "2299:\ttotal: 4m 28s\tremaining: 5m 15s\n",
      "2300:\tlearn: 0.8015918\ttest: 1.0797120\tbest: 1.0797120 (2300)\ttotal: 4m 29s\tremaining: 5m 15s\n",
      "2301:\ttotal: 4m 29s\tremaining: 5m 15s\n",
      "2302:\ttotal: 4m 29s\tremaining: 5m 15s\n",
      "2303:\ttotal: 4m 29s\tremaining: 5m 15s\n",
      "2304:\ttotal: 4m 29s\tremaining: 5m 15s\n",
      "2305:\tlearn: 0.8008177\ttest: 1.0794822\tbest: 1.0794822 (2305)\ttotal: 4m 29s\tremaining: 5m 15s\n",
      "2306:\ttotal: 4m 29s\tremaining: 5m 14s\n",
      "2307:\ttotal: 4m 29s\tremaining: 5m 14s\n",
      "2308:\ttotal: 4m 29s\tremaining: 5m 14s\n",
      "2309:\ttotal: 4m 30s\tremaining: 5m 14s\n",
      "2310:\tlearn: 0.8000735\ttest: 1.0791847\tbest: 1.0791847 (2310)\ttotal: 4m 30s\tremaining: 5m 14s\n",
      "2311:\ttotal: 4m 30s\tremaining: 5m 14s\n",
      "2312:\ttotal: 4m 30s\tremaining: 5m 14s\n",
      "2313:\ttotal: 4m 30s\tremaining: 5m 13s\n",
      "2314:\ttotal: 4m 30s\tremaining: 5m 13s\n",
      "2315:\tlearn: 0.7993309\ttest: 1.0789312\tbest: 1.0789312 (2315)\ttotal: 4m 30s\tremaining: 5m 13s\n",
      "2316:\ttotal: 4m 30s\tremaining: 5m 13s\n",
      "2317:\ttotal: 4m 30s\tremaining: 5m 13s\n",
      "2318:\ttotal: 4m 31s\tremaining: 5m 13s\n",
      "2319:\ttotal: 4m 31s\tremaining: 5m 13s\n",
      "2320:\tlearn: 0.7985566\ttest: 1.0786969\tbest: 1.0786969 (2320)\ttotal: 4m 31s\tremaining: 5m 13s\n",
      "2321:\ttotal: 4m 31s\tremaining: 5m 13s\n",
      "2322:\ttotal: 4m 31s\tremaining: 5m 12s\n",
      "2323:\ttotal: 4m 31s\tremaining: 5m 12s\n",
      "2324:\ttotal: 4m 31s\tremaining: 5m 12s\n",
      "2325:\tlearn: 0.7978197\ttest: 1.0783478\tbest: 1.0783478 (2325)\ttotal: 4m 31s\tremaining: 5m 12s\n",
      "2326:\ttotal: 4m 31s\tremaining: 5m 12s\n",
      "2327:\ttotal: 4m 32s\tremaining: 5m 12s\n",
      "2328:\ttotal: 4m 32s\tremaining: 5m 12s\n",
      "2329:\ttotal: 4m 32s\tremaining: 5m 12s\n",
      "2330:\tlearn: 0.7970596\ttest: 1.0780166\tbest: 1.0780166 (2330)\ttotal: 4m 32s\tremaining: 5m 11s\n",
      "2331:\ttotal: 4m 32s\tremaining: 5m 11s\n",
      "2332:\ttotal: 4m 32s\tremaining: 5m 11s\n",
      "2333:\ttotal: 4m 32s\tremaining: 5m 11s\n",
      "2334:\ttotal: 4m 32s\tremaining: 5m 11s\n",
      "2335:\tlearn: 0.7962995\ttest: 1.0777134\tbest: 1.0777134 (2335)\ttotal: 4m 32s\tremaining: 5m 11s\n",
      "2336:\ttotal: 4m 33s\tremaining: 5m 11s\n",
      "2337:\ttotal: 4m 33s\tremaining: 5m 10s\n",
      "2338:\ttotal: 4m 33s\tremaining: 5m 10s\n",
      "2339:\ttotal: 4m 33s\tremaining: 5m 10s\n",
      "2340:\tlearn: 0.7955648\ttest: 1.0773802\tbest: 1.0773802 (2340)\ttotal: 4m 33s\tremaining: 5m 10s\n",
      "2341:\ttotal: 4m 33s\tremaining: 5m 10s\n",
      "2342:\ttotal: 4m 33s\tremaining: 5m 10s\n",
      "2343:\ttotal: 4m 33s\tremaining: 5m 10s\n",
      "2344:\ttotal: 4m 33s\tremaining: 5m 10s\n",
      "2345:\tlearn: 0.7948210\ttest: 1.0769813\tbest: 1.0769813 (2345)\ttotal: 4m 33s\tremaining: 5m 9s\n",
      "2346:\ttotal: 4m 34s\tremaining: 5m 9s\n",
      "2347:\ttotal: 4m 34s\tremaining: 5m 9s\n",
      "2348:\ttotal: 4m 34s\tremaining: 5m 9s\n",
      "2349:\ttotal: 4m 34s\tremaining: 5m 9s\n",
      "2350:\tlearn: 0.7941087\ttest: 1.0767127\tbest: 1.0767127 (2350)\ttotal: 4m 34s\tremaining: 5m 9s\n",
      "2351:\ttotal: 4m 34s\tremaining: 5m 9s\n",
      "2352:\ttotal: 4m 34s\tremaining: 5m 9s\n",
      "2353:\ttotal: 4m 34s\tremaining: 5m 8s\n",
      "2354:\ttotal: 4m 34s\tremaining: 5m 8s\n",
      "2355:\tlearn: 0.7933589\ttest: 1.0764581\tbest: 1.0764581 (2355)\ttotal: 4m 35s\tremaining: 5m 8s\n",
      "2356:\ttotal: 4m 35s\tremaining: 5m 8s\n",
      "2357:\ttotal: 4m 35s\tremaining: 5m 8s\n",
      "2358:\ttotal: 4m 35s\tremaining: 5m 8s\n",
      "2359:\ttotal: 4m 35s\tremaining: 5m 8s\n",
      "2360:\tlearn: 0.7925717\ttest: 1.0762260\tbest: 1.0762260 (2360)\ttotal: 4m 35s\tremaining: 5m 8s\n",
      "2361:\ttotal: 4m 35s\tremaining: 5m 7s\n",
      "2362:\ttotal: 4m 35s\tremaining: 5m 7s\n",
      "2363:\ttotal: 4m 35s\tremaining: 5m 7s\n",
      "2364:\ttotal: 4m 36s\tremaining: 5m 7s\n",
      "2365:\tlearn: 0.7918144\ttest: 1.0759183\tbest: 1.0759183 (2365)\ttotal: 4m 36s\tremaining: 5m 7s\n",
      "2366:\ttotal: 4m 36s\tremaining: 5m 7s\n",
      "2367:\ttotal: 4m 36s\tremaining: 5m 7s\n",
      "2368:\ttotal: 4m 36s\tremaining: 5m 7s\n",
      "2369:\ttotal: 4m 36s\tremaining: 5m 6s\n",
      "2370:\tlearn: 0.7911096\ttest: 1.0755615\tbest: 1.0755615 (2370)\ttotal: 4m 36s\tremaining: 5m 6s\n",
      "2371:\ttotal: 4m 36s\tremaining: 5m 6s\n",
      "2372:\ttotal: 4m 36s\tremaining: 5m 6s\n",
      "2373:\ttotal: 4m 37s\tremaining: 5m 6s\n",
      "2374:\ttotal: 4m 37s\tremaining: 5m 6s\n",
      "2375:\tlearn: 0.7903130\ttest: 1.0752900\tbest: 1.0752900 (2375)\ttotal: 4m 37s\tremaining: 5m 6s\n",
      "2376:\ttotal: 4m 37s\tremaining: 5m 6s\n",
      "2377:\ttotal: 4m 37s\tremaining: 5m 5s\n",
      "2378:\ttotal: 4m 37s\tremaining: 5m 5s\n",
      "2379:\ttotal: 4m 37s\tremaining: 5m 5s\n",
      "2380:\tlearn: 0.7896392\ttest: 1.0749090\tbest: 1.0749090 (2380)\ttotal: 4m 37s\tremaining: 5m 5s\n",
      "2381:\ttotal: 4m 37s\tremaining: 5m 5s\n",
      "2382:\ttotal: 4m 37s\tremaining: 5m 5s\n",
      "2383:\ttotal: 4m 38s\tremaining: 5m 5s\n",
      "2384:\ttotal: 4m 38s\tremaining: 5m 4s\n",
      "2385:\tlearn: 0.7889459\ttest: 1.0746816\tbest: 1.0746816 (2385)\ttotal: 4m 38s\tremaining: 5m 4s\n",
      "2386:\ttotal: 4m 38s\tremaining: 5m 4s\n",
      "2387:\ttotal: 4m 38s\tremaining: 5m 4s\n",
      "2388:\ttotal: 4m 38s\tremaining: 5m 4s\n",
      "2389:\ttotal: 4m 38s\tremaining: 5m 4s\n",
      "2390:\tlearn: 0.7881873\ttest: 1.0743386\tbest: 1.0743386 (2390)\ttotal: 4m 38s\tremaining: 5m 4s\n",
      "2391:\ttotal: 4m 38s\tremaining: 5m 4s\n",
      "2392:\ttotal: 4m 39s\tremaining: 5m 4s\n",
      "2393:\ttotal: 4m 39s\tremaining: 5m 3s\n",
      "2394:\ttotal: 4m 39s\tremaining: 5m 3s\n",
      "2395:\tlearn: 0.7874696\ttest: 1.0740152\tbest: 1.0740152 (2395)\ttotal: 4m 39s\tremaining: 5m 3s\n",
      "2396:\ttotal: 4m 39s\tremaining: 5m 3s\n",
      "2397:\ttotal: 4m 39s\tremaining: 5m 3s\n",
      "2398:\ttotal: 4m 39s\tremaining: 5m 3s\n",
      "2399:\ttotal: 4m 39s\tremaining: 5m 3s\n",
      "2400:\tlearn: 0.7867538\ttest: 1.0736513\tbest: 1.0736513 (2400)\ttotal: 4m 39s\tremaining: 5m 2s\n",
      "2401:\ttotal: 4m 39s\tremaining: 5m 2s\n",
      "2402:\ttotal: 4m 40s\tremaining: 5m 2s\n",
      "2403:\ttotal: 4m 40s\tremaining: 5m 2s\n",
      "2404:\ttotal: 4m 40s\tremaining: 5m 2s\n",
      "2405:\tlearn: 0.7859906\ttest: 1.0733568\tbest: 1.0733568 (2405)\ttotal: 4m 40s\tremaining: 5m 2s\n",
      "2406:\ttotal: 4m 40s\tremaining: 5m 2s\n",
      "2407:\ttotal: 4m 40s\tremaining: 5m 2s\n",
      "2408:\ttotal: 4m 40s\tremaining: 5m 1s\n",
      "2409:\ttotal: 4m 40s\tremaining: 5m 1s\n",
      "2410:\tlearn: 0.7852728\ttest: 1.0729167\tbest: 1.0729167 (2410)\ttotal: 4m 40s\tremaining: 5m 1s\n",
      "2411:\ttotal: 4m 41s\tremaining: 5m 1s\n",
      "2412:\ttotal: 4m 41s\tremaining: 5m 1s\n",
      "2413:\ttotal: 4m 41s\tremaining: 5m 1s\n",
      "2414:\ttotal: 4m 41s\tremaining: 5m 1s\n",
      "2415:\tlearn: 0.7845856\ttest: 1.0726528\tbest: 1.0726528 (2415)\ttotal: 4m 41s\tremaining: 5m 1s\n",
      "2416:\ttotal: 4m 41s\tremaining: 5m\n",
      "2417:\ttotal: 4m 41s\tremaining: 5m\n",
      "2418:\ttotal: 4m 41s\tremaining: 5m\n",
      "2419:\ttotal: 4m 41s\tremaining: 5m\n",
      "2420:\tlearn: 0.7838464\ttest: 1.0724009\tbest: 1.0724009 (2420)\ttotal: 4m 42s\tremaining: 5m\n",
      "2421:\ttotal: 4m 42s\tremaining: 5m\n",
      "2422:\ttotal: 4m 42s\tremaining: 5m\n",
      "2423:\ttotal: 4m 42s\tremaining: 5m\n",
      "2424:\ttotal: 4m 42s\tremaining: 5m\n",
      "2425:\tlearn: 0.7831526\ttest: 1.0721491\tbest: 1.0721491 (2425)\ttotal: 4m 42s\tremaining: 4m 59s\n",
      "2426:\ttotal: 4m 42s\tremaining: 4m 59s\n",
      "2427:\ttotal: 4m 42s\tremaining: 4m 59s\n",
      "2428:\ttotal: 4m 43s\tremaining: 4m 59s\n",
      "2429:\ttotal: 4m 43s\tremaining: 4m 59s\n",
      "2430:\tlearn: 0.7824548\ttest: 1.0718168\tbest: 1.0718168 (2430)\ttotal: 4m 43s\tremaining: 4m 59s\n",
      "2431:\ttotal: 4m 43s\tremaining: 4m 59s\n",
      "2432:\ttotal: 4m 43s\tremaining: 4m 59s\n",
      "2433:\ttotal: 4m 43s\tremaining: 4m 58s\n",
      "2434:\ttotal: 4m 43s\tremaining: 4m 58s\n",
      "2435:\tlearn: 0.7817147\ttest: 1.0715403\tbest: 1.0715403 (2435)\ttotal: 4m 43s\tremaining: 4m 58s\n",
      "2436:\ttotal: 4m 43s\tremaining: 4m 58s\n",
      "2437:\ttotal: 4m 43s\tremaining: 4m 58s\n",
      "2438:\ttotal: 4m 44s\tremaining: 4m 58s\n",
      "2439:\ttotal: 4m 44s\tremaining: 4m 58s\n",
      "2440:\tlearn: 0.7809638\ttest: 1.0711980\tbest: 1.0711980 (2440)\ttotal: 4m 44s\tremaining: 4m 58s\n",
      "2441:\ttotal: 4m 44s\tremaining: 4m 57s\n",
      "2442:\ttotal: 4m 44s\tremaining: 4m 57s\n",
      "2443:\ttotal: 4m 44s\tremaining: 4m 57s\n",
      "2444:\ttotal: 4m 44s\tremaining: 4m 57s\n",
      "2445:\tlearn: 0.7803100\ttest: 1.0709227\tbest: 1.0709227 (2445)\ttotal: 4m 44s\tremaining: 4m 57s\n",
      "2446:\ttotal: 4m 44s\tremaining: 4m 57s\n",
      "2447:\ttotal: 4m 45s\tremaining: 4m 57s\n",
      "2448:\ttotal: 4m 45s\tremaining: 4m 57s\n",
      "2449:\ttotal: 4m 45s\tremaining: 4m 56s\n",
      "2450:\tlearn: 0.7796011\ttest: 1.0706165\tbest: 1.0706165 (2450)\ttotal: 4m 45s\tremaining: 4m 56s\n",
      "2451:\ttotal: 4m 45s\tremaining: 4m 56s\n",
      "2452:\ttotal: 4m 45s\tremaining: 4m 56s\n",
      "2453:\ttotal: 4m 45s\tremaining: 4m 56s\n",
      "2454:\ttotal: 4m 45s\tremaining: 4m 56s\n",
      "2455:\tlearn: 0.7788426\ttest: 1.0703614\tbest: 1.0703614 (2455)\ttotal: 4m 45s\tremaining: 4m 56s\n",
      "2456:\ttotal: 4m 46s\tremaining: 4m 56s\n",
      "2457:\ttotal: 4m 46s\tremaining: 4m 55s\n",
      "2458:\ttotal: 4m 46s\tremaining: 4m 55s\n",
      "2459:\ttotal: 4m 46s\tremaining: 4m 55s\n",
      "2460:\tlearn: 0.7781318\ttest: 1.0700166\tbest: 1.0700166 (2460)\ttotal: 4m 46s\tremaining: 4m 55s\n",
      "2461:\ttotal: 4m 46s\tremaining: 4m 55s\n",
      "2462:\ttotal: 4m 46s\tremaining: 4m 55s\n",
      "2463:\ttotal: 4m 46s\tremaining: 4m 55s\n",
      "2464:\ttotal: 4m 46s\tremaining: 4m 55s\n",
      "2465:\tlearn: 0.7773969\ttest: 1.0696584\tbest: 1.0696584 (2465)\ttotal: 4m 47s\tremaining: 4m 54s\n",
      "2466:\ttotal: 4m 47s\tremaining: 4m 54s\n",
      "2467:\ttotal: 4m 47s\tremaining: 4m 54s\n",
      "2468:\ttotal: 4m 47s\tremaining: 4m 54s\n",
      "2469:\ttotal: 4m 47s\tremaining: 4m 54s\n",
      "2470:\tlearn: 0.7767733\ttest: 1.0693072\tbest: 1.0693072 (2470)\ttotal: 4m 47s\tremaining: 4m 54s\n",
      "2471:\ttotal: 4m 47s\tremaining: 4m 54s\n",
      "2472:\ttotal: 4m 47s\tremaining: 4m 54s\n",
      "2473:\ttotal: 4m 47s\tremaining: 4m 53s\n",
      "2474:\ttotal: 4m 48s\tremaining: 4m 53s\n",
      "2475:\tlearn: 0.7760788\ttest: 1.0689932\tbest: 1.0689932 (2475)\ttotal: 4m 48s\tremaining: 4m 53s\n",
      "2476:\ttotal: 4m 48s\tremaining: 4m 53s\n",
      "2477:\ttotal: 4m 48s\tremaining: 4m 53s\n",
      "2478:\ttotal: 4m 48s\tremaining: 4m 53s\n",
      "2479:\ttotal: 4m 48s\tremaining: 4m 53s\n",
      "2480:\tlearn: 0.7753884\ttest: 1.0686836\tbest: 1.0686836 (2480)\ttotal: 4m 48s\tremaining: 4m 53s\n",
      "2481:\ttotal: 4m 48s\tremaining: 4m 53s\n",
      "2482:\ttotal: 4m 48s\tremaining: 4m 52s\n",
      "2483:\ttotal: 4m 49s\tremaining: 4m 52s\n",
      "2484:\ttotal: 4m 49s\tremaining: 4m 52s\n",
      "2485:\tlearn: 0.7746618\ttest: 1.0684484\tbest: 1.0684484 (2485)\ttotal: 4m 49s\tremaining: 4m 52s\n",
      "2486:\ttotal: 4m 49s\tremaining: 4m 52s\n",
      "2487:\ttotal: 4m 49s\tremaining: 4m 52s\n",
      "2488:\ttotal: 4m 49s\tremaining: 4m 52s\n",
      "2489:\ttotal: 4m 49s\tremaining: 4m 52s\n",
      "2490:\tlearn: 0.7739723\ttest: 1.0682098\tbest: 1.0682098 (2490)\ttotal: 4m 49s\tremaining: 4m 51s\n",
      "2491:\ttotal: 4m 49s\tremaining: 4m 51s\n",
      "2492:\ttotal: 4m 50s\tremaining: 4m 51s\n",
      "2493:\ttotal: 4m 50s\tremaining: 4m 51s\n",
      "2494:\ttotal: 4m 50s\tremaining: 4m 51s\n",
      "2495:\tlearn: 0.7732912\ttest: 1.0679747\tbest: 1.0679747 (2495)\ttotal: 4m 50s\tremaining: 4m 51s\n",
      "2496:\ttotal: 4m 50s\tremaining: 4m 51s\n",
      "2497:\ttotal: 4m 50s\tremaining: 4m 51s\n",
      "2498:\ttotal: 4m 50s\tremaining: 4m 50s\n",
      "2499:\ttotal: 4m 50s\tremaining: 4m 50s\n",
      "2500:\tlearn: 0.7725937\ttest: 1.0676804\tbest: 1.0676804 (2500)\ttotal: 4m 50s\tremaining: 4m 50s\n",
      "2501:\ttotal: 4m 50s\tremaining: 4m 50s\n",
      "2502:\ttotal: 4m 51s\tremaining: 4m 50s\n",
      "2503:\ttotal: 4m 51s\tremaining: 4m 50s\n",
      "2504:\ttotal: 4m 51s\tremaining: 4m 50s\n",
      "2505:\tlearn: 0.7718710\ttest: 1.0673933\tbest: 1.0673933 (2505)\ttotal: 4m 51s\tremaining: 4m 50s\n",
      "2506:\ttotal: 4m 51s\tremaining: 4m 49s\n",
      "2507:\ttotal: 4m 51s\tremaining: 4m 49s\n",
      "2508:\ttotal: 4m 51s\tremaining: 4m 49s\n",
      "2509:\ttotal: 4m 51s\tremaining: 4m 49s\n",
      "2510:\tlearn: 0.7711678\ttest: 1.0670822\tbest: 1.0670822 (2510)\ttotal: 4m 51s\tremaining: 4m 49s\n",
      "2511:\ttotal: 4m 52s\tremaining: 4m 49s\n",
      "2512:\ttotal: 4m 52s\tremaining: 4m 49s\n",
      "2513:\ttotal: 4m 52s\tremaining: 4m 49s\n",
      "2514:\ttotal: 4m 52s\tremaining: 4m 48s\n",
      "2515:\tlearn: 0.7705007\ttest: 1.0666530\tbest: 1.0666530 (2515)\ttotal: 4m 52s\tremaining: 4m 48s\n",
      "2516:\ttotal: 4m 52s\tremaining: 4m 48s\n",
      "2517:\ttotal: 4m 52s\tremaining: 4m 48s\n",
      "2518:\ttotal: 4m 52s\tremaining: 4m 48s\n",
      "2519:\ttotal: 4m 52s\tremaining: 4m 48s\n",
      "2520:\tlearn: 0.7698011\ttest: 1.0664343\tbest: 1.0664343 (2520)\ttotal: 4m 53s\tremaining: 4m 48s\n",
      "2521:\ttotal: 4m 53s\tremaining: 4m 48s\n",
      "2522:\ttotal: 4m 53s\tremaining: 4m 47s\n",
      "2523:\ttotal: 4m 53s\tremaining: 4m 47s\n",
      "2524:\ttotal: 4m 53s\tremaining: 4m 47s\n",
      "2525:\tlearn: 0.7691219\ttest: 1.0662209\tbest: 1.0662209 (2525)\ttotal: 4m 53s\tremaining: 4m 47s\n",
      "2526:\ttotal: 4m 53s\tremaining: 4m 47s\n",
      "2527:\ttotal: 4m 53s\tremaining: 4m 47s\n",
      "2528:\ttotal: 4m 53s\tremaining: 4m 47s\n",
      "2529:\ttotal: 4m 54s\tremaining: 4m 47s\n",
      "2530:\tlearn: 0.7684309\ttest: 1.0660138\tbest: 1.0660138 (2530)\ttotal: 4m 54s\tremaining: 4m 46s\n",
      "2531:\ttotal: 4m 54s\tremaining: 4m 46s\n",
      "2532:\ttotal: 4m 54s\tremaining: 4m 46s\n",
      "2533:\ttotal: 4m 54s\tremaining: 4m 46s\n",
      "2534:\ttotal: 4m 54s\tremaining: 4m 46s\n",
      "2535:\tlearn: 0.7677273\ttest: 1.0657405\tbest: 1.0657405 (2535)\ttotal: 4m 54s\tremaining: 4m 46s\n",
      "2536:\ttotal: 4m 54s\tremaining: 4m 46s\n",
      "2537:\ttotal: 4m 54s\tremaining: 4m 46s\n",
      "2538:\ttotal: 4m 55s\tremaining: 4m 45s\n",
      "2539:\ttotal: 4m 55s\tremaining: 4m 45s\n",
      "2540:\tlearn: 0.7670728\ttest: 1.0654651\tbest: 1.0654651 (2540)\ttotal: 4m 55s\tremaining: 4m 45s\n",
      "2541:\ttotal: 4m 55s\tremaining: 4m 45s\n",
      "2542:\ttotal: 4m 55s\tremaining: 4m 45s\n",
      "2543:\ttotal: 4m 55s\tremaining: 4m 45s\n",
      "2544:\ttotal: 4m 55s\tremaining: 4m 45s\n",
      "2545:\tlearn: 0.7662761\ttest: 1.0651241\tbest: 1.0651241 (2545)\ttotal: 4m 55s\tremaining: 4m 45s\n",
      "2546:\ttotal: 4m 55s\tremaining: 4m 44s\n",
      "2547:\ttotal: 4m 55s\tremaining: 4m 44s\n",
      "2548:\ttotal: 4m 56s\tremaining: 4m 44s\n",
      "2549:\ttotal: 4m 56s\tremaining: 4m 44s\n",
      "2550:\tlearn: 0.7655498\ttest: 1.0648224\tbest: 1.0648224 (2550)\ttotal: 4m 56s\tremaining: 4m 44s\n",
      "2551:\ttotal: 4m 56s\tremaining: 4m 44s\n",
      "2552:\ttotal: 4m 56s\tremaining: 4m 44s\n",
      "2553:\ttotal: 4m 56s\tremaining: 4m 44s\n",
      "2554:\ttotal: 4m 56s\tremaining: 4m 43s\n",
      "2555:\tlearn: 0.7648702\ttest: 1.0645393\tbest: 1.0645393 (2555)\ttotal: 4m 56s\tremaining: 4m 43s\n",
      "2556:\ttotal: 4m 56s\tremaining: 4m 43s\n",
      "2557:\ttotal: 4m 57s\tremaining: 4m 43s\n",
      "2558:\ttotal: 4m 57s\tremaining: 4m 43s\n",
      "2559:\ttotal: 4m 57s\tremaining: 4m 43s\n",
      "2560:\tlearn: 0.7641654\ttest: 1.0642460\tbest: 1.0642460 (2560)\ttotal: 4m 57s\tremaining: 4m 43s\n",
      "2561:\ttotal: 4m 57s\tremaining: 4m 43s\n",
      "2562:\ttotal: 4m 57s\tremaining: 4m 42s\n",
      "2563:\ttotal: 4m 57s\tremaining: 4m 42s\n",
      "2564:\ttotal: 4m 57s\tremaining: 4m 42s\n",
      "2565:\tlearn: 0.7634773\ttest: 1.0639124\tbest: 1.0639124 (2565)\ttotal: 4m 57s\tremaining: 4m 42s\n",
      "2566:\ttotal: 4m 57s\tremaining: 4m 42s\n",
      "2567:\ttotal: 4m 58s\tremaining: 4m 42s\n",
      "2568:\ttotal: 4m 58s\tremaining: 4m 42s\n",
      "2569:\ttotal: 4m 58s\tremaining: 4m 42s\n",
      "2570:\tlearn: 0.7627712\ttest: 1.0636371\tbest: 1.0636371 (2570)\ttotal: 4m 58s\tremaining: 4m 41s\n",
      "2571:\ttotal: 4m 58s\tremaining: 4m 41s\n",
      "2572:\ttotal: 4m 58s\tremaining: 4m 41s\n",
      "2573:\ttotal: 4m 58s\tremaining: 4m 41s\n",
      "2574:\ttotal: 4m 58s\tremaining: 4m 41s\n",
      "2575:\tlearn: 0.7620490\ttest: 1.0633654\tbest: 1.0633654 (2575)\ttotal: 4m 58s\tremaining: 4m 41s\n",
      "2576:\ttotal: 4m 59s\tremaining: 4m 41s\n",
      "2577:\ttotal: 4m 59s\tremaining: 4m 41s\n",
      "2578:\ttotal: 4m 59s\tremaining: 4m 40s\n",
      "2579:\ttotal: 4m 59s\tremaining: 4m 40s\n",
      "2580:\tlearn: 0.7613611\ttest: 1.0630962\tbest: 1.0630962 (2580)\ttotal: 4m 59s\tremaining: 4m 40s\n",
      "2581:\ttotal: 4m 59s\tremaining: 4m 40s\n",
      "2582:\ttotal: 4m 59s\tremaining: 4m 40s\n",
      "2583:\ttotal: 4m 59s\tremaining: 4m 40s\n",
      "2584:\ttotal: 4m 59s\tremaining: 4m 40s\n",
      "2585:\tlearn: 0.7607210\ttest: 1.0627772\tbest: 1.0627772 (2585)\ttotal: 4m 59s\tremaining: 4m 39s\n",
      "2586:\ttotal: 5m\tremaining: 4m 39s\n",
      "2587:\ttotal: 5m\tremaining: 4m 39s\n",
      "2588:\ttotal: 5m\tremaining: 4m 39s\n",
      "2589:\ttotal: 5m\tremaining: 4m 39s\n",
      "2590:\tlearn: 0.7600630\ttest: 1.0625579\tbest: 1.0625579 (2590)\ttotal: 5m\tremaining: 4m 39s\n",
      "2591:\ttotal: 5m\tremaining: 4m 39s\n",
      "2592:\ttotal: 5m\tremaining: 4m 39s\n",
      "2593:\ttotal: 5m\tremaining: 4m 38s\n",
      "2594:\ttotal: 5m\tremaining: 4m 38s\n",
      "2595:\tlearn: 0.7594114\ttest: 1.0623897\tbest: 1.0623897 (2595)\ttotal: 5m 1s\tremaining: 4m 38s\n",
      "2596:\ttotal: 5m 1s\tremaining: 4m 38s\n",
      "2597:\ttotal: 5m 1s\tremaining: 4m 38s\n",
      "2598:\ttotal: 5m 1s\tremaining: 4m 38s\n",
      "2599:\ttotal: 5m 1s\tremaining: 4m 38s\n",
      "2600:\tlearn: 0.7586962\ttest: 1.0620594\tbest: 1.0620594 (2600)\ttotal: 5m 1s\tremaining: 4m 38s\n",
      "2601:\ttotal: 5m 1s\tremaining: 4m 37s\n",
      "2602:\ttotal: 5m 1s\tremaining: 4m 37s\n",
      "2603:\ttotal: 5m 1s\tremaining: 4m 37s\n",
      "2604:\ttotal: 5m 2s\tremaining: 4m 37s\n",
      "2605:\tlearn: 0.7579741\ttest: 1.0618933\tbest: 1.0618933 (2605)\ttotal: 5m 2s\tremaining: 4m 37s\n",
      "2606:\ttotal: 5m 2s\tremaining: 4m 37s\n",
      "2607:\ttotal: 5m 2s\tremaining: 4m 37s\n",
      "2608:\ttotal: 5m 2s\tremaining: 4m 37s\n",
      "2609:\ttotal: 5m 2s\tremaining: 4m 37s\n",
      "2610:\tlearn: 0.7572971\ttest: 1.0616523\tbest: 1.0616523 (2610)\ttotal: 5m 2s\tremaining: 4m 36s\n",
      "2611:\ttotal: 5m 2s\tremaining: 4m 36s\n",
      "2612:\ttotal: 5m 2s\tremaining: 4m 36s\n",
      "2613:\ttotal: 5m 2s\tremaining: 4m 36s\n",
      "2614:\ttotal: 5m 3s\tremaining: 4m 36s\n",
      "2615:\tlearn: 0.7566452\ttest: 1.0613726\tbest: 1.0613726 (2615)\ttotal: 5m 3s\tremaining: 4m 36s\n",
      "2616:\ttotal: 5m 3s\tremaining: 4m 36s\n",
      "2617:\ttotal: 5m 3s\tremaining: 4m 35s\n",
      "2618:\ttotal: 5m 3s\tremaining: 4m 35s\n",
      "2619:\ttotal: 5m 3s\tremaining: 4m 35s\n",
      "2620:\tlearn: 0.7559814\ttest: 1.0611551\tbest: 1.0611551 (2620)\ttotal: 5m 3s\tremaining: 4m 35s\n",
      "2621:\ttotal: 5m 3s\tremaining: 4m 35s\n",
      "2622:\ttotal: 5m 3s\tremaining: 4m 35s\n",
      "2623:\ttotal: 5m 3s\tremaining: 4m 35s\n",
      "2624:\ttotal: 5m 4s\tremaining: 4m 35s\n",
      "2625:\tlearn: 0.7553468\ttest: 1.0609165\tbest: 1.0609165 (2625)\ttotal: 5m 4s\tremaining: 4m 34s\n",
      "2626:\ttotal: 5m 4s\tremaining: 4m 34s\n",
      "2627:\ttotal: 5m 4s\tremaining: 4m 34s\n",
      "2628:\ttotal: 5m 4s\tremaining: 4m 34s\n",
      "2629:\ttotal: 5m 4s\tremaining: 4m 34s\n",
      "2630:\tlearn: 0.7546923\ttest: 1.0607366\tbest: 1.0607366 (2630)\ttotal: 5m 4s\tremaining: 4m 34s\n",
      "2631:\ttotal: 5m 4s\tremaining: 4m 34s\n",
      "2632:\ttotal: 5m 4s\tremaining: 4m 34s\n",
      "2633:\ttotal: 5m 5s\tremaining: 4m 34s\n",
      "2634:\ttotal: 5m 5s\tremaining: 4m 33s\n",
      "2635:\tlearn: 0.7540525\ttest: 1.0605868\tbest: 1.0605868 (2635)\ttotal: 5m 5s\tremaining: 4m 33s\n",
      "2636:\ttotal: 5m 5s\tremaining: 4m 33s\n",
      "2637:\ttotal: 5m 5s\tremaining: 4m 33s\n",
      "2638:\ttotal: 5m 5s\tremaining: 4m 33s\n",
      "2639:\ttotal: 5m 5s\tremaining: 4m 33s\n",
      "2640:\tlearn: 0.7533951\ttest: 1.0604064\tbest: 1.0604064 (2640)\ttotal: 5m 5s\tremaining: 4m 33s\n",
      "2641:\ttotal: 5m 5s\tremaining: 4m 33s\n",
      "2642:\ttotal: 5m 5s\tremaining: 4m 32s\n",
      "2643:\ttotal: 5m 6s\tremaining: 4m 32s\n",
      "2644:\ttotal: 5m 6s\tremaining: 4m 32s\n",
      "2645:\tlearn: 0.7527755\ttest: 1.0601838\tbest: 1.0601838 (2645)\ttotal: 5m 6s\tremaining: 4m 32s\n",
      "2646:\ttotal: 5m 6s\tremaining: 4m 32s\n",
      "2647:\ttotal: 5m 6s\tremaining: 4m 32s\n",
      "2648:\ttotal: 5m 6s\tremaining: 4m 32s\n",
      "2649:\ttotal: 5m 6s\tremaining: 4m 32s\n",
      "2650:\tlearn: 0.7521384\ttest: 1.0598922\tbest: 1.0598922 (2650)\ttotal: 5m 6s\tremaining: 4m 31s\n",
      "2651:\ttotal: 5m 6s\tremaining: 4m 31s\n",
      "2652:\ttotal: 5m 7s\tremaining: 4m 31s\n",
      "2653:\ttotal: 5m 7s\tremaining: 4m 31s\n",
      "2654:\ttotal: 5m 7s\tremaining: 4m 31s\n",
      "2655:\tlearn: 0.7514862\ttest: 1.0597020\tbest: 1.0597020 (2655)\ttotal: 5m 7s\tremaining: 4m 31s\n",
      "2656:\ttotal: 5m 7s\tremaining: 4m 31s\n",
      "2657:\ttotal: 5m 7s\tremaining: 4m 30s\n",
      "2658:\ttotal: 5m 7s\tremaining: 4m 30s\n",
      "2659:\ttotal: 5m 7s\tremaining: 4m 30s\n",
      "2660:\tlearn: 0.7508242\ttest: 1.0594775\tbest: 1.0594775 (2660)\ttotal: 5m 7s\tremaining: 4m 30s\n",
      "2661:\ttotal: 5m 8s\tremaining: 4m 30s\n",
      "2662:\ttotal: 5m 8s\tremaining: 4m 30s\n",
      "2663:\ttotal: 5m 8s\tremaining: 4m 30s\n",
      "2664:\ttotal: 5m 8s\tremaining: 4m 30s\n",
      "2665:\tlearn: 0.7501770\ttest: 1.0591976\tbest: 1.0591976 (2665)\ttotal: 5m 8s\tremaining: 4m 30s\n",
      "2666:\ttotal: 5m 8s\tremaining: 4m 29s\n",
      "2667:\ttotal: 5m 8s\tremaining: 4m 29s\n",
      "2668:\ttotal: 5m 8s\tremaining: 4m 29s\n",
      "2669:\ttotal: 5m 8s\tremaining: 4m 29s\n",
      "2670:\tlearn: 0.7495216\ttest: 1.0589390\tbest: 1.0589390 (2670)\ttotal: 5m 9s\tremaining: 4m 29s\n",
      "2671:\ttotal: 5m 9s\tremaining: 4m 29s\n",
      "2672:\ttotal: 5m 9s\tremaining: 4m 29s\n",
      "2673:\ttotal: 5m 9s\tremaining: 4m 29s\n",
      "2674:\ttotal: 5m 9s\tremaining: 4m 28s\n",
      "2675:\tlearn: 0.7489130\ttest: 1.0587365\tbest: 1.0587365 (2675)\ttotal: 5m 9s\tremaining: 4m 28s\n",
      "2676:\ttotal: 5m 9s\tremaining: 4m 28s\n",
      "2677:\ttotal: 5m 9s\tremaining: 4m 28s\n",
      "2678:\ttotal: 5m 9s\tremaining: 4m 28s\n",
      "2679:\ttotal: 5m 10s\tremaining: 4m 28s\n",
      "2680:\tlearn: 0.7482468\ttest: 1.0585175\tbest: 1.0585175 (2680)\ttotal: 5m 10s\tremaining: 4m 28s\n",
      "2681:\ttotal: 5m 10s\tremaining: 4m 28s\n",
      "2682:\ttotal: 5m 10s\tremaining: 4m 28s\n",
      "2683:\ttotal: 5m 10s\tremaining: 4m 27s\n",
      "2684:\ttotal: 5m 10s\tremaining: 4m 27s\n",
      "2685:\tlearn: 0.7475686\ttest: 1.0582320\tbest: 1.0582320 (2685)\ttotal: 5m 10s\tremaining: 4m 27s\n",
      "2686:\ttotal: 5m 10s\tremaining: 4m 27s\n",
      "2687:\ttotal: 5m 10s\tremaining: 4m 27s\n",
      "2688:\ttotal: 5m 10s\tremaining: 4m 27s\n",
      "2689:\ttotal: 5m 11s\tremaining: 4m 27s\n",
      "2690:\tlearn: 0.7469567\ttest: 1.0580170\tbest: 1.0580170 (2690)\ttotal: 5m 11s\tremaining: 4m 27s\n",
      "2691:\ttotal: 5m 11s\tremaining: 4m 26s\n",
      "2692:\ttotal: 5m 11s\tremaining: 4m 26s\n",
      "2693:\ttotal: 5m 11s\tremaining: 4m 26s\n",
      "2694:\ttotal: 5m 11s\tremaining: 4m 26s\n",
      "2695:\tlearn: 0.7463239\ttest: 1.0577650\tbest: 1.0577650 (2695)\ttotal: 5m 11s\tremaining: 4m 26s\n",
      "2696:\ttotal: 5m 11s\tremaining: 4m 26s\n",
      "2697:\ttotal: 5m 11s\tremaining: 4m 26s\n",
      "2698:\ttotal: 5m 12s\tremaining: 4m 26s\n",
      "2699:\ttotal: 5m 12s\tremaining: 4m 25s\n",
      "2700:\tlearn: 0.7456976\ttest: 1.0575436\tbest: 1.0575436 (2700)\ttotal: 5m 12s\tremaining: 4m 25s\n",
      "2701:\ttotal: 5m 12s\tremaining: 4m 25s\n",
      "2702:\ttotal: 5m 12s\tremaining: 4m 25s\n",
      "2703:\ttotal: 5m 12s\tremaining: 4m 25s\n",
      "2704:\ttotal: 5m 12s\tremaining: 4m 25s\n",
      "2705:\tlearn: 0.7449908\ttest: 1.0573375\tbest: 1.0573375 (2705)\ttotal: 5m 12s\tremaining: 4m 25s\n",
      "2706:\ttotal: 5m 13s\tremaining: 4m 25s\n",
      "2707:\ttotal: 5m 13s\tremaining: 4m 25s\n",
      "2708:\ttotal: 5m 13s\tremaining: 4m 24s\n",
      "2709:\ttotal: 5m 13s\tremaining: 4m 24s\n",
      "2710:\tlearn: 0.7443546\ttest: 1.0570796\tbest: 1.0570796 (2710)\ttotal: 5m 13s\tremaining: 4m 24s\n",
      "2711:\ttotal: 5m 13s\tremaining: 4m 24s\n",
      "2712:\ttotal: 5m 13s\tremaining: 4m 24s\n",
      "2713:\ttotal: 5m 13s\tremaining: 4m 24s\n",
      "2714:\ttotal: 5m 13s\tremaining: 4m 24s\n",
      "2715:\tlearn: 0.7436787\ttest: 1.0567896\tbest: 1.0567896 (2715)\ttotal: 5m 14s\tremaining: 4m 24s\n",
      "2716:\ttotal: 5m 14s\tremaining: 4m 23s\n",
      "2717:\ttotal: 5m 14s\tremaining: 4m 23s\n",
      "2718:\ttotal: 5m 14s\tremaining: 4m 23s\n",
      "2719:\ttotal: 5m 14s\tremaining: 4m 23s\n",
      "2720:\tlearn: 0.7431087\ttest: 1.0564789\tbest: 1.0564789 (2720)\ttotal: 5m 14s\tremaining: 4m 23s\n",
      "2721:\ttotal: 5m 14s\tremaining: 4m 23s\n",
      "2722:\ttotal: 5m 14s\tremaining: 4m 23s\n",
      "2723:\ttotal: 5m 14s\tremaining: 4m 23s\n",
      "2724:\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2725:\tlearn: 0.7424366\ttest: 1.0562272\tbest: 1.0562272 (2725)\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2726:\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2727:\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2728:\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2729:\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2730:\tlearn: 0.7417335\ttest: 1.0560185\tbest: 1.0560185 (2730)\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2731:\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2732:\ttotal: 5m 15s\tremaining: 4m 22s\n",
      "2733:\ttotal: 5m 16s\tremaining: 4m 21s\n",
      "2734:\ttotal: 5m 16s\tremaining: 4m 21s\n",
      "2735:\tlearn: 0.7410481\ttest: 1.0558206\tbest: 1.0558206 (2735)\ttotal: 5m 16s\tremaining: 4m 21s\n",
      "2736:\ttotal: 5m 16s\tremaining: 4m 21s\n",
      "2737:\ttotal: 5m 16s\tremaining: 4m 21s\n",
      "2738:\ttotal: 5m 16s\tremaining: 4m 21s\n",
      "2739:\ttotal: 5m 16s\tremaining: 4m 21s\n",
      "2740:\tlearn: 0.7403904\ttest: 1.0554988\tbest: 1.0554988 (2740)\ttotal: 5m 16s\tremaining: 4m 21s\n",
      "2741:\ttotal: 5m 16s\tremaining: 4m 20s\n",
      "2742:\ttotal: 5m 16s\tremaining: 4m 20s\n",
      "2743:\ttotal: 5m 17s\tremaining: 4m 20s\n",
      "2744:\ttotal: 5m 17s\tremaining: 4m 20s\n",
      "2745:\tlearn: 0.7397632\ttest: 1.0552764\tbest: 1.0552764 (2745)\ttotal: 5m 17s\tremaining: 4m 20s\n",
      "2746:\ttotal: 5m 17s\tremaining: 4m 20s\n",
      "2747:\ttotal: 5m 17s\tremaining: 4m 20s\n",
      "2748:\ttotal: 5m 17s\tremaining: 4m 20s\n",
      "2749:\ttotal: 5m 17s\tremaining: 4m 19s\n",
      "2750:\tlearn: 0.7391603\ttest: 1.0550096\tbest: 1.0550096 (2750)\ttotal: 5m 17s\tremaining: 4m 19s\n",
      "2751:\ttotal: 5m 17s\tremaining: 4m 19s\n",
      "2752:\ttotal: 5m 18s\tremaining: 4m 19s\n",
      "2753:\ttotal: 5m 18s\tremaining: 4m 19s\n",
      "2754:\ttotal: 5m 18s\tremaining: 4m 19s\n",
      "2755:\tlearn: 0.7385708\ttest: 1.0547824\tbest: 1.0547824 (2755)\ttotal: 5m 18s\tremaining: 4m 19s\n",
      "2756:\ttotal: 5m 18s\tremaining: 4m 19s\n",
      "2757:\ttotal: 5m 18s\tremaining: 4m 18s\n",
      "2758:\ttotal: 5m 18s\tremaining: 4m 18s\n",
      "2759:\ttotal: 5m 18s\tremaining: 4m 18s\n",
      "2760:\tlearn: 0.7379214\ttest: 1.0545716\tbest: 1.0545716 (2760)\ttotal: 5m 18s\tremaining: 4m 18s\n",
      "2761:\ttotal: 5m 19s\tremaining: 4m 18s\n",
      "2762:\ttotal: 5m 19s\tremaining: 4m 18s\n",
      "2763:\ttotal: 5m 19s\tremaining: 4m 18s\n",
      "2764:\ttotal: 5m 19s\tremaining: 4m 18s\n",
      "2765:\tlearn: 0.7372465\ttest: 1.0543098\tbest: 1.0543098 (2765)\ttotal: 5m 19s\tremaining: 4m 18s\n",
      "2766:\ttotal: 5m 19s\tremaining: 4m 17s\n",
      "2767:\ttotal: 5m 19s\tremaining: 4m 17s\n",
      "2768:\ttotal: 5m 19s\tremaining: 4m 17s\n",
      "2769:\ttotal: 5m 19s\tremaining: 4m 17s\n",
      "2770:\tlearn: 0.7365993\ttest: 1.0541167\tbest: 1.0541167 (2770)\ttotal: 5m 20s\tremaining: 4m 17s\n",
      "2771:\ttotal: 5m 20s\tremaining: 4m 17s\n",
      "2772:\ttotal: 5m 20s\tremaining: 4m 17s\n",
      "2773:\ttotal: 5m 20s\tremaining: 4m 17s\n",
      "2774:\ttotal: 5m 20s\tremaining: 4m 16s\n",
      "2775:\tlearn: 0.7359947\ttest: 1.0538807\tbest: 1.0538807 (2775)\ttotal: 5m 20s\tremaining: 4m 16s\n",
      "2776:\ttotal: 5m 20s\tremaining: 4m 16s\n",
      "2777:\ttotal: 5m 20s\tremaining: 4m 16s\n",
      "2778:\ttotal: 5m 20s\tremaining: 4m 16s\n",
      "2779:\ttotal: 5m 20s\tremaining: 4m 16s\n",
      "2780:\tlearn: 0.7353218\ttest: 1.0537035\tbest: 1.0537035 (2780)\ttotal: 5m 21s\tremaining: 4m 16s\n",
      "2781:\ttotal: 5m 21s\tremaining: 4m 16s\n",
      "2782:\ttotal: 5m 21s\tremaining: 4m 15s\n",
      "2783:\ttotal: 5m 21s\tremaining: 4m 15s\n",
      "2784:\ttotal: 5m 21s\tremaining: 4m 15s\n",
      "2785:\tlearn: 0.7347332\ttest: 1.0534719\tbest: 1.0534719 (2785)\ttotal: 5m 21s\tremaining: 4m 15s\n",
      "2786:\ttotal: 5m 21s\tremaining: 4m 15s\n",
      "2787:\ttotal: 5m 21s\tremaining: 4m 15s\n",
      "2788:\ttotal: 5m 21s\tremaining: 4m 15s\n",
      "2789:\ttotal: 5m 22s\tremaining: 4m 15s\n",
      "2790:\tlearn: 0.7341061\ttest: 1.0532626\tbest: 1.0532626 (2790)\ttotal: 5m 22s\tremaining: 4m 15s\n",
      "2791:\ttotal: 5m 22s\tremaining: 4m 14s\n",
      "2792:\ttotal: 5m 22s\tremaining: 4m 14s\n",
      "2793:\ttotal: 5m 22s\tremaining: 4m 14s\n",
      "2794:\ttotal: 5m 22s\tremaining: 4m 14s\n",
      "2795:\tlearn: 0.7334956\ttest: 1.0530278\tbest: 1.0530278 (2795)\ttotal: 5m 22s\tremaining: 4m 14s\n",
      "2796:\ttotal: 5m 22s\tremaining: 4m 14s\n",
      "2797:\ttotal: 5m 22s\tremaining: 4m 14s\n",
      "2798:\ttotal: 5m 23s\tremaining: 4m 14s\n",
      "2799:\ttotal: 5m 23s\tremaining: 4m 13s\n",
      "2800:\tlearn: 0.7328626\ttest: 1.0528682\tbest: 1.0528682 (2800)\ttotal: 5m 23s\tremaining: 4m 13s\n",
      "2801:\ttotal: 5m 23s\tremaining: 4m 13s\n",
      "2802:\ttotal: 5m 23s\tremaining: 4m 13s\n",
      "2803:\ttotal: 5m 23s\tremaining: 4m 13s\n",
      "2804:\ttotal: 5m 23s\tremaining: 4m 13s\n",
      "2805:\tlearn: 0.7322508\ttest: 1.0526320\tbest: 1.0526320 (2805)\ttotal: 5m 23s\tremaining: 4m 13s\n",
      "2806:\ttotal: 5m 23s\tremaining: 4m 13s\n",
      "2807:\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2808:\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2809:\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2810:\tlearn: 0.7316226\ttest: 1.0523975\tbest: 1.0523975 (2810)\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2811:\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2812:\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2813:\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2814:\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2815:\tlearn: 0.7309644\ttest: 1.0521495\tbest: 1.0521495 (2815)\ttotal: 5m 24s\tremaining: 4m 12s\n",
      "2816:\ttotal: 5m 25s\tremaining: 4m 11s\n",
      "2817:\ttotal: 5m 25s\tremaining: 4m 11s\n",
      "2818:\ttotal: 5m 25s\tremaining: 4m 11s\n",
      "2819:\ttotal: 5m 25s\tremaining: 4m 11s\n",
      "2820:\tlearn: 0.7304146\ttest: 1.0519694\tbest: 1.0519694 (2820)\ttotal: 5m 25s\tremaining: 4m 11s\n",
      "2821:\ttotal: 5m 25s\tremaining: 4m 11s\n",
      "2822:\ttotal: 5m 25s\tremaining: 4m 11s\n",
      "2823:\ttotal: 5m 25s\tremaining: 4m 11s\n",
      "2824:\ttotal: 5m 25s\tremaining: 4m 10s\n",
      "2825:\tlearn: 0.7298397\ttest: 1.0517884\tbest: 1.0517884 (2825)\ttotal: 5m 25s\tremaining: 4m 10s\n",
      "2826:\ttotal: 5m 26s\tremaining: 4m 10s\n",
      "2827:\ttotal: 5m 26s\tremaining: 4m 10s\n",
      "2828:\ttotal: 5m 26s\tremaining: 4m 10s\n",
      "2829:\ttotal: 5m 26s\tremaining: 4m 10s\n",
      "2830:\tlearn: 0.7292108\ttest: 1.0516347\tbest: 1.0516347 (2830)\ttotal: 5m 26s\tremaining: 4m 10s\n",
      "2831:\ttotal: 5m 26s\tremaining: 4m 10s\n",
      "2832:\ttotal: 5m 26s\tremaining: 4m 9s\n",
      "2833:\ttotal: 5m 26s\tremaining: 4m 9s\n",
      "2834:\ttotal: 5m 26s\tremaining: 4m 9s\n",
      "2835:\tlearn: 0.7285739\ttest: 1.0514512\tbest: 1.0514512 (2835)\ttotal: 5m 27s\tremaining: 4m 9s\n",
      "2836:\ttotal: 5m 27s\tremaining: 4m 9s\n",
      "2837:\ttotal: 5m 27s\tremaining: 4m 9s\n",
      "2838:\ttotal: 5m 27s\tremaining: 4m 9s\n",
      "2839:\ttotal: 5m 27s\tremaining: 4m 9s\n",
      "2840:\tlearn: 0.7280278\ttest: 1.0511880\tbest: 1.0511880 (2840)\ttotal: 5m 27s\tremaining: 4m 8s\n",
      "2841:\ttotal: 5m 27s\tremaining: 4m 8s\n",
      "2842:\ttotal: 5m 27s\tremaining: 4m 8s\n",
      "2843:\ttotal: 5m 27s\tremaining: 4m 8s\n",
      "2844:\ttotal: 5m 28s\tremaining: 4m 8s\n",
      "2845:\tlearn: 0.7273425\ttest: 1.0509398\tbest: 1.0509398 (2845)\ttotal: 5m 28s\tremaining: 4m 8s\n",
      "2846:\ttotal: 5m 28s\tremaining: 4m 8s\n",
      "2847:\ttotal: 5m 28s\tremaining: 4m 8s\n",
      "2848:\ttotal: 5m 28s\tremaining: 4m 8s\n",
      "2849:\ttotal: 5m 28s\tremaining: 4m 7s\n",
      "2850:\tlearn: 0.7267308\ttest: 1.0507339\tbest: 1.0507339 (2850)\ttotal: 5m 28s\tremaining: 4m 7s\n",
      "2851:\ttotal: 5m 28s\tremaining: 4m 7s\n",
      "2852:\ttotal: 5m 28s\tremaining: 4m 7s\n",
      "2853:\ttotal: 5m 29s\tremaining: 4m 7s\n",
      "2854:\ttotal: 5m 29s\tremaining: 4m 7s\n",
      "2855:\tlearn: 0.7261297\ttest: 1.0505043\tbest: 1.0505043 (2855)\ttotal: 5m 29s\tremaining: 4m 7s\n",
      "2856:\ttotal: 5m 29s\tremaining: 4m 7s\n",
      "2857:\ttotal: 5m 29s\tremaining: 4m 6s\n",
      "2858:\ttotal: 5m 29s\tremaining: 4m 6s\n",
      "2859:\ttotal: 5m 29s\tremaining: 4m 6s\n",
      "2860:\tlearn: 0.7255365\ttest: 1.0503127\tbest: 1.0503127 (2860)\ttotal: 5m 29s\tremaining: 4m 6s\n",
      "2861:\ttotal: 5m 29s\tremaining: 4m 6s\n",
      "2862:\ttotal: 5m 30s\tremaining: 4m 6s\n",
      "2863:\ttotal: 5m 30s\tremaining: 4m 6s\n",
      "2864:\ttotal: 5m 30s\tremaining: 4m 6s\n",
      "2865:\tlearn: 0.7249213\ttest: 1.0500629\tbest: 1.0500629 (2865)\ttotal: 5m 30s\tremaining: 4m 6s\n",
      "2866:\ttotal: 5m 30s\tremaining: 4m 5s\n",
      "2867:\ttotal: 5m 30s\tremaining: 4m 5s\n",
      "2868:\ttotal: 5m 30s\tremaining: 4m 5s\n",
      "2869:\ttotal: 5m 30s\tremaining: 4m 5s\n",
      "2870:\tlearn: 0.7242997\ttest: 1.0498896\tbest: 1.0498896 (2870)\ttotal: 5m 30s\tremaining: 4m 5s\n",
      "2871:\ttotal: 5m 31s\tremaining: 4m 5s\n",
      "2872:\ttotal: 5m 31s\tremaining: 4m 5s\n",
      "2873:\ttotal: 5m 31s\tremaining: 4m 5s\n",
      "2874:\ttotal: 5m 31s\tremaining: 4m 4s\n",
      "2875:\tlearn: 0.7236714\ttest: 1.0497064\tbest: 1.0497064 (2875)\ttotal: 5m 31s\tremaining: 4m 4s\n",
      "2876:\ttotal: 5m 31s\tremaining: 4m 4s\n",
      "2877:\ttotal: 5m 31s\tremaining: 4m 4s\n",
      "2878:\ttotal: 5m 31s\tremaining: 4m 4s\n",
      "2879:\ttotal: 5m 31s\tremaining: 4m 4s\n",
      "2880:\tlearn: 0.7230821\ttest: 1.0494960\tbest: 1.0494960 (2880)\ttotal: 5m 32s\tremaining: 4m 4s\n",
      "2881:\ttotal: 5m 32s\tremaining: 4m 4s\n",
      "2882:\ttotal: 5m 32s\tremaining: 4m 4s\n",
      "2883:\ttotal: 5m 32s\tremaining: 4m 3s\n",
      "2884:\ttotal: 5m 32s\tremaining: 4m 3s\n",
      "2885:\tlearn: 0.7224549\ttest: 1.0492691\tbest: 1.0492691 (2885)\ttotal: 5m 32s\tremaining: 4m 3s\n",
      "2886:\ttotal: 5m 32s\tremaining: 4m 3s\n",
      "2887:\ttotal: 5m 32s\tremaining: 4m 3s\n",
      "2888:\ttotal: 5m 32s\tremaining: 4m 3s\n",
      "2889:\ttotal: 5m 33s\tremaining: 4m 3s\n",
      "2890:\tlearn: 0.7218901\ttest: 1.0490415\tbest: 1.0490415 (2890)\ttotal: 5m 33s\tremaining: 4m 3s\n",
      "2891:\ttotal: 5m 33s\tremaining: 4m 2s\n",
      "2892:\ttotal: 5m 33s\tremaining: 4m 2s\n",
      "2893:\ttotal: 5m 33s\tremaining: 4m 2s\n",
      "2894:\ttotal: 5m 33s\tremaining: 4m 2s\n",
      "2895:\tlearn: 0.7212480\ttest: 1.0488569\tbest: 1.0488569 (2895)\ttotal: 5m 33s\tremaining: 4m 2s\n",
      "2896:\ttotal: 5m 33s\tremaining: 4m 2s\n",
      "2897:\ttotal: 5m 33s\tremaining: 4m 2s\n",
      "2898:\ttotal: 5m 34s\tremaining: 4m 2s\n",
      "2899:\ttotal: 5m 34s\tremaining: 4m 1s\n",
      "2900:\tlearn: 0.7206293\ttest: 1.0486434\tbest: 1.0486434 (2900)\ttotal: 5m 34s\tremaining: 4m 1s\n",
      "2901:\ttotal: 5m 34s\tremaining: 4m 1s\n",
      "2902:\ttotal: 5m 34s\tremaining: 4m 1s\n",
      "2903:\ttotal: 5m 34s\tremaining: 4m 1s\n",
      "2904:\ttotal: 5m 34s\tremaining: 4m 1s\n",
      "2905:\tlearn: 0.7200202\ttest: 1.0483917\tbest: 1.0483917 (2905)\ttotal: 5m 34s\tremaining: 4m 1s\n",
      "2906:\ttotal: 5m 34s\tremaining: 4m 1s\n",
      "2907:\ttotal: 5m 34s\tremaining: 4m\n",
      "2908:\ttotal: 5m 35s\tremaining: 4m\n",
      "2909:\ttotal: 5m 35s\tremaining: 4m\n",
      "2910:\tlearn: 0.7194378\ttest: 1.0481777\tbest: 1.0481777 (2910)\ttotal: 5m 35s\tremaining: 4m\n",
      "2911:\ttotal: 5m 35s\tremaining: 4m\n",
      "2912:\ttotal: 5m 35s\tremaining: 4m\n",
      "2913:\ttotal: 5m 35s\tremaining: 4m\n",
      "2914:\ttotal: 5m 35s\tremaining: 4m\n",
      "2915:\tlearn: 0.7187981\ttest: 1.0480266\tbest: 1.0480266 (2915)\ttotal: 5m 35s\tremaining: 4m\n",
      "2916:\ttotal: 5m 35s\tremaining: 3m 59s\n",
      "2917:\ttotal: 5m 36s\tremaining: 3m 59s\n",
      "2918:\ttotal: 5m 36s\tremaining: 3m 59s\n",
      "2919:\ttotal: 5m 36s\tremaining: 3m 59s\n",
      "2920:\tlearn: 0.7182092\ttest: 1.0478335\tbest: 1.0478335 (2920)\ttotal: 5m 36s\tremaining: 3m 59s\n",
      "2921:\ttotal: 5m 36s\tremaining: 3m 59s\n",
      "2922:\ttotal: 5m 36s\tremaining: 3m 59s\n",
      "2923:\ttotal: 5m 36s\tremaining: 3m 59s\n",
      "2924:\ttotal: 5m 36s\tremaining: 3m 58s\n",
      "2925:\tlearn: 0.7176294\ttest: 1.0476514\tbest: 1.0476514 (2925)\ttotal: 5m 36s\tremaining: 3m 58s\n",
      "2926:\ttotal: 5m 37s\tremaining: 3m 58s\n",
      "2927:\ttotal: 5m 37s\tremaining: 3m 58s\n",
      "2928:\ttotal: 5m 37s\tremaining: 3m 58s\n",
      "2929:\ttotal: 5m 37s\tremaining: 3m 58s\n",
      "2930:\tlearn: 0.7170231\ttest: 1.0474444\tbest: 1.0474444 (2930)\ttotal: 5m 37s\tremaining: 3m 58s\n",
      "2931:\ttotal: 5m 37s\tremaining: 3m 58s\n",
      "2932:\ttotal: 5m 37s\tremaining: 3m 58s\n",
      "2933:\ttotal: 5m 37s\tremaining: 3m 57s\n",
      "2934:\ttotal: 5m 37s\tremaining: 3m 57s\n",
      "2935:\tlearn: 0.7164334\ttest: 1.0473099\tbest: 1.0473099 (2935)\ttotal: 5m 38s\tremaining: 3m 57s\n",
      "2936:\ttotal: 5m 38s\tremaining: 3m 57s\n",
      "2937:\ttotal: 5m 38s\tremaining: 3m 57s\n",
      "2938:\ttotal: 5m 38s\tremaining: 3m 57s\n",
      "2939:\ttotal: 5m 38s\tremaining: 3m 57s\n",
      "2940:\tlearn: 0.7158307\ttest: 1.0471360\tbest: 1.0471360 (2940)\ttotal: 5m 38s\tremaining: 3m 57s\n",
      "2941:\ttotal: 5m 38s\tremaining: 3m 56s\n",
      "2942:\ttotal: 5m 38s\tremaining: 3m 56s\n",
      "2943:\ttotal: 5m 38s\tremaining: 3m 56s\n",
      "2944:\ttotal: 5m 39s\tremaining: 3m 56s\n",
      "2945:\tlearn: 0.7153215\ttest: 1.0469167\tbest: 1.0469167 (2945)\ttotal: 5m 39s\tremaining: 3m 56s\n",
      "2946:\ttotal: 5m 39s\tremaining: 3m 56s\n",
      "2947:\ttotal: 5m 39s\tremaining: 3m 56s\n",
      "2948:\ttotal: 5m 39s\tremaining: 3m 56s\n",
      "2949:\ttotal: 5m 39s\tremaining: 3m 55s\n",
      "2950:\tlearn: 0.7147570\ttest: 1.0467380\tbest: 1.0467380 (2950)\ttotal: 5m 39s\tremaining: 3m 55s\n",
      "2951:\ttotal: 5m 39s\tremaining: 3m 55s\n",
      "2952:\ttotal: 5m 39s\tremaining: 3m 55s\n",
      "2953:\ttotal: 5m 39s\tremaining: 3m 55s\n",
      "2954:\ttotal: 5m 40s\tremaining: 3m 55s\n",
      "2955:\tlearn: 0.7142035\ttest: 1.0465502\tbest: 1.0465502 (2955)\ttotal: 5m 40s\tremaining: 3m 55s\n",
      "2956:\ttotal: 5m 40s\tremaining: 3m 55s\n",
      "2957:\ttotal: 5m 40s\tremaining: 3m 54s\n",
      "2958:\ttotal: 5m 40s\tremaining: 3m 54s\n",
      "2959:\ttotal: 5m 40s\tremaining: 3m 54s\n",
      "2960:\tlearn: 0.7136872\ttest: 1.0463308\tbest: 1.0463308 (2960)\ttotal: 5m 40s\tremaining: 3m 54s\n",
      "2961:\ttotal: 5m 40s\tremaining: 3m 54s\n",
      "2962:\ttotal: 5m 40s\tremaining: 3m 54s\n",
      "2963:\ttotal: 5m 41s\tremaining: 3m 54s\n",
      "2964:\ttotal: 5m 41s\tremaining: 3m 54s\n",
      "2965:\tlearn: 0.7131266\ttest: 1.0460759\tbest: 1.0460759 (2965)\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "2966:\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "2967:\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "2968:\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "2969:\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "2970:\tlearn: 0.7125676\ttest: 1.0458607\tbest: 1.0458607 (2970)\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "2971:\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "2972:\ttotal: 5m 41s\tremaining: 3m 53s\n",
      "2973:\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2974:\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2975:\tlearn: 0.7119710\ttest: 1.0457167\tbest: 1.0457167 (2975)\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2976:\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2977:\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2978:\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2979:\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2980:\tlearn: 0.7113606\ttest: 1.0455599\tbest: 1.0455599 (2980)\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2981:\ttotal: 5m 42s\tremaining: 3m 52s\n",
      "2982:\ttotal: 5m 42s\tremaining: 3m 51s\n",
      "2983:\ttotal: 5m 43s\tremaining: 3m 51s\n",
      "2984:\ttotal: 5m 43s\tremaining: 3m 51s\n",
      "2985:\tlearn: 0.7107813\ttest: 1.0453601\tbest: 1.0453601 (2985)\ttotal: 5m 43s\tremaining: 3m 51s\n",
      "2986:\ttotal: 5m 43s\tremaining: 3m 51s\n",
      "2987:\ttotal: 5m 43s\tremaining: 3m 51s\n",
      "2988:\ttotal: 5m 43s\tremaining: 3m 51s\n",
      "2989:\ttotal: 5m 43s\tremaining: 3m 51s\n",
      "2990:\tlearn: 0.7102299\ttest: 1.0451408\tbest: 1.0451408 (2990)\ttotal: 5m 43s\tremaining: 3m 50s\n",
      "2991:\ttotal: 5m 43s\tremaining: 3m 50s\n",
      "2992:\ttotal: 5m 44s\tremaining: 3m 50s\n",
      "2993:\ttotal: 5m 44s\tremaining: 3m 50s\n",
      "2994:\ttotal: 5m 44s\tremaining: 3m 50s\n",
      "2995:\tlearn: 0.7096643\ttest: 1.0449532\tbest: 1.0449532 (2995)\ttotal: 5m 44s\tremaining: 3m 50s\n",
      "2996:\ttotal: 5m 44s\tremaining: 3m 50s\n",
      "2997:\ttotal: 5m 44s\tremaining: 3m 50s\n",
      "2998:\ttotal: 5m 44s\tremaining: 3m 50s\n",
      "2999:\ttotal: 5m 44s\tremaining: 3m 49s\n",
      "3000:\tlearn: 0.7090831\ttest: 1.0447419\tbest: 1.0447419 (3000)\ttotal: 5m 44s\tremaining: 3m 49s\n",
      "3001:\ttotal: 5m 45s\tremaining: 3m 49s\n",
      "3002:\ttotal: 5m 45s\tremaining: 3m 49s\n",
      "3003:\ttotal: 5m 45s\tremaining: 3m 49s\n",
      "3004:\ttotal: 5m 45s\tremaining: 3m 49s\n",
      "3005:\tlearn: 0.7085118\ttest: 1.0446062\tbest: 1.0446062 (3005)\ttotal: 5m 45s\tremaining: 3m 49s\n",
      "3006:\ttotal: 5m 45s\tremaining: 3m 49s\n",
      "3007:\ttotal: 5m 45s\tremaining: 3m 48s\n",
      "3008:\ttotal: 5m 45s\tremaining: 3m 48s\n",
      "3009:\ttotal: 5m 45s\tremaining: 3m 48s\n",
      "3010:\tlearn: 0.7079795\ttest: 1.0444177\tbest: 1.0444177 (3010)\ttotal: 5m 46s\tremaining: 3m 48s\n",
      "3011:\ttotal: 5m 46s\tremaining: 3m 48s\n",
      "3012:\ttotal: 5m 46s\tremaining: 3m 48s\n",
      "3013:\ttotal: 5m 46s\tremaining: 3m 48s\n",
      "3014:\ttotal: 5m 46s\tremaining: 3m 48s\n",
      "3015:\tlearn: 0.7074215\ttest: 1.0442310\tbest: 1.0442310 (3015)\ttotal: 5m 46s\tremaining: 3m 48s\n",
      "3016:\ttotal: 5m 46s\tremaining: 3m 47s\n",
      "3017:\ttotal: 5m 46s\tremaining: 3m 47s\n",
      "3018:\ttotal: 5m 46s\tremaining: 3m 47s\n",
      "3019:\ttotal: 5m 47s\tremaining: 3m 47s\n",
      "3020:\tlearn: 0.7068244\ttest: 1.0440361\tbest: 1.0440361 (3020)\ttotal: 5m 47s\tremaining: 3m 47s\n",
      "3021:\ttotal: 5m 47s\tremaining: 3m 47s\n",
      "3022:\ttotal: 5m 47s\tremaining: 3m 47s\n",
      "3023:\ttotal: 5m 47s\tremaining: 3m 47s\n",
      "3024:\ttotal: 5m 47s\tremaining: 3m 46s\n",
      "3025:\tlearn: 0.7062835\ttest: 1.0438204\tbest: 1.0438204 (3025)\ttotal: 5m 47s\tremaining: 3m 46s\n",
      "3026:\ttotal: 5m 47s\tremaining: 3m 46s\n",
      "3027:\ttotal: 5m 47s\tremaining: 3m 46s\n",
      "3028:\ttotal: 5m 48s\tremaining: 3m 46s\n",
      "3029:\ttotal: 5m 48s\tremaining: 3m 46s\n",
      "3030:\tlearn: 0.7057162\ttest: 1.0436816\tbest: 1.0436816 (3030)\ttotal: 5m 48s\tremaining: 3m 46s\n",
      "3031:\ttotal: 5m 48s\tremaining: 3m 46s\n",
      "3032:\ttotal: 5m 48s\tremaining: 3m 45s\n",
      "3033:\ttotal: 5m 48s\tremaining: 3m 45s\n",
      "3034:\ttotal: 5m 48s\tremaining: 3m 45s\n",
      "3035:\tlearn: 0.7051135\ttest: 1.0434289\tbest: 1.0434289 (3035)\ttotal: 5m 48s\tremaining: 3m 45s\n",
      "3036:\ttotal: 5m 48s\tremaining: 3m 45s\n",
      "3037:\ttotal: 5m 49s\tremaining: 3m 45s\n",
      "3038:\ttotal: 5m 49s\tremaining: 3m 45s\n",
      "3039:\ttotal: 5m 49s\tremaining: 3m 45s\n",
      "3040:\tlearn: 0.7045578\ttest: 1.0432198\tbest: 1.0432198 (3040)\ttotal: 5m 49s\tremaining: 3m 45s\n",
      "3041:\ttotal: 5m 49s\tremaining: 3m 44s\n",
      "3042:\ttotal: 5m 49s\tremaining: 3m 44s\n",
      "3043:\ttotal: 5m 49s\tremaining: 3m 44s\n",
      "3044:\ttotal: 5m 49s\tremaining: 3m 44s\n",
      "3045:\tlearn: 0.7039622\ttest: 1.0430354\tbest: 1.0430354 (3045)\ttotal: 5m 49s\tremaining: 3m 44s\n",
      "3046:\ttotal: 5m 49s\tremaining: 3m 44s\n",
      "3047:\ttotal: 5m 50s\tremaining: 3m 44s\n",
      "3048:\ttotal: 5m 50s\tremaining: 3m 44s\n",
      "3049:\ttotal: 5m 50s\tremaining: 3m 43s\n",
      "3050:\tlearn: 0.7034370\ttest: 1.0428397\tbest: 1.0428397 (3050)\ttotal: 5m 50s\tremaining: 3m 43s\n",
      "3051:\ttotal: 5m 50s\tremaining: 3m 43s\n",
      "3052:\ttotal: 5m 50s\tremaining: 3m 43s\n",
      "3053:\ttotal: 5m 50s\tremaining: 3m 43s\n",
      "3054:\ttotal: 5m 50s\tremaining: 3m 43s\n",
      "3055:\tlearn: 0.7028409\ttest: 1.0426241\tbest: 1.0426241 (3055)\ttotal: 5m 50s\tremaining: 3m 43s\n",
      "3056:\ttotal: 5m 51s\tremaining: 3m 43s\n",
      "3057:\ttotal: 5m 51s\tremaining: 3m 43s\n",
      "3058:\ttotal: 5m 51s\tremaining: 3m 42s\n",
      "3059:\ttotal: 5m 51s\tremaining: 3m 42s\n",
      "3060:\tlearn: 0.7023003\ttest: 1.0424620\tbest: 1.0424620 (3060)\ttotal: 5m 51s\tremaining: 3m 42s\n",
      "3061:\ttotal: 5m 51s\tremaining: 3m 42s\n",
      "3062:\ttotal: 5m 51s\tremaining: 3m 42s\n",
      "3063:\ttotal: 5m 51s\tremaining: 3m 42s\n",
      "3064:\ttotal: 5m 51s\tremaining: 3m 42s\n",
      "3065:\tlearn: 0.7017269\ttest: 1.0423315\tbest: 1.0423315 (3065)\ttotal: 5m 52s\tremaining: 3m 42s\n",
      "3066:\ttotal: 5m 52s\tremaining: 3m 41s\n",
      "3067:\ttotal: 5m 52s\tremaining: 3m 41s\n",
      "3068:\ttotal: 5m 52s\tremaining: 3m 41s\n",
      "3069:\ttotal: 5m 52s\tremaining: 3m 41s\n",
      "3070:\tlearn: 0.7011163\ttest: 1.0421912\tbest: 1.0421912 (3070)\ttotal: 5m 52s\tremaining: 3m 41s\n",
      "3071:\ttotal: 5m 52s\tremaining: 3m 41s\n",
      "3072:\ttotal: 5m 52s\tremaining: 3m 41s\n",
      "3073:\ttotal: 5m 52s\tremaining: 3m 41s\n",
      "3074:\ttotal: 5m 52s\tremaining: 3m 40s\n",
      "3075:\tlearn: 0.7006072\ttest: 1.0419444\tbest: 1.0419444 (3075)\ttotal: 5m 53s\tremaining: 3m 40s\n",
      "3076:\ttotal: 5m 53s\tremaining: 3m 40s\n",
      "3077:\ttotal: 5m 53s\tremaining: 3m 40s\n",
      "3078:\ttotal: 5m 53s\tremaining: 3m 40s\n",
      "3079:\ttotal: 5m 53s\tremaining: 3m 40s\n",
      "3080:\tlearn: 0.7000947\ttest: 1.0417294\tbest: 1.0417294 (3080)\ttotal: 5m 53s\tremaining: 3m 40s\n",
      "3081:\ttotal: 5m 53s\tremaining: 3m 40s\n",
      "3082:\ttotal: 5m 53s\tremaining: 3m 40s\n",
      "3083:\ttotal: 5m 53s\tremaining: 3m 39s\n",
      "3084:\ttotal: 5m 54s\tremaining: 3m 39s\n",
      "3085:\tlearn: 0.6995240\ttest: 1.0416055\tbest: 1.0416055 (3085)\ttotal: 5m 54s\tremaining: 3m 39s\n",
      "3086:\ttotal: 5m 54s\tremaining: 3m 39s\n",
      "3087:\ttotal: 5m 54s\tremaining: 3m 39s\n",
      "3088:\ttotal: 5m 54s\tremaining: 3m 39s\n",
      "3089:\ttotal: 5m 54s\tremaining: 3m 39s\n",
      "3090:\tlearn: 0.6990032\ttest: 1.0413776\tbest: 1.0413776 (3090)\ttotal: 5m 54s\tremaining: 3m 39s\n",
      "3091:\ttotal: 5m 54s\tremaining: 3m 38s\n",
      "3092:\ttotal: 5m 54s\tremaining: 3m 38s\n",
      "3093:\ttotal: 5m 55s\tremaining: 3m 38s\n",
      "3094:\ttotal: 5m 55s\tremaining: 3m 38s\n",
      "3095:\tlearn: 0.6983873\ttest: 1.0412558\tbest: 1.0412558 (3095)\ttotal: 5m 55s\tremaining: 3m 38s\n",
      "3096:\ttotal: 5m 55s\tremaining: 3m 38s\n",
      "3097:\ttotal: 5m 55s\tremaining: 3m 38s\n",
      "3098:\ttotal: 5m 55s\tremaining: 3m 38s\n",
      "3099:\ttotal: 5m 55s\tremaining: 3m 37s\n",
      "3100:\tlearn: 0.6977957\ttest: 1.0410903\tbest: 1.0410903 (3100)\ttotal: 5m 55s\tremaining: 3m 37s\n",
      "3101:\ttotal: 5m 55s\tremaining: 3m 37s\n",
      "3102:\ttotal: 5m 56s\tremaining: 3m 37s\n",
      "3103:\ttotal: 5m 56s\tremaining: 3m 37s\n",
      "3104:\ttotal: 5m 56s\tremaining: 3m 37s\n",
      "3105:\tlearn: 0.6972639\ttest: 1.0409628\tbest: 1.0409628 (3105)\ttotal: 5m 56s\tremaining: 3m 37s\n",
      "3106:\ttotal: 5m 56s\tremaining: 3m 37s\n",
      "3107:\ttotal: 5m 56s\tremaining: 3m 37s\n",
      "3108:\ttotal: 5m 56s\tremaining: 3m 36s\n",
      "3109:\ttotal: 5m 56s\tremaining: 3m 36s\n",
      "3110:\tlearn: 0.6967158\ttest: 1.0406905\tbest: 1.0406905 (3110)\ttotal: 5m 56s\tremaining: 3m 36s\n",
      "3111:\ttotal: 5m 56s\tremaining: 3m 36s\n",
      "3112:\ttotal: 5m 57s\tremaining: 3m 36s\n",
      "3113:\ttotal: 5m 57s\tremaining: 3m 36s\n",
      "3114:\ttotal: 5m 57s\tremaining: 3m 36s\n",
      "3115:\tlearn: 0.6961328\ttest: 1.0404092\tbest: 1.0404092 (3115)\ttotal: 5m 57s\tremaining: 3m 36s\n",
      "3116:\ttotal: 5m 57s\tremaining: 3m 35s\n",
      "3117:\ttotal: 5m 57s\tremaining: 3m 35s\n",
      "3118:\ttotal: 5m 57s\tremaining: 3m 35s\n",
      "3119:\ttotal: 5m 57s\tremaining: 3m 35s\n",
      "3120:\tlearn: 0.6955939\ttest: 1.0402744\tbest: 1.0402744 (3120)\ttotal: 5m 57s\tremaining: 3m 35s\n",
      "3121:\ttotal: 5m 58s\tremaining: 3m 35s\n",
      "3122:\ttotal: 5m 58s\tremaining: 3m 35s\n",
      "3123:\ttotal: 5m 58s\tremaining: 3m 35s\n",
      "3124:\ttotal: 5m 58s\tremaining: 3m 35s\n",
      "3125:\tlearn: 0.6950278\ttest: 1.0401786\tbest: 1.0401786 (3125)\ttotal: 5m 58s\tremaining: 3m 34s\n",
      "3126:\ttotal: 5m 58s\tremaining: 3m 34s\n",
      "3127:\ttotal: 5m 58s\tremaining: 3m 34s\n",
      "3128:\ttotal: 5m 58s\tremaining: 3m 34s\n",
      "3129:\ttotal: 5m 58s\tremaining: 3m 34s\n",
      "3130:\tlearn: 0.6944840\ttest: 1.0400145\tbest: 1.0400145 (3130)\ttotal: 5m 59s\tremaining: 3m 34s\n",
      "3131:\ttotal: 5m 59s\tremaining: 3m 34s\n",
      "3132:\ttotal: 5m 59s\tremaining: 3m 34s\n",
      "3133:\ttotal: 5m 59s\tremaining: 3m 34s\n",
      "3134:\ttotal: 5m 59s\tremaining: 3m 33s\n",
      "3135:\tlearn: 0.6938912\ttest: 1.0398395\tbest: 1.0398395 (3135)\ttotal: 5m 59s\tremaining: 3m 33s\n",
      "3136:\ttotal: 5m 59s\tremaining: 3m 33s\n",
      "3137:\ttotal: 5m 59s\tremaining: 3m 33s\n",
      "3138:\ttotal: 5m 59s\tremaining: 3m 33s\n",
      "3139:\ttotal: 6m\tremaining: 3m 33s\n",
      "3140:\tlearn: 0.6933794\ttest: 1.0396228\tbest: 1.0396228 (3140)\ttotal: 6m\tremaining: 3m 33s\n",
      "3141:\ttotal: 6m\tremaining: 3m 33s\n",
      "3142:\ttotal: 6m\tremaining: 3m 32s\n",
      "3143:\ttotal: 6m\tremaining: 3m 32s\n",
      "3144:\ttotal: 6m\tremaining: 3m 32s\n",
      "3145:\tlearn: 0.6928703\ttest: 1.0394459\tbest: 1.0394459 (3145)\ttotal: 6m\tremaining: 3m 32s\n",
      "3146:\ttotal: 6m\tremaining: 3m 32s\n",
      "3147:\ttotal: 6m\tremaining: 3m 32s\n",
      "3148:\ttotal: 6m 1s\tremaining: 3m 32s\n",
      "3149:\ttotal: 6m 1s\tremaining: 3m 32s\n",
      "3150:\tlearn: 0.6923488\ttest: 1.0392583\tbest: 1.0392583 (3150)\ttotal: 6m 1s\tremaining: 3m 31s\n",
      "3151:\ttotal: 6m 1s\tremaining: 3m 31s\n",
      "3152:\ttotal: 6m 1s\tremaining: 3m 31s\n",
      "3153:\ttotal: 6m 1s\tremaining: 3m 31s\n",
      "3154:\ttotal: 6m 1s\tremaining: 3m 31s\n",
      "3155:\tlearn: 0.6918454\ttest: 1.0390832\tbest: 1.0390832 (3155)\ttotal: 6m 1s\tremaining: 3m 31s\n",
      "3156:\ttotal: 6m 1s\tremaining: 3m 31s\n",
      "3157:\ttotal: 6m 1s\tremaining: 3m 31s\n",
      "3158:\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3159:\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3160:\tlearn: 0.6912904\ttest: 1.0388491\tbest: 1.0388491 (3160)\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3161:\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3162:\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3163:\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3164:\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3165:\tlearn: 0.6907893\ttest: 1.0386930\tbest: 1.0386930 (3165)\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3166:\ttotal: 6m 2s\tremaining: 3m 30s\n",
      "3167:\ttotal: 6m 2s\tremaining: 3m 29s\n",
      "3168:\ttotal: 6m 3s\tremaining: 3m 29s\n",
      "3169:\ttotal: 6m 3s\tremaining: 3m 29s\n",
      "3170:\tlearn: 0.6902407\ttest: 1.0385722\tbest: 1.0385722 (3170)\ttotal: 6m 3s\tremaining: 3m 29s\n",
      "3171:\ttotal: 6m 3s\tremaining: 3m 29s\n",
      "3172:\ttotal: 6m 3s\tremaining: 3m 29s\n",
      "3173:\ttotal: 6m 3s\tremaining: 3m 29s\n",
      "3174:\ttotal: 6m 3s\tremaining: 3m 29s\n",
      "3175:\tlearn: 0.6897084\ttest: 1.0384471\tbest: 1.0384471 (3175)\ttotal: 6m 3s\tremaining: 3m 28s\n",
      "3176:\ttotal: 6m 3s\tremaining: 3m 28s\n",
      "3177:\ttotal: 6m 3s\tremaining: 3m 28s\n",
      "3178:\ttotal: 6m 4s\tremaining: 3m 28s\n",
      "3179:\ttotal: 6m 4s\tremaining: 3m 28s\n",
      "3180:\tlearn: 0.6892357\ttest: 1.0383266\tbest: 1.0383266 (3180)\ttotal: 6m 4s\tremaining: 3m 28s\n",
      "3181:\ttotal: 6m 4s\tremaining: 3m 28s\n",
      "3182:\ttotal: 6m 4s\tremaining: 3m 28s\n",
      "3183:\ttotal: 6m 4s\tremaining: 3m 27s\n",
      "3184:\ttotal: 6m 4s\tremaining: 3m 27s\n",
      "3185:\tlearn: 0.6887524\ttest: 1.0380882\tbest: 1.0380882 (3185)\ttotal: 6m 4s\tremaining: 3m 27s\n",
      "3186:\ttotal: 6m 4s\tremaining: 3m 27s\n",
      "3187:\ttotal: 6m 4s\tremaining: 3m 27s\n",
      "3188:\ttotal: 6m 5s\tremaining: 3m 27s\n",
      "3189:\ttotal: 6m 5s\tremaining: 3m 27s\n",
      "3190:\tlearn: 0.6882639\ttest: 1.0379239\tbest: 1.0379239 (3190)\ttotal: 6m 5s\tremaining: 3m 27s\n",
      "3191:\ttotal: 6m 5s\tremaining: 3m 26s\n",
      "3192:\ttotal: 6m 5s\tremaining: 3m 26s\n",
      "3193:\ttotal: 6m 5s\tremaining: 3m 26s\n",
      "3194:\ttotal: 6m 5s\tremaining: 3m 26s\n",
      "3195:\tlearn: 0.6877242\ttest: 1.0377915\tbest: 1.0377915 (3195)\ttotal: 6m 5s\tremaining: 3m 26s\n",
      "3196:\ttotal: 6m 5s\tremaining: 3m 26s\n",
      "3197:\ttotal: 6m 6s\tremaining: 3m 26s\n",
      "3198:\ttotal: 6m 6s\tremaining: 3m 26s\n",
      "3199:\ttotal: 6m 6s\tremaining: 3m 26s\n",
      "3200:\tlearn: 0.6872265\ttest: 1.0376241\tbest: 1.0376241 (3200)\ttotal: 6m 6s\tremaining: 3m 25s\n",
      "3201:\ttotal: 6m 6s\tremaining: 3m 25s\n",
      "3202:\ttotal: 6m 6s\tremaining: 3m 25s\n",
      "3203:\ttotal: 6m 6s\tremaining: 3m 25s\n",
      "3204:\ttotal: 6m 6s\tremaining: 3m 25s\n",
      "3205:\tlearn: 0.6866848\ttest: 1.0374507\tbest: 1.0374507 (3205)\ttotal: 6m 6s\tremaining: 3m 25s\n",
      "3206:\ttotal: 6m 7s\tremaining: 3m 25s\n",
      "3207:\ttotal: 6m 7s\tremaining: 3m 25s\n",
      "3208:\ttotal: 6m 7s\tremaining: 3m 24s\n",
      "3209:\ttotal: 6m 7s\tremaining: 3m 24s\n",
      "3210:\tlearn: 0.6860932\ttest: 1.0373339\tbest: 1.0373339 (3210)\ttotal: 6m 7s\tremaining: 3m 24s\n",
      "3211:\ttotal: 6m 7s\tremaining: 3m 24s\n",
      "3212:\ttotal: 6m 7s\tremaining: 3m 24s\n",
      "3213:\ttotal: 6m 7s\tremaining: 3m 24s\n",
      "3214:\ttotal: 6m 7s\tremaining: 3m 24s\n",
      "3215:\tlearn: 0.6855477\ttest: 1.0371055\tbest: 1.0371055 (3215)\ttotal: 6m 8s\tremaining: 3m 24s\n",
      "3216:\ttotal: 6m 8s\tremaining: 3m 24s\n",
      "3217:\ttotal: 6m 8s\tremaining: 3m 23s\n",
      "3218:\ttotal: 6m 8s\tremaining: 3m 23s\n",
      "3219:\ttotal: 6m 8s\tremaining: 3m 23s\n",
      "3220:\tlearn: 0.6850178\ttest: 1.0369017\tbest: 1.0369017 (3220)\ttotal: 6m 8s\tremaining: 3m 23s\n",
      "3221:\ttotal: 6m 8s\tremaining: 3m 23s\n",
      "3222:\ttotal: 6m 8s\tremaining: 3m 23s\n",
      "3223:\ttotal: 6m 8s\tremaining: 3m 23s\n",
      "3224:\ttotal: 6m 8s\tremaining: 3m 23s\n",
      "3225:\tlearn: 0.6844648\ttest: 1.0367189\tbest: 1.0367189 (3225)\ttotal: 6m 9s\tremaining: 3m 22s\n",
      "3226:\ttotal: 6m 9s\tremaining: 3m 22s\n",
      "3227:\ttotal: 6m 9s\tremaining: 3m 22s\n",
      "3228:\ttotal: 6m 9s\tremaining: 3m 22s\n",
      "3229:\ttotal: 6m 9s\tremaining: 3m 22s\n",
      "3230:\tlearn: 0.6839537\ttest: 1.0365945\tbest: 1.0365945 (3230)\ttotal: 6m 9s\tremaining: 3m 22s\n",
      "3231:\ttotal: 6m 9s\tremaining: 3m 22s\n",
      "3232:\ttotal: 6m 9s\tremaining: 3m 22s\n",
      "3233:\ttotal: 6m 9s\tremaining: 3m 21s\n",
      "3234:\ttotal: 6m 10s\tremaining: 3m 21s\n",
      "3235:\tlearn: 0.6834008\ttest: 1.0363851\tbest: 1.0363851 (3235)\ttotal: 6m 10s\tremaining: 3m 21s\n",
      "3236:\ttotal: 6m 10s\tremaining: 3m 21s\n",
      "3237:\ttotal: 6m 10s\tremaining: 3m 21s\n",
      "3238:\ttotal: 6m 10s\tremaining: 3m 21s\n",
      "3239:\ttotal: 6m 10s\tremaining: 3m 21s\n",
      "3240:\tlearn: 0.6828814\ttest: 1.0362340\tbest: 1.0362340 (3240)\ttotal: 6m 10s\tremaining: 3m 21s\n",
      "3241:\ttotal: 6m 10s\tremaining: 3m 21s\n",
      "3242:\ttotal: 6m 10s\tremaining: 3m 20s\n",
      "3243:\ttotal: 6m 10s\tremaining: 3m 20s\n",
      "3244:\ttotal: 6m 11s\tremaining: 3m 20s\n",
      "3245:\tlearn: 0.6823689\ttest: 1.0360218\tbest: 1.0360218 (3245)\ttotal: 6m 11s\tremaining: 3m 20s\n",
      "3246:\ttotal: 6m 11s\tremaining: 3m 20s\n",
      "3247:\ttotal: 6m 11s\tremaining: 3m 20s\n",
      "3248:\ttotal: 6m 11s\tremaining: 3m 20s\n",
      "3249:\ttotal: 6m 11s\tremaining: 3m 20s\n",
      "3250:\tlearn: 0.6818217\ttest: 1.0359496\tbest: 1.0359496 (3250)\ttotal: 6m 11s\tremaining: 3m 19s\n",
      "3251:\ttotal: 6m 11s\tremaining: 3m 19s\n",
      "3252:\ttotal: 6m 11s\tremaining: 3m 19s\n",
      "3253:\ttotal: 6m 12s\tremaining: 3m 19s\n",
      "3254:\ttotal: 6m 12s\tremaining: 3m 19s\n",
      "3255:\tlearn: 0.6812869\ttest: 1.0357969\tbest: 1.0357969 (3255)\ttotal: 6m 12s\tremaining: 3m 19s\n",
      "3256:\ttotal: 6m 12s\tremaining: 3m 19s\n",
      "3257:\ttotal: 6m 12s\tremaining: 3m 19s\n",
      "3258:\ttotal: 6m 12s\tremaining: 3m 19s\n",
      "3259:\ttotal: 6m 12s\tremaining: 3m 18s\n",
      "3260:\tlearn: 0.6808182\ttest: 1.0357165\tbest: 1.0357165 (3260)\ttotal: 6m 12s\tremaining: 3m 18s\n",
      "3261:\ttotal: 6m 12s\tremaining: 3m 18s\n",
      "3262:\ttotal: 6m 13s\tremaining: 3m 18s\n",
      "3263:\ttotal: 6m 13s\tremaining: 3m 18s\n",
      "3264:\ttotal: 6m 13s\tremaining: 3m 18s\n",
      "3265:\tlearn: 0.6802482\ttest: 1.0356038\tbest: 1.0356038 (3265)\ttotal: 6m 13s\tremaining: 3m 18s\n",
      "3266:\ttotal: 6m 13s\tremaining: 3m 18s\n",
      "3267:\ttotal: 6m 13s\tremaining: 3m 17s\n",
      "3268:\ttotal: 6m 13s\tremaining: 3m 17s\n",
      "3269:\ttotal: 6m 13s\tremaining: 3m 17s\n",
      "3270:\tlearn: 0.6797103\ttest: 1.0354890\tbest: 1.0354890 (3270)\ttotal: 6m 13s\tremaining: 3m 17s\n",
      "3271:\ttotal: 6m 13s\tremaining: 3m 17s\n",
      "3272:\ttotal: 6m 14s\tremaining: 3m 17s\n",
      "3273:\ttotal: 6m 14s\tremaining: 3m 17s\n",
      "3274:\ttotal: 6m 14s\tremaining: 3m 17s\n",
      "3275:\tlearn: 0.6792182\ttest: 1.0353371\tbest: 1.0353371 (3275)\ttotal: 6m 14s\tremaining: 3m 16s\n",
      "3276:\ttotal: 6m 14s\tremaining: 3m 16s\n",
      "3277:\ttotal: 6m 14s\tremaining: 3m 16s\n",
      "3278:\ttotal: 6m 14s\tremaining: 3m 16s\n",
      "3279:\ttotal: 6m 14s\tremaining: 3m 16s\n",
      "3280:\tlearn: 0.6786645\ttest: 1.0351488\tbest: 1.0351488 (3280)\ttotal: 6m 14s\tremaining: 3m 16s\n",
      "3281:\ttotal: 6m 14s\tremaining: 3m 16s\n",
      "3282:\ttotal: 6m 15s\tremaining: 3m 16s\n",
      "3283:\ttotal: 6m 15s\tremaining: 3m 16s\n",
      "3284:\ttotal: 6m 15s\tremaining: 3m 15s\n",
      "3285:\tlearn: 0.6781234\ttest: 1.0349835\tbest: 1.0349835 (3285)\ttotal: 6m 15s\tremaining: 3m 15s\n",
      "3286:\ttotal: 6m 15s\tremaining: 3m 15s\n",
      "3287:\ttotal: 6m 15s\tremaining: 3m 15s\n",
      "3288:\ttotal: 6m 15s\tremaining: 3m 15s\n",
      "3289:\ttotal: 6m 15s\tremaining: 3m 15s\n",
      "3290:\tlearn: 0.6775977\ttest: 1.0348757\tbest: 1.0348757 (3290)\ttotal: 6m 15s\tremaining: 3m 15s\n",
      "3291:\ttotal: 6m 16s\tremaining: 3m 15s\n",
      "3292:\ttotal: 6m 16s\tremaining: 3m 15s\n",
      "3293:\ttotal: 6m 16s\tremaining: 3m 14s\n",
      "3294:\ttotal: 6m 16s\tremaining: 3m 14s\n",
      "3295:\tlearn: 0.6770576\ttest: 1.0347771\tbest: 1.0347771 (3295)\ttotal: 6m 16s\tremaining: 3m 14s\n",
      "3296:\ttotal: 6m 16s\tremaining: 3m 14s\n",
      "3297:\ttotal: 6m 16s\tremaining: 3m 14s\n",
      "3298:\ttotal: 6m 16s\tremaining: 3m 14s\n",
      "3299:\ttotal: 6m 16s\tremaining: 3m 14s\n",
      "3300:\tlearn: 0.6765870\ttest: 1.0346082\tbest: 1.0346082 (3300)\ttotal: 6m 16s\tremaining: 3m 14s\n",
      "3301:\ttotal: 6m 17s\tremaining: 3m 13s\n",
      "3302:\ttotal: 6m 17s\tremaining: 3m 13s\n",
      "3303:\ttotal: 6m 17s\tremaining: 3m 13s\n",
      "3304:\ttotal: 6m 17s\tremaining: 3m 13s\n",
      "3305:\tlearn: 0.6760708\ttest: 1.0344419\tbest: 1.0344419 (3305)\ttotal: 6m 17s\tremaining: 3m 13s\n",
      "3306:\ttotal: 6m 17s\tremaining: 3m 13s\n",
      "3307:\ttotal: 6m 17s\tremaining: 3m 13s\n",
      "3308:\ttotal: 6m 17s\tremaining: 3m 13s\n",
      "3309:\ttotal: 6m 17s\tremaining: 3m 12s\n",
      "3310:\tlearn: 0.6756106\ttest: 1.0342437\tbest: 1.0342437 (3310)\ttotal: 6m 17s\tremaining: 3m 12s\n",
      "3311:\ttotal: 6m 18s\tremaining: 3m 12s\n",
      "3312:\ttotal: 6m 18s\tremaining: 3m 12s\n",
      "3313:\ttotal: 6m 18s\tremaining: 3m 12s\n",
      "3314:\ttotal: 6m 18s\tremaining: 3m 12s\n",
      "3315:\tlearn: 0.6751396\ttest: 1.0341157\tbest: 1.0341157 (3315)\ttotal: 6m 18s\tremaining: 3m 12s\n",
      "3316:\ttotal: 6m 18s\tremaining: 3m 12s\n",
      "3317:\ttotal: 6m 18s\tremaining: 3m 12s\n",
      "3318:\ttotal: 6m 18s\tremaining: 3m 11s\n",
      "3319:\ttotal: 6m 18s\tremaining: 3m 11s\n",
      "3320:\tlearn: 0.6746333\ttest: 1.0339343\tbest: 1.0339343 (3320)\ttotal: 6m 19s\tremaining: 3m 11s\n",
      "3321:\ttotal: 6m 19s\tremaining: 3m 11s\n",
      "3322:\ttotal: 6m 19s\tremaining: 3m 11s\n",
      "3323:\ttotal: 6m 19s\tremaining: 3m 11s\n",
      "3324:\ttotal: 6m 19s\tremaining: 3m 11s\n",
      "3325:\tlearn: 0.6741473\ttest: 1.0337503\tbest: 1.0337503 (3325)\ttotal: 6m 19s\tremaining: 3m 11s\n",
      "3326:\ttotal: 6m 19s\tremaining: 3m 10s\n",
      "3327:\ttotal: 6m 19s\tremaining: 3m 10s\n",
      "3328:\ttotal: 6m 19s\tremaining: 3m 10s\n",
      "3329:\ttotal: 6m 20s\tremaining: 3m 10s\n",
      "3330:\tlearn: 0.6736628\ttest: 1.0335816\tbest: 1.0335816 (3330)\ttotal: 6m 20s\tremaining: 3m 10s\n",
      "3331:\ttotal: 6m 20s\tremaining: 3m 10s\n",
      "3332:\ttotal: 6m 20s\tremaining: 3m 10s\n",
      "3333:\ttotal: 6m 20s\tremaining: 3m 10s\n",
      "3334:\ttotal: 6m 20s\tremaining: 3m 9s\n",
      "3335:\tlearn: 0.6731711\ttest: 1.0334858\tbest: 1.0334858 (3335)\ttotal: 6m 20s\tremaining: 3m 9s\n",
      "3336:\ttotal: 6m 20s\tremaining: 3m 9s\n",
      "3337:\ttotal: 6m 20s\tremaining: 3m 9s\n",
      "3338:\ttotal: 6m 20s\tremaining: 3m 9s\n",
      "3339:\ttotal: 6m 21s\tremaining: 3m 9s\n",
      "3340:\tlearn: 0.6726164\ttest: 1.0332990\tbest: 1.0332990 (3340)\ttotal: 6m 21s\tremaining: 3m 9s\n",
      "3341:\ttotal: 6m 21s\tremaining: 3m 9s\n",
      "3342:\ttotal: 6m 21s\tremaining: 3m 9s\n",
      "3343:\ttotal: 6m 21s\tremaining: 3m 8s\n",
      "3344:\ttotal: 6m 21s\tremaining: 3m 8s\n",
      "3345:\tlearn: 0.6721486\ttest: 1.0332095\tbest: 1.0332095 (3345)\ttotal: 6m 21s\tremaining: 3m 8s\n",
      "3346:\ttotal: 6m 21s\tremaining: 3m 8s\n",
      "3347:\ttotal: 6m 21s\tremaining: 3m 8s\n",
      "3348:\ttotal: 6m 21s\tremaining: 3m 8s\n",
      "3349:\ttotal: 6m 22s\tremaining: 3m 8s\n",
      "3350:\tlearn: 0.6716176\ttest: 1.0330952\tbest: 1.0330952 (3350)\ttotal: 6m 22s\tremaining: 3m 8s\n",
      "3351:\ttotal: 6m 22s\tremaining: 3m 7s\n",
      "3352:\ttotal: 6m 22s\tremaining: 3m 7s\n",
      "3353:\ttotal: 6m 22s\tremaining: 3m 7s\n",
      "3354:\ttotal: 6m 22s\tremaining: 3m 7s\n",
      "3355:\tlearn: 0.6711176\ttest: 1.0329853\tbest: 1.0329853 (3355)\ttotal: 6m 22s\tremaining: 3m 7s\n",
      "3356:\ttotal: 6m 22s\tremaining: 3m 7s\n",
      "3357:\ttotal: 6m 22s\tremaining: 3m 7s\n",
      "3358:\ttotal: 6m 22s\tremaining: 3m 7s\n",
      "3359:\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3360:\tlearn: 0.6705780\ttest: 1.0328292\tbest: 1.0328292 (3360)\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3361:\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3362:\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3363:\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3364:\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3365:\tlearn: 0.6700965\ttest: 1.0326810\tbest: 1.0326810 (3365)\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3366:\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3367:\ttotal: 6m 23s\tremaining: 3m 6s\n",
      "3368:\ttotal: 6m 24s\tremaining: 3m 5s\n",
      "3369:\ttotal: 6m 24s\tremaining: 3m 5s\n",
      "3370:\tlearn: 0.6696251\ttest: 1.0324617\tbest: 1.0324617 (3370)\ttotal: 6m 24s\tremaining: 3m 5s\n",
      "3371:\ttotal: 6m 24s\tremaining: 3m 5s\n",
      "3372:\ttotal: 6m 24s\tremaining: 3m 5s\n",
      "3373:\ttotal: 6m 24s\tremaining: 3m 5s\n",
      "3374:\ttotal: 6m 24s\tremaining: 3m 5s\n",
      "3375:\tlearn: 0.6691233\ttest: 1.0323511\tbest: 1.0323511 (3375)\ttotal: 6m 24s\tremaining: 3m 5s\n",
      "3376:\ttotal: 6m 24s\tremaining: 3m 4s\n",
      "3377:\ttotal: 6m 24s\tremaining: 3m 4s\n",
      "3378:\ttotal: 6m 25s\tremaining: 3m 4s\n",
      "3379:\ttotal: 6m 25s\tremaining: 3m 4s\n",
      "3380:\tlearn: 0.6686174\ttest: 1.0323276\tbest: 1.0323276 (3380)\ttotal: 6m 25s\tremaining: 3m 4s\n",
      "3381:\ttotal: 6m 25s\tremaining: 3m 4s\n",
      "3382:\ttotal: 6m 25s\tremaining: 3m 4s\n",
      "3383:\ttotal: 6m 25s\tremaining: 3m 4s\n",
      "3384:\ttotal: 6m 25s\tremaining: 3m 4s\n",
      "3385:\tlearn: 0.6681403\ttest: 1.0321586\tbest: 1.0321586 (3385)\ttotal: 6m 25s\tremaining: 3m 3s\n",
      "3386:\ttotal: 6m 25s\tremaining: 3m 3s\n",
      "3387:\ttotal: 6m 26s\tremaining: 3m 3s\n",
      "3388:\ttotal: 6m 26s\tremaining: 3m 3s\n",
      "3389:\ttotal: 6m 26s\tremaining: 3m 3s\n",
      "3390:\tlearn: 0.6676120\ttest: 1.0319683\tbest: 1.0319683 (3390)\ttotal: 6m 26s\tremaining: 3m 3s\n",
      "3391:\ttotal: 6m 26s\tremaining: 3m 3s\n",
      "3392:\ttotal: 6m 26s\tremaining: 3m 3s\n",
      "3393:\ttotal: 6m 26s\tremaining: 3m 2s\n",
      "3394:\ttotal: 6m 26s\tremaining: 3m 2s\n",
      "3395:\tlearn: 0.6671221\ttest: 1.0317756\tbest: 1.0317756 (3395)\ttotal: 6m 26s\tremaining: 3m 2s\n",
      "3396:\ttotal: 6m 26s\tremaining: 3m 2s\n",
      "3397:\ttotal: 6m 27s\tremaining: 3m 2s\n",
      "3398:\ttotal: 6m 27s\tremaining: 3m 2s\n",
      "3399:\ttotal: 6m 27s\tremaining: 3m 2s\n",
      "3400:\tlearn: 0.6665748\ttest: 1.0316511\tbest: 1.0316511 (3400)\ttotal: 6m 27s\tremaining: 3m 2s\n",
      "3401:\ttotal: 6m 27s\tremaining: 3m 2s\n",
      "3402:\ttotal: 6m 27s\tremaining: 3m 1s\n",
      "3403:\ttotal: 6m 27s\tremaining: 3m 1s\n",
      "3404:\ttotal: 6m 27s\tremaining: 3m 1s\n",
      "3405:\tlearn: 0.6660870\ttest: 1.0314658\tbest: 1.0314658 (3405)\ttotal: 6m 27s\tremaining: 3m 1s\n",
      "3406:\ttotal: 6m 28s\tremaining: 3m 1s\n",
      "3407:\ttotal: 6m 28s\tremaining: 3m 1s\n",
      "3408:\ttotal: 6m 28s\tremaining: 3m 1s\n",
      "3409:\ttotal: 6m 28s\tremaining: 3m 1s\n",
      "3410:\tlearn: 0.6655939\ttest: 1.0313433\tbest: 1.0313433 (3410)\ttotal: 6m 28s\tremaining: 3m\n",
      "3411:\ttotal: 6m 28s\tremaining: 3m\n",
      "3412:\ttotal: 6m 28s\tremaining: 3m\n",
      "3413:\ttotal: 6m 28s\tremaining: 3m\n",
      "3414:\ttotal: 6m 28s\tremaining: 3m\n",
      "3415:\tlearn: 0.6651375\ttest: 1.0311924\tbest: 1.0311924 (3415)\ttotal: 6m 28s\tremaining: 3m\n",
      "3416:\ttotal: 6m 29s\tremaining: 3m\n",
      "3417:\ttotal: 6m 29s\tremaining: 3m\n",
      "3418:\ttotal: 6m 29s\tremaining: 3m\n",
      "3419:\ttotal: 6m 29s\tremaining: 2m 59s\n",
      "3420:\tlearn: 0.6646519\ttest: 1.0309936\tbest: 1.0309936 (3420)\ttotal: 6m 29s\tremaining: 2m 59s\n",
      "3421:\ttotal: 6m 29s\tremaining: 2m 59s\n",
      "3422:\ttotal: 6m 29s\tremaining: 2m 59s\n",
      "3423:\ttotal: 6m 29s\tremaining: 2m 59s\n",
      "3424:\ttotal: 6m 29s\tremaining: 2m 59s\n",
      "3425:\tlearn: 0.6641477\ttest: 1.0308446\tbest: 1.0308446 (3425)\ttotal: 6m 30s\tremaining: 2m 59s\n",
      "3426:\ttotal: 6m 30s\tremaining: 2m 59s\n",
      "3427:\ttotal: 6m 30s\tremaining: 2m 58s\n",
      "3428:\ttotal: 6m 30s\tremaining: 2m 58s\n",
      "3429:\ttotal: 6m 30s\tremaining: 2m 58s\n",
      "3430:\tlearn: 0.6636661\ttest: 1.0307444\tbest: 1.0307444 (3430)\ttotal: 6m 30s\tremaining: 2m 58s\n",
      "3431:\ttotal: 6m 30s\tremaining: 2m 58s\n",
      "3432:\ttotal: 6m 30s\tremaining: 2m 58s\n",
      "3433:\ttotal: 6m 30s\tremaining: 2m 58s\n",
      "3434:\ttotal: 6m 31s\tremaining: 2m 58s\n",
      "3435:\tlearn: 0.6631812\ttest: 1.0306145\tbest: 1.0306145 (3435)\ttotal: 6m 31s\tremaining: 2m 58s\n",
      "3436:\ttotal: 6m 31s\tremaining: 2m 57s\n",
      "3437:\ttotal: 6m 31s\tremaining: 2m 57s\n",
      "3438:\ttotal: 6m 31s\tremaining: 2m 57s\n",
      "3439:\ttotal: 6m 31s\tremaining: 2m 57s\n",
      "3440:\tlearn: 0.6627121\ttest: 1.0305222\tbest: 1.0305222 (3440)\ttotal: 6m 31s\tremaining: 2m 57s\n",
      "3441:\ttotal: 6m 31s\tremaining: 2m 57s\n",
      "3442:\ttotal: 6m 31s\tremaining: 2m 57s\n",
      "3443:\ttotal: 6m 32s\tremaining: 2m 57s\n",
      "3444:\ttotal: 6m 32s\tremaining: 2m 57s\n",
      "3445:\tlearn: 0.6622083\ttest: 1.0304734\tbest: 1.0304734 (3445)\ttotal: 6m 32s\tremaining: 2m 56s\n",
      "3446:\ttotal: 6m 32s\tremaining: 2m 56s\n",
      "3447:\ttotal: 6m 32s\tremaining: 2m 56s\n",
      "3448:\ttotal: 6m 32s\tremaining: 2m 56s\n",
      "3449:\ttotal: 6m 32s\tremaining: 2m 56s\n",
      "3450:\tlearn: 0.6617601\ttest: 1.0303669\tbest: 1.0303669 (3450)\ttotal: 6m 32s\tremaining: 2m 56s\n",
      "3451:\ttotal: 6m 32s\tremaining: 2m 56s\n",
      "3452:\ttotal: 6m 32s\tremaining: 2m 56s\n",
      "3453:\ttotal: 6m 33s\tremaining: 2m 55s\n",
      "3454:\ttotal: 6m 33s\tremaining: 2m 55s\n",
      "3455:\tlearn: 0.6612781\ttest: 1.0302273\tbest: 1.0302273 (3455)\ttotal: 6m 33s\tremaining: 2m 55s\n",
      "3456:\ttotal: 6m 33s\tremaining: 2m 55s\n",
      "3457:\ttotal: 6m 33s\tremaining: 2m 55s\n",
      "3458:\ttotal: 6m 33s\tremaining: 2m 55s\n",
      "3459:\ttotal: 6m 33s\tremaining: 2m 55s\n",
      "3460:\tlearn: 0.6607767\ttest: 1.0301027\tbest: 1.0301027 (3460)\ttotal: 6m 33s\tremaining: 2m 55s\n",
      "3461:\ttotal: 6m 33s\tremaining: 2m 54s\n",
      "3462:\ttotal: 6m 33s\tremaining: 2m 54s\n",
      "3463:\ttotal: 6m 34s\tremaining: 2m 54s\n",
      "3464:\ttotal: 6m 34s\tremaining: 2m 54s\n",
      "3465:\tlearn: 0.6602618\ttest: 1.0299204\tbest: 1.0299204 (3465)\ttotal: 6m 34s\tremaining: 2m 54s\n",
      "3466:\ttotal: 6m 34s\tremaining: 2m 54s\n",
      "3467:\ttotal: 6m 34s\tremaining: 2m 54s\n",
      "3468:\ttotal: 6m 34s\tremaining: 2m 54s\n",
      "3469:\ttotal: 6m 34s\tremaining: 2m 54s\n",
      "3470:\tlearn: 0.6597599\ttest: 1.0298384\tbest: 1.0298384 (3470)\ttotal: 6m 34s\tremaining: 2m 53s\n",
      "3471:\ttotal: 6m 34s\tremaining: 2m 53s\n",
      "3472:\ttotal: 6m 35s\tremaining: 2m 53s\n",
      "3473:\ttotal: 6m 35s\tremaining: 2m 53s\n",
      "3474:\ttotal: 6m 35s\tremaining: 2m 53s\n",
      "3475:\tlearn: 0.6592729\ttest: 1.0297387\tbest: 1.0297387 (3475)\ttotal: 6m 35s\tremaining: 2m 53s\n",
      "3476:\ttotal: 6m 35s\tremaining: 2m 53s\n",
      "3477:\ttotal: 6m 35s\tremaining: 2m 53s\n",
      "3478:\ttotal: 6m 35s\tremaining: 2m 53s\n",
      "3479:\ttotal: 6m 35s\tremaining: 2m 52s\n",
      "3480:\tlearn: 0.6588072\ttest: 1.0296118\tbest: 1.0296118 (3480)\ttotal: 6m 35s\tremaining: 2m 52s\n",
      "3481:\ttotal: 6m 36s\tremaining: 2m 52s\n",
      "3482:\ttotal: 6m 36s\tremaining: 2m 52s\n",
      "3483:\ttotal: 6m 36s\tremaining: 2m 52s\n",
      "3484:\ttotal: 6m 36s\tremaining: 2m 52s\n",
      "3485:\tlearn: 0.6583187\ttest: 1.0294295\tbest: 1.0294295 (3485)\ttotal: 6m 36s\tremaining: 2m 52s\n",
      "3486:\ttotal: 6m 36s\tremaining: 2m 52s\n",
      "3487:\ttotal: 6m 36s\tremaining: 2m 51s\n",
      "3488:\ttotal: 6m 36s\tremaining: 2m 51s\n",
      "3489:\ttotal: 6m 36s\tremaining: 2m 51s\n",
      "3490:\tlearn: 0.6578476\ttest: 1.0292735\tbest: 1.0292735 (3490)\ttotal: 6m 36s\tremaining: 2m 51s\n",
      "3491:\ttotal: 6m 37s\tremaining: 2m 51s\n",
      "3492:\ttotal: 6m 37s\tremaining: 2m 51s\n",
      "3493:\ttotal: 6m 37s\tremaining: 2m 51s\n",
      "3494:\ttotal: 6m 37s\tremaining: 2m 51s\n",
      "3495:\tlearn: 0.6573748\ttest: 1.0291108\tbest: 1.0291108 (3495)\ttotal: 6m 37s\tremaining: 2m 51s\n",
      "3496:\ttotal: 6m 37s\tremaining: 2m 50s\n",
      "3497:\ttotal: 6m 37s\tremaining: 2m 50s\n",
      "3498:\ttotal: 6m 37s\tremaining: 2m 50s\n",
      "3499:\ttotal: 6m 37s\tremaining: 2m 50s\n",
      "3500:\tlearn: 0.6568699\ttest: 1.0289722\tbest: 1.0289722 (3500)\ttotal: 6m 38s\tremaining: 2m 50s\n",
      "3501:\ttotal: 6m 38s\tremaining: 2m 50s\n",
      "3502:\ttotal: 6m 38s\tremaining: 2m 50s\n",
      "3503:\ttotal: 6m 38s\tremaining: 2m 50s\n",
      "3504:\ttotal: 6m 38s\tremaining: 2m 49s\n",
      "3505:\tlearn: 0.6563657\ttest: 1.0287663\tbest: 1.0287663 (3505)\ttotal: 6m 38s\tremaining: 2m 49s\n",
      "3506:\ttotal: 6m 38s\tremaining: 2m 49s\n",
      "3507:\ttotal: 6m 38s\tremaining: 2m 49s\n",
      "3508:\ttotal: 6m 38s\tremaining: 2m 49s\n",
      "3509:\ttotal: 6m 38s\tremaining: 2m 49s\n",
      "3510:\tlearn: 0.6559478\ttest: 1.0286081\tbest: 1.0286081 (3510)\ttotal: 6m 39s\tremaining: 2m 49s\n",
      "3511:\ttotal: 6m 39s\tremaining: 2m 49s\n",
      "3512:\ttotal: 6m 39s\tremaining: 2m 49s\n",
      "3513:\ttotal: 6m 39s\tremaining: 2m 48s\n",
      "3514:\ttotal: 6m 39s\tremaining: 2m 48s\n",
      "3515:\tlearn: 0.6554569\ttest: 1.0285049\tbest: 1.0285049 (3515)\ttotal: 6m 39s\tremaining: 2m 48s\n",
      "3516:\ttotal: 6m 39s\tremaining: 2m 48s\n",
      "3517:\ttotal: 6m 39s\tremaining: 2m 48s\n",
      "3518:\ttotal: 6m 39s\tremaining: 2m 48s\n",
      "3519:\ttotal: 6m 40s\tremaining: 2m 48s\n",
      "3520:\tlearn: 0.6549669\ttest: 1.0284212\tbest: 1.0284212 (3520)\ttotal: 6m 40s\tremaining: 2m 48s\n",
      "3521:\ttotal: 6m 40s\tremaining: 2m 47s\n",
      "3522:\ttotal: 6m 40s\tremaining: 2m 47s\n",
      "3523:\ttotal: 6m 40s\tremaining: 2m 47s\n",
      "3524:\ttotal: 6m 40s\tremaining: 2m 47s\n",
      "3525:\tlearn: 0.6544664\ttest: 1.0283053\tbest: 1.0283053 (3525)\ttotal: 6m 40s\tremaining: 2m 47s\n",
      "3526:\ttotal: 6m 40s\tremaining: 2m 47s\n",
      "3527:\ttotal: 6m 40s\tremaining: 2m 47s\n",
      "3528:\ttotal: 6m 40s\tremaining: 2m 47s\n",
      "3529:\ttotal: 6m 41s\tremaining: 2m 47s\n",
      "3530:\tlearn: 0.6539964\ttest: 1.0281693\tbest: 1.0281693 (3530)\ttotal: 6m 41s\tremaining: 2m 46s\n",
      "3531:\ttotal: 6m 41s\tremaining: 2m 46s\n",
      "3532:\ttotal: 6m 41s\tremaining: 2m 46s\n",
      "3533:\ttotal: 6m 41s\tremaining: 2m 46s\n",
      "3534:\ttotal: 6m 41s\tremaining: 2m 46s\n",
      "3535:\tlearn: 0.6535089\ttest: 1.0280299\tbest: 1.0280299 (3535)\ttotal: 6m 41s\tremaining: 2m 46s\n",
      "3536:\ttotal: 6m 41s\tremaining: 2m 46s\n",
      "3537:\ttotal: 6m 41s\tremaining: 2m 46s\n",
      "3538:\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3539:\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3540:\tlearn: 0.6530042\ttest: 1.0278709\tbest: 1.0278709 (3540)\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3541:\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3542:\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3543:\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3544:\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3545:\tlearn: 0.6525386\ttest: 1.0277916\tbest: 1.0277916 (3545)\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3546:\ttotal: 6m 42s\tremaining: 2m 45s\n",
      "3547:\ttotal: 6m 42s\tremaining: 2m 44s\n",
      "3548:\ttotal: 6m 43s\tremaining: 2m 44s\n",
      "3549:\ttotal: 6m 43s\tremaining: 2m 44s\n",
      "3550:\tlearn: 0.6520619\ttest: 1.0277032\tbest: 1.0277032 (3550)\ttotal: 6m 43s\tremaining: 2m 44s\n",
      "3551:\ttotal: 6m 43s\tremaining: 2m 44s\n",
      "3552:\ttotal: 6m 43s\tremaining: 2m 44s\n",
      "3553:\ttotal: 6m 43s\tremaining: 2m 44s\n",
      "3554:\ttotal: 6m 43s\tremaining: 2m 44s\n",
      "3555:\tlearn: 0.6516322\ttest: 1.0275782\tbest: 1.0275782 (3555)\ttotal: 6m 43s\tremaining: 2m 43s\n",
      "3556:\ttotal: 6m 43s\tremaining: 2m 43s\n",
      "3557:\ttotal: 6m 43s\tremaining: 2m 43s\n",
      "3558:\ttotal: 6m 44s\tremaining: 2m 43s\n",
      "3559:\ttotal: 6m 44s\tremaining: 2m 43s\n",
      "3560:\tlearn: 0.6511923\ttest: 1.0275080\tbest: 1.0275080 (3560)\ttotal: 6m 44s\tremaining: 2m 43s\n",
      "3561:\ttotal: 6m 44s\tremaining: 2m 43s\n",
      "3562:\ttotal: 6m 44s\tremaining: 2m 43s\n",
      "3563:\ttotal: 6m 44s\tremaining: 2m 42s\n",
      "3564:\ttotal: 6m 44s\tremaining: 2m 42s\n",
      "3565:\tlearn: 0.6507254\ttest: 1.0273891\tbest: 1.0273891 (3565)\ttotal: 6m 44s\tremaining: 2m 42s\n",
      "3566:\ttotal: 6m 44s\tremaining: 2m 42s\n",
      "3567:\ttotal: 6m 44s\tremaining: 2m 42s\n",
      "3568:\ttotal: 6m 45s\tremaining: 2m 42s\n",
      "3569:\ttotal: 6m 45s\tremaining: 2m 42s\n",
      "3570:\tlearn: 0.6502582\ttest: 1.0272564\tbest: 1.0272564 (3570)\ttotal: 6m 45s\tremaining: 2m 42s\n",
      "3571:\ttotal: 6m 45s\tremaining: 2m 42s\n",
      "3572:\ttotal: 6m 45s\tremaining: 2m 41s\n",
      "3573:\ttotal: 6m 45s\tremaining: 2m 41s\n",
      "3574:\ttotal: 6m 45s\tremaining: 2m 41s\n",
      "3575:\tlearn: 0.6497866\ttest: 1.0271982\tbest: 1.0271982 (3575)\ttotal: 6m 45s\tremaining: 2m 41s\n",
      "3576:\ttotal: 6m 45s\tremaining: 2m 41s\n",
      "3577:\ttotal: 6m 46s\tremaining: 2m 41s\n",
      "3578:\ttotal: 6m 46s\tremaining: 2m 41s\n",
      "3579:\ttotal: 6m 46s\tremaining: 2m 41s\n",
      "3580:\tlearn: 0.6493236\ttest: 1.0271128\tbest: 1.0271128 (3580)\ttotal: 6m 46s\tremaining: 2m 41s\n",
      "3581:\ttotal: 6m 46s\tremaining: 2m 40s\n",
      "3582:\ttotal: 6m 46s\tremaining: 2m 40s\n",
      "3583:\ttotal: 6m 46s\tremaining: 2m 40s\n",
      "3584:\ttotal: 6m 46s\tremaining: 2m 40s\n",
      "3585:\tlearn: 0.6488985\ttest: 1.0269557\tbest: 1.0269557 (3585)\ttotal: 6m 46s\tremaining: 2m 40s\n",
      "3586:\ttotal: 6m 46s\tremaining: 2m 40s\n",
      "3587:\ttotal: 6m 47s\tremaining: 2m 40s\n",
      "3588:\ttotal: 6m 47s\tremaining: 2m 40s\n",
      "3589:\ttotal: 6m 47s\tremaining: 2m 39s\n",
      "3590:\tlearn: 0.6484978\ttest: 1.0267838\tbest: 1.0267838 (3590)\ttotal: 6m 47s\tremaining: 2m 39s\n",
      "3591:\ttotal: 6m 47s\tremaining: 2m 39s\n",
      "3592:\ttotal: 6m 47s\tremaining: 2m 39s\n",
      "3593:\ttotal: 6m 47s\tremaining: 2m 39s\n",
      "3594:\ttotal: 6m 47s\tremaining: 2m 39s\n",
      "3595:\tlearn: 0.6479721\ttest: 1.0266838\tbest: 1.0266838 (3595)\ttotal: 6m 47s\tremaining: 2m 39s\n",
      "3596:\ttotal: 6m 48s\tremaining: 2m 39s\n",
      "3597:\ttotal: 6m 48s\tremaining: 2m 39s\n",
      "3598:\ttotal: 6m 48s\tremaining: 2m 38s\n",
      "3599:\ttotal: 6m 48s\tremaining: 2m 38s\n",
      "3600:\tlearn: 0.6475321\ttest: 1.0264841\tbest: 1.0264841 (3600)\ttotal: 6m 48s\tremaining: 2m 38s\n",
      "3601:\ttotal: 6m 48s\tremaining: 2m 38s\n",
      "3602:\ttotal: 6m 48s\tremaining: 2m 38s\n",
      "3603:\ttotal: 6m 48s\tremaining: 2m 38s\n",
      "3604:\ttotal: 6m 48s\tremaining: 2m 38s\n",
      "3605:\tlearn: 0.6470233\ttest: 1.0263876\tbest: 1.0263876 (3605)\ttotal: 6m 48s\tremaining: 2m 38s\n",
      "3606:\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3607:\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3608:\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3609:\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3610:\tlearn: 0.6466015\ttest: 1.0262299\tbest: 1.0262299 (3610)\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3611:\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3612:\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3613:\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3614:\ttotal: 6m 49s\tremaining: 2m 37s\n",
      "3615:\tlearn: 0.6461550\ttest: 1.0260506\tbest: 1.0260506 (3615)\ttotal: 6m 50s\tremaining: 2m 36s\n",
      "3616:\ttotal: 6m 50s\tremaining: 2m 36s\n",
      "3617:\ttotal: 6m 50s\tremaining: 2m 36s\n",
      "3618:\ttotal: 6m 50s\tremaining: 2m 36s\n",
      "3619:\ttotal: 6m 50s\tremaining: 2m 36s\n",
      "3620:\tlearn: 0.6456999\ttest: 1.0259629\tbest: 1.0259629 (3620)\ttotal: 6m 50s\tremaining: 2m 36s\n",
      "3621:\ttotal: 6m 50s\tremaining: 2m 36s\n",
      "3622:\ttotal: 6m 50s\tremaining: 2m 36s\n",
      "3623:\ttotal: 6m 50s\tremaining: 2m 35s\n",
      "3624:\ttotal: 6m 50s\tremaining: 2m 35s\n",
      "3625:\tlearn: 0.6452303\ttest: 1.0258384\tbest: 1.0258384 (3625)\ttotal: 6m 51s\tremaining: 2m 35s\n",
      "3626:\ttotal: 6m 51s\tremaining: 2m 35s\n",
      "3627:\ttotal: 6m 51s\tremaining: 2m 35s\n",
      "3628:\ttotal: 6m 51s\tremaining: 2m 35s\n",
      "3629:\ttotal: 6m 51s\tremaining: 2m 35s\n",
      "3630:\tlearn: 0.6447552\ttest: 1.0256911\tbest: 1.0256911 (3630)\ttotal: 6m 51s\tremaining: 2m 35s\n",
      "3631:\ttotal: 6m 51s\tremaining: 2m 35s\n",
      "3632:\ttotal: 6m 51s\tremaining: 2m 34s\n",
      "3633:\ttotal: 6m 51s\tremaining: 2m 34s\n",
      "3634:\ttotal: 6m 52s\tremaining: 2m 34s\n",
      "3635:\tlearn: 0.6443207\ttest: 1.0255713\tbest: 1.0255713 (3635)\ttotal: 6m 52s\tremaining: 2m 34s\n",
      "3636:\ttotal: 6m 52s\tremaining: 2m 34s\n",
      "3637:\ttotal: 6m 52s\tremaining: 2m 34s\n",
      "3638:\ttotal: 6m 52s\tremaining: 2m 34s\n",
      "3639:\ttotal: 6m 52s\tremaining: 2m 34s\n",
      "3640:\tlearn: 0.6438411\ttest: 1.0253289\tbest: 1.0253289 (3640)\ttotal: 6m 52s\tremaining: 2m 34s\n",
      "3641:\ttotal: 6m 52s\tremaining: 2m 33s\n",
      "3642:\ttotal: 6m 52s\tremaining: 2m 33s\n",
      "3643:\ttotal: 6m 52s\tremaining: 2m 33s\n",
      "3644:\ttotal: 6m 53s\tremaining: 2m 33s\n",
      "3645:\tlearn: 0.6433722\ttest: 1.0251813\tbest: 1.0251813 (3645)\ttotal: 6m 53s\tremaining: 2m 33s\n",
      "3646:\ttotal: 6m 53s\tremaining: 2m 33s\n",
      "3647:\ttotal: 6m 53s\tremaining: 2m 33s\n",
      "3648:\ttotal: 6m 53s\tremaining: 2m 33s\n",
      "3649:\ttotal: 6m 53s\tremaining: 2m 32s\n",
      "3650:\tlearn: 0.6429137\ttest: 1.0250349\tbest: 1.0250349 (3650)\ttotal: 6m 53s\tremaining: 2m 32s\n",
      "3651:\ttotal: 6m 53s\tremaining: 2m 32s\n",
      "3652:\ttotal: 6m 53s\tremaining: 2m 32s\n",
      "3653:\ttotal: 6m 54s\tremaining: 2m 32s\n",
      "3654:\ttotal: 6m 54s\tremaining: 2m 32s\n",
      "3655:\tlearn: 0.6425136\ttest: 1.0249423\tbest: 1.0249423 (3655)\ttotal: 6m 54s\tremaining: 2m 32s\n",
      "3656:\ttotal: 6m 54s\tremaining: 2m 32s\n",
      "3657:\ttotal: 6m 54s\tremaining: 2m 32s\n",
      "3658:\ttotal: 6m 54s\tremaining: 2m 31s\n",
      "3659:\ttotal: 6m 54s\tremaining: 2m 31s\n",
      "3660:\tlearn: 0.6420885\ttest: 1.0248302\tbest: 1.0248302 (3660)\ttotal: 6m 54s\tremaining: 2m 31s\n",
      "3661:\ttotal: 6m 54s\tremaining: 2m 31s\n",
      "3662:\ttotal: 6m 54s\tremaining: 2m 31s\n",
      "3663:\ttotal: 6m 55s\tremaining: 2m 31s\n",
      "3664:\ttotal: 6m 55s\tremaining: 2m 31s\n",
      "3665:\tlearn: 0.6416576\ttest: 1.0247747\tbest: 1.0247747 (3665)\ttotal: 6m 55s\tremaining: 2m 31s\n",
      "3666:\ttotal: 6m 55s\tremaining: 2m 30s\n",
      "3667:\ttotal: 6m 55s\tremaining: 2m 30s\n",
      "3668:\ttotal: 6m 55s\tremaining: 2m 30s\n",
      "3669:\ttotal: 6m 55s\tremaining: 2m 30s\n",
      "3670:\tlearn: 0.6411960\ttest: 1.0247015\tbest: 1.0247015 (3670)\ttotal: 6m 55s\tremaining: 2m 30s\n",
      "3671:\ttotal: 6m 55s\tremaining: 2m 30s\n",
      "3672:\ttotal: 6m 55s\tremaining: 2m 30s\n",
      "3673:\ttotal: 6m 56s\tremaining: 2m 30s\n",
      "3674:\ttotal: 6m 56s\tremaining: 2m 30s\n",
      "3675:\tlearn: 0.6407744\ttest: 1.0245514\tbest: 1.0245514 (3675)\ttotal: 6m 56s\tremaining: 2m 29s\n",
      "3676:\ttotal: 6m 56s\tremaining: 2m 29s\n",
      "3677:\ttotal: 6m 56s\tremaining: 2m 29s\n",
      "3678:\ttotal: 6m 56s\tremaining: 2m 29s\n",
      "3679:\ttotal: 6m 56s\tremaining: 2m 29s\n",
      "3680:\tlearn: 0.6403078\ttest: 1.0244673\tbest: 1.0244673 (3680)\ttotal: 6m 56s\tremaining: 2m 29s\n",
      "3681:\ttotal: 6m 56s\tremaining: 2m 29s\n",
      "3682:\ttotal: 6m 57s\tremaining: 2m 29s\n",
      "3683:\ttotal: 6m 57s\tremaining: 2m 29s\n",
      "3684:\ttotal: 6m 57s\tremaining: 2m 28s\n",
      "3685:\tlearn: 0.6398419\ttest: 1.0243366\tbest: 1.0243366 (3685)\ttotal: 6m 57s\tremaining: 2m 28s\n",
      "3686:\ttotal: 6m 57s\tremaining: 2m 28s\n",
      "3687:\ttotal: 6m 57s\tremaining: 2m 28s\n",
      "3688:\ttotal: 6m 57s\tremaining: 2m 28s\n",
      "3689:\ttotal: 6m 57s\tremaining: 2m 28s\n",
      "3690:\tlearn: 0.6394159\ttest: 1.0242006\tbest: 1.0242006 (3690)\ttotal: 6m 57s\tremaining: 2m 28s\n",
      "3691:\ttotal: 6m 58s\tremaining: 2m 28s\n",
      "3692:\ttotal: 6m 58s\tremaining: 2m 27s\n",
      "3693:\ttotal: 6m 58s\tremaining: 2m 27s\n",
      "3694:\ttotal: 6m 58s\tremaining: 2m 27s\n",
      "3695:\tlearn: 0.6389174\ttest: 1.0240767\tbest: 1.0240767 (3695)\ttotal: 6m 58s\tremaining: 2m 27s\n",
      "3696:\ttotal: 6m 58s\tremaining: 2m 27s\n",
      "3697:\ttotal: 6m 58s\tremaining: 2m 27s\n",
      "3698:\ttotal: 6m 58s\tremaining: 2m 27s\n",
      "3699:\ttotal: 6m 58s\tremaining: 2m 27s\n",
      "3700:\tlearn: 0.6385182\ttest: 1.0239377\tbest: 1.0239377 (3700)\ttotal: 6m 59s\tremaining: 2m 27s\n",
      "3701:\ttotal: 6m 59s\tremaining: 2m 26s\n",
      "3702:\ttotal: 6m 59s\tremaining: 2m 26s\n",
      "3703:\ttotal: 6m 59s\tremaining: 2m 26s\n",
      "3704:\ttotal: 6m 59s\tremaining: 2m 26s\n",
      "3705:\tlearn: 0.6381165\ttest: 1.0238565\tbest: 1.0238565 (3705)\ttotal: 6m 59s\tremaining: 2m 26s\n",
      "3706:\ttotal: 6m 59s\tremaining: 2m 26s\n",
      "3707:\ttotal: 6m 59s\tremaining: 2m 26s\n",
      "3708:\ttotal: 6m 59s\tremaining: 2m 26s\n",
      "3709:\ttotal: 7m\tremaining: 2m 26s\n",
      "3710:\tlearn: 0.6376553\ttest: 1.0237699\tbest: 1.0237699 (3710)\ttotal: 7m\tremaining: 2m 25s\n",
      "3711:\ttotal: 7m\tremaining: 2m 25s\n",
      "3712:\ttotal: 7m\tremaining: 2m 25s\n",
      "3713:\ttotal: 7m\tremaining: 2m 25s\n",
      "3714:\ttotal: 7m\tremaining: 2m 25s\n",
      "3715:\tlearn: 0.6371843\ttest: 1.0235874\tbest: 1.0235874 (3715)\ttotal: 7m\tremaining: 2m 25s\n",
      "3716:\ttotal: 7m\tremaining: 2m 25s\n",
      "3717:\ttotal: 7m\tremaining: 2m 25s\n",
      "3718:\ttotal: 7m\tremaining: 2m 25s\n",
      "3719:\ttotal: 7m 1s\tremaining: 2m 24s\n",
      "3720:\tlearn: 0.6367085\ttest: 1.0234086\tbest: 1.0234086 (3720)\ttotal: 7m 1s\tremaining: 2m 24s\n",
      "3721:\ttotal: 7m 1s\tremaining: 2m 24s\n",
      "3722:\ttotal: 7m 1s\tremaining: 2m 24s\n",
      "3723:\ttotal: 7m 1s\tremaining: 2m 24s\n",
      "3724:\ttotal: 7m 1s\tremaining: 2m 24s\n",
      "3725:\tlearn: 0.6362962\ttest: 1.0232440\tbest: 1.0232440 (3725)\ttotal: 7m 1s\tremaining: 2m 24s\n",
      "3726:\ttotal: 7m 1s\tremaining: 2m 24s\n",
      "3727:\ttotal: 7m 1s\tremaining: 2m 23s\n",
      "3728:\ttotal: 7m 2s\tremaining: 2m 23s\n",
      "3729:\ttotal: 7m 2s\tremaining: 2m 23s\n",
      "3730:\tlearn: 0.6358920\ttest: 1.0231393\tbest: 1.0231393 (3730)\ttotal: 7m 2s\tremaining: 2m 23s\n",
      "3731:\ttotal: 7m 2s\tremaining: 2m 23s\n",
      "3732:\ttotal: 7m 2s\tremaining: 2m 23s\n",
      "3733:\ttotal: 7m 2s\tremaining: 2m 23s\n",
      "3734:\ttotal: 7m 2s\tremaining: 2m 23s\n",
      "3735:\tlearn: 0.6354553\ttest: 1.0230011\tbest: 1.0230011 (3735)\ttotal: 7m 2s\tremaining: 2m 23s\n",
      "3736:\ttotal: 7m 2s\tremaining: 2m 22s\n",
      "3737:\ttotal: 7m 2s\tremaining: 2m 22s\n",
      "3738:\ttotal: 7m 3s\tremaining: 2m 22s\n",
      "3739:\ttotal: 7m 3s\tremaining: 2m 22s\n",
      "3740:\tlearn: 0.6349724\ttest: 1.0229003\tbest: 1.0229003 (3740)\ttotal: 7m 3s\tremaining: 2m 22s\n",
      "3741:\ttotal: 7m 3s\tremaining: 2m 22s\n",
      "3742:\ttotal: 7m 3s\tremaining: 2m 22s\n",
      "3743:\ttotal: 7m 3s\tremaining: 2m 22s\n",
      "3744:\ttotal: 7m 3s\tremaining: 2m 21s\n",
      "3745:\tlearn: 0.6345100\ttest: 1.0227566\tbest: 1.0227566 (3745)\ttotal: 7m 3s\tremaining: 2m 21s\n",
      "3746:\ttotal: 7m 3s\tremaining: 2m 21s\n",
      "3747:\ttotal: 7m 3s\tremaining: 2m 21s\n",
      "3748:\ttotal: 7m 4s\tremaining: 2m 21s\n",
      "3749:\ttotal: 7m 4s\tremaining: 2m 21s\n",
      "3750:\tlearn: 0.6341503\ttest: 1.0226334\tbest: 1.0226334 (3750)\ttotal: 7m 4s\tremaining: 2m 21s\n",
      "3751:\ttotal: 7m 4s\tremaining: 2m 21s\n",
      "3752:\ttotal: 7m 4s\tremaining: 2m 21s\n",
      "3753:\ttotal: 7m 4s\tremaining: 2m 20s\n",
      "3754:\ttotal: 7m 4s\tremaining: 2m 20s\n",
      "3755:\tlearn: 0.6337139\ttest: 1.0225036\tbest: 1.0225036 (3755)\ttotal: 7m 4s\tremaining: 2m 20s\n",
      "3756:\ttotal: 7m 4s\tremaining: 2m 20s\n",
      "3757:\ttotal: 7m 5s\tremaining: 2m 20s\n",
      "3758:\ttotal: 7m 5s\tremaining: 2m 20s\n",
      "3759:\ttotal: 7m 5s\tremaining: 2m 20s\n",
      "3760:\tlearn: 0.6332667\ttest: 1.0223490\tbest: 1.0223490 (3760)\ttotal: 7m 5s\tremaining: 2m 20s\n",
      "3761:\ttotal: 7m 5s\tremaining: 2m 19s\n",
      "3762:\ttotal: 7m 5s\tremaining: 2m 19s\n",
      "3763:\ttotal: 7m 5s\tremaining: 2m 19s\n",
      "3764:\ttotal: 7m 5s\tremaining: 2m 19s\n",
      "3765:\tlearn: 0.6327932\ttest: 1.0222645\tbest: 1.0222645 (3765)\ttotal: 7m 5s\tremaining: 2m 19s\n",
      "3766:\ttotal: 7m 5s\tremaining: 2m 19s\n",
      "3767:\ttotal: 7m 5s\tremaining: 2m 19s\n",
      "3768:\ttotal: 7m 6s\tremaining: 2m 19s\n",
      "3769:\ttotal: 7m 6s\tremaining: 2m 19s\n",
      "3770:\tlearn: 0.6323630\ttest: 1.0221327\tbest: 1.0221327 (3770)\ttotal: 7m 6s\tremaining: 2m 18s\n",
      "3771:\ttotal: 7m 6s\tremaining: 2m 18s\n",
      "3772:\ttotal: 7m 6s\tremaining: 2m 18s\n",
      "3773:\ttotal: 7m 6s\tremaining: 2m 18s\n",
      "3774:\ttotal: 7m 6s\tremaining: 2m 18s\n",
      "3775:\tlearn: 0.6319106\ttest: 1.0220473\tbest: 1.0220473 (3775)\ttotal: 7m 6s\tremaining: 2m 18s\n",
      "3776:\ttotal: 7m 6s\tremaining: 2m 18s\n",
      "3777:\ttotal: 7m 7s\tremaining: 2m 18s\n",
      "3778:\ttotal: 7m 7s\tremaining: 2m 18s\n",
      "3779:\ttotal: 7m 7s\tremaining: 2m 17s\n",
      "3780:\tlearn: 0.6314948\ttest: 1.0219484\tbest: 1.0219484 (3780)\ttotal: 7m 7s\tremaining: 2m 17s\n",
      "3781:\ttotal: 7m 7s\tremaining: 2m 17s\n",
      "3782:\ttotal: 7m 7s\tremaining: 2m 17s\n",
      "3783:\ttotal: 7m 7s\tremaining: 2m 17s\n",
      "3784:\ttotal: 7m 7s\tremaining: 2m 17s\n",
      "3785:\tlearn: 0.6310974\ttest: 1.0218764\tbest: 1.0218764 (3785)\ttotal: 7m 7s\tremaining: 2m 17s\n",
      "3786:\ttotal: 7m 7s\tremaining: 2m 17s\n",
      "3787:\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3788:\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3789:\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3790:\tlearn: 0.6306689\ttest: 1.0217347\tbest: 1.0217347 (3790)\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3791:\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3792:\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3793:\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3794:\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3795:\tlearn: 0.6302636\ttest: 1.0215977\tbest: 1.0215977 (3795)\ttotal: 7m 8s\tremaining: 2m 16s\n",
      "3796:\ttotal: 7m 8s\tremaining: 2m 15s\n",
      "3797:\ttotal: 7m 9s\tremaining: 2m 15s\n",
      "3798:\ttotal: 7m 9s\tremaining: 2m 15s\n",
      "3799:\ttotal: 7m 9s\tremaining: 2m 15s\n",
      "3800:\tlearn: 0.6298322\ttest: 1.0214538\tbest: 1.0214538 (3800)\ttotal: 7m 9s\tremaining: 2m 15s\n",
      "3801:\ttotal: 7m 9s\tremaining: 2m 15s\n",
      "3802:\ttotal: 7m 9s\tremaining: 2m 15s\n",
      "3803:\ttotal: 7m 9s\tremaining: 2m 15s\n",
      "3804:\ttotal: 7m 9s\tremaining: 2m 14s\n",
      "3805:\tlearn: 0.6293849\ttest: 1.0213199\tbest: 1.0213199 (3805)\ttotal: 7m 9s\tremaining: 2m 14s\n",
      "3806:\ttotal: 7m 9s\tremaining: 2m 14s\n",
      "3807:\ttotal: 7m 10s\tremaining: 2m 14s\n",
      "3808:\ttotal: 7m 10s\tremaining: 2m 14s\n",
      "3809:\ttotal: 7m 10s\tremaining: 2m 14s\n",
      "3810:\tlearn: 0.6289695\ttest: 1.0211820\tbest: 1.0211820 (3810)\ttotal: 7m 10s\tremaining: 2m 14s\n",
      "3811:\ttotal: 7m 10s\tremaining: 2m 14s\n",
      "3812:\ttotal: 7m 10s\tremaining: 2m 14s\n",
      "3813:\ttotal: 7m 10s\tremaining: 2m 13s\n",
      "3814:\ttotal: 7m 10s\tremaining: 2m 13s\n",
      "3815:\tlearn: 0.6285271\ttest: 1.0210122\tbest: 1.0210122 (3815)\ttotal: 7m 10s\tremaining: 2m 13s\n",
      "3816:\ttotal: 7m 10s\tremaining: 2m 13s\n",
      "3817:\ttotal: 7m 11s\tremaining: 2m 13s\n",
      "3818:\ttotal: 7m 11s\tremaining: 2m 13s\n",
      "3819:\ttotal: 7m 11s\tremaining: 2m 13s\n",
      "3820:\tlearn: 0.6281055\ttest: 1.0209353\tbest: 1.0209353 (3820)\ttotal: 7m 11s\tremaining: 2m 13s\n",
      "3821:\ttotal: 7m 11s\tremaining: 2m 12s\n",
      "3822:\ttotal: 7m 11s\tremaining: 2m 12s\n",
      "3823:\ttotal: 7m 11s\tremaining: 2m 12s\n",
      "3824:\ttotal: 7m 11s\tremaining: 2m 12s\n",
      "3825:\tlearn: 0.6276796\ttest: 1.0207906\tbest: 1.0207906 (3825)\ttotal: 7m 11s\tremaining: 2m 12s\n",
      "3826:\ttotal: 7m 11s\tremaining: 2m 12s\n",
      "3827:\ttotal: 7m 12s\tremaining: 2m 12s\n",
      "3828:\ttotal: 7m 12s\tremaining: 2m 12s\n",
      "3829:\ttotal: 7m 12s\tremaining: 2m 12s\n",
      "3830:\tlearn: 0.6272408\ttest: 1.0206581\tbest: 1.0206581 (3830)\ttotal: 7m 12s\tremaining: 2m 11s\n",
      "3831:\ttotal: 7m 12s\tremaining: 2m 11s\n",
      "3832:\ttotal: 7m 12s\tremaining: 2m 11s\n",
      "3833:\ttotal: 7m 12s\tremaining: 2m 11s\n",
      "3834:\ttotal: 7m 12s\tremaining: 2m 11s\n",
      "3835:\tlearn: 0.6268345\ttest: 1.0205668\tbest: 1.0205668 (3835)\ttotal: 7m 12s\tremaining: 2m 11s\n",
      "3836:\ttotal: 7m 13s\tremaining: 2m 11s\n",
      "3837:\ttotal: 7m 13s\tremaining: 2m 11s\n",
      "3838:\ttotal: 7m 13s\tremaining: 2m 11s\n",
      "3839:\ttotal: 7m 13s\tremaining: 2m 10s\n",
      "3840:\tlearn: 0.6263798\ttest: 1.0205174\tbest: 1.0205174 (3840)\ttotal: 7m 13s\tremaining: 2m 10s\n",
      "3841:\ttotal: 7m 13s\tremaining: 2m 10s\n",
      "3842:\ttotal: 7m 13s\tremaining: 2m 10s\n",
      "3843:\ttotal: 7m 13s\tremaining: 2m 10s\n",
      "3844:\ttotal: 7m 13s\tremaining: 2m 10s\n",
      "3845:\tlearn: 0.6259773\ttest: 1.0203915\tbest: 1.0203915 (3845)\ttotal: 7m 13s\tremaining: 2m 10s\n",
      "3846:\ttotal: 7m 14s\tremaining: 2m 10s\n",
      "3847:\ttotal: 7m 14s\tremaining: 2m 9s\n",
      "3848:\ttotal: 7m 14s\tremaining: 2m 9s\n",
      "3849:\ttotal: 7m 14s\tremaining: 2m 9s\n",
      "3850:\tlearn: 0.6255393\ttest: 1.0203656\tbest: 1.0203656 (3850)\ttotal: 7m 14s\tremaining: 2m 9s\n",
      "3851:\ttotal: 7m 14s\tremaining: 2m 9s\n",
      "3852:\ttotal: 7m 14s\tremaining: 2m 9s\n",
      "3853:\ttotal: 7m 14s\tremaining: 2m 9s\n",
      "3854:\ttotal: 7m 14s\tremaining: 2m 9s\n",
      "3855:\tlearn: 0.6250981\ttest: 1.0203020\tbest: 1.0203020 (3855)\ttotal: 7m 15s\tremaining: 2m 9s\n",
      "3856:\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3857:\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3858:\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3859:\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3860:\tlearn: 0.6246574\ttest: 1.0202242\tbest: 1.0202242 (3860)\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3861:\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3862:\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3863:\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3864:\ttotal: 7m 15s\tremaining: 2m 8s\n",
      "3865:\tlearn: 0.6241929\ttest: 1.0200875\tbest: 1.0200875 (3865)\ttotal: 7m 16s\tremaining: 2m 7s\n",
      "3866:\ttotal: 7m 16s\tremaining: 2m 7s\n",
      "3867:\ttotal: 7m 16s\tremaining: 2m 7s\n",
      "3868:\ttotal: 7m 16s\tremaining: 2m 7s\n",
      "3869:\ttotal: 7m 16s\tremaining: 2m 7s\n",
      "3870:\tlearn: 0.6236990\ttest: 1.0199808\tbest: 1.0199808 (3870)\ttotal: 7m 16s\tremaining: 2m 7s\n",
      "3871:\ttotal: 7m 16s\tremaining: 2m 7s\n",
      "3872:\ttotal: 7m 16s\tremaining: 2m 7s\n",
      "3873:\ttotal: 7m 16s\tremaining: 2m 6s\n",
      "3874:\ttotal: 7m 17s\tremaining: 2m 6s\n",
      "3875:\tlearn: 0.6232405\ttest: 1.0198467\tbest: 1.0198467 (3875)\ttotal: 7m 17s\tremaining: 2m 6s\n",
      "3876:\ttotal: 7m 17s\tremaining: 2m 6s\n",
      "3877:\ttotal: 7m 17s\tremaining: 2m 6s\n",
      "3878:\ttotal: 7m 17s\tremaining: 2m 6s\n",
      "3879:\ttotal: 7m 17s\tremaining: 2m 6s\n",
      "3880:\tlearn: 0.6227925\ttest: 1.0196976\tbest: 1.0196976 (3880)\ttotal: 7m 17s\tremaining: 2m 6s\n",
      "3881:\ttotal: 7m 17s\tremaining: 2m 6s\n",
      "3882:\ttotal: 7m 17s\tremaining: 2m 5s\n",
      "3883:\ttotal: 7m 17s\tremaining: 2m 5s\n",
      "3884:\ttotal: 7m 18s\tremaining: 2m 5s\n",
      "3885:\tlearn: 0.6223198\ttest: 1.0196313\tbest: 1.0196313 (3885)\ttotal: 7m 18s\tremaining: 2m 5s\n",
      "3886:\ttotal: 7m 18s\tremaining: 2m 5s\n",
      "3887:\ttotal: 7m 18s\tremaining: 2m 5s\n",
      "3888:\ttotal: 7m 18s\tremaining: 2m 5s\n",
      "3889:\ttotal: 7m 18s\tremaining: 2m 5s\n",
      "3890:\tlearn: 0.6219211\ttest: 1.0195579\tbest: 1.0195579 (3890)\ttotal: 7m 18s\tremaining: 2m 5s\n",
      "3891:\ttotal: 7m 18s\tremaining: 2m 4s\n",
      "3892:\ttotal: 7m 18s\tremaining: 2m 4s\n",
      "3893:\ttotal: 7m 19s\tremaining: 2m 4s\n",
      "3894:\ttotal: 7m 19s\tremaining: 2m 4s\n",
      "3895:\tlearn: 0.6214796\ttest: 1.0194571\tbest: 1.0194571 (3895)\ttotal: 7m 19s\tremaining: 2m 4s\n",
      "3896:\ttotal: 7m 19s\tremaining: 2m 4s\n",
      "3897:\ttotal: 7m 19s\tremaining: 2m 4s\n",
      "3898:\ttotal: 7m 19s\tremaining: 2m 4s\n",
      "3899:\ttotal: 7m 19s\tremaining: 2m 4s\n",
      "3900:\tlearn: 0.6210442\ttest: 1.0193365\tbest: 1.0193365 (3900)\ttotal: 7m 19s\tremaining: 2m 3s\n",
      "3901:\ttotal: 7m 19s\tremaining: 2m 3s\n",
      "3902:\ttotal: 7m 19s\tremaining: 2m 3s\n",
      "3903:\ttotal: 7m 20s\tremaining: 2m 3s\n",
      "3904:\ttotal: 7m 20s\tremaining: 2m 3s\n",
      "3905:\tlearn: 0.6205876\ttest: 1.0191825\tbest: 1.0191825 (3905)\ttotal: 7m 20s\tremaining: 2m 3s\n",
      "3906:\ttotal: 7m 20s\tremaining: 2m 3s\n",
      "3907:\ttotal: 7m 20s\tremaining: 2m 3s\n",
      "3908:\ttotal: 7m 20s\tremaining: 2m 2s\n",
      "3909:\ttotal: 7m 20s\tremaining: 2m 2s\n",
      "3910:\tlearn: 0.6201538\ttest: 1.0191194\tbest: 1.0191194 (3910)\ttotal: 7m 20s\tremaining: 2m 2s\n",
      "3911:\ttotal: 7m 20s\tremaining: 2m 2s\n",
      "3912:\ttotal: 7m 20s\tremaining: 2m 2s\n",
      "3913:\ttotal: 7m 21s\tremaining: 2m 2s\n",
      "3914:\ttotal: 7m 21s\tremaining: 2m 2s\n",
      "3915:\tlearn: 0.6197282\ttest: 1.0190118\tbest: 1.0190118 (3915)\ttotal: 7m 21s\tremaining: 2m 2s\n",
      "3916:\ttotal: 7m 21s\tremaining: 2m 2s\n",
      "3917:\ttotal: 7m 21s\tremaining: 2m 1s\n",
      "3918:\ttotal: 7m 21s\tremaining: 2m 1s\n",
      "3919:\ttotal: 7m 21s\tremaining: 2m 1s\n",
      "3920:\tlearn: 0.6193015\ttest: 1.0188466\tbest: 1.0188466 (3920)\ttotal: 7m 21s\tremaining: 2m 1s\n",
      "3921:\ttotal: 7m 21s\tremaining: 2m 1s\n",
      "3922:\ttotal: 7m 21s\tremaining: 2m 1s\n",
      "3923:\ttotal: 7m 22s\tremaining: 2m 1s\n",
      "3924:\ttotal: 7m 22s\tremaining: 2m 1s\n",
      "3925:\tlearn: 0.6188690\ttest: 1.0187801\tbest: 1.0187801 (3925)\ttotal: 7m 22s\tremaining: 2m\n",
      "3926:\ttotal: 7m 22s\tremaining: 2m\n",
      "3927:\ttotal: 7m 22s\tremaining: 2m\n",
      "3928:\ttotal: 7m 22s\tremaining: 2m\n",
      "3929:\ttotal: 7m 22s\tremaining: 2m\n",
      "3930:\tlearn: 0.6184674\ttest: 1.0187008\tbest: 1.0187008 (3930)\ttotal: 7m 22s\tremaining: 2m\n",
      "3931:\ttotal: 7m 22s\tremaining: 2m\n",
      "3932:\ttotal: 7m 23s\tremaining: 2m\n",
      "3933:\ttotal: 7m 23s\tremaining: 2m\n",
      "3934:\ttotal: 7m 23s\tremaining: 1m 59s\n",
      "3935:\tlearn: 0.6180336\ttest: 1.0185131\tbest: 1.0185131 (3935)\ttotal: 7m 23s\tremaining: 1m 59s\n",
      "3936:\ttotal: 7m 23s\tremaining: 1m 59s\n",
      "3937:\ttotal: 7m 23s\tremaining: 1m 59s\n",
      "3938:\ttotal: 7m 23s\tremaining: 1m 59s\n",
      "3939:\ttotal: 7m 23s\tremaining: 1m 59s\n",
      "3940:\tlearn: 0.6175864\ttest: 1.0184608\tbest: 1.0184608 (3940)\ttotal: 7m 23s\tremaining: 1m 59s\n",
      "3941:\ttotal: 7m 23s\tremaining: 1m 59s\n",
      "3942:\ttotal: 7m 24s\tremaining: 1m 59s\n",
      "3943:\ttotal: 7m 24s\tremaining: 1m 58s\n",
      "3944:\ttotal: 7m 24s\tremaining: 1m 58s\n",
      "3945:\tlearn: 0.6171309\ttest: 1.0182638\tbest: 1.0182638 (3945)\ttotal: 7m 24s\tremaining: 1m 58s\n",
      "3946:\ttotal: 7m 24s\tremaining: 1m 58s\n",
      "3947:\ttotal: 7m 24s\tremaining: 1m 58s\n",
      "3948:\ttotal: 7m 24s\tremaining: 1m 58s\n",
      "3949:\ttotal: 7m 24s\tremaining: 1m 58s\n",
      "3950:\tlearn: 0.6167153\ttest: 1.0181314\tbest: 1.0181314 (3950)\ttotal: 7m 24s\tremaining: 1m 58s\n",
      "3951:\ttotal: 7m 24s\tremaining: 1m 57s\n",
      "3952:\ttotal: 7m 25s\tremaining: 1m 57s\n",
      "3953:\ttotal: 7m 25s\tremaining: 1m 57s\n",
      "3954:\ttotal: 7m 25s\tremaining: 1m 57s\n",
      "3955:\tlearn: 0.6162339\ttest: 1.0180476\tbest: 1.0180476 (3955)\ttotal: 7m 25s\tremaining: 1m 57s\n",
      "3956:\ttotal: 7m 25s\tremaining: 1m 57s\n",
      "3957:\ttotal: 7m 25s\tremaining: 1m 57s\n",
      "3958:\ttotal: 7m 25s\tremaining: 1m 57s\n",
      "3959:\ttotal: 7m 25s\tremaining: 1m 57s\n",
      "3960:\tlearn: 0.6158295\ttest: 1.0179637\tbest: 1.0179637 (3960)\ttotal: 7m 25s\tremaining: 1m 56s\n",
      "3961:\ttotal: 7m 25s\tremaining: 1m 56s\n",
      "3962:\ttotal: 7m 26s\tremaining: 1m 56s\n",
      "3963:\ttotal: 7m 26s\tremaining: 1m 56s\n",
      "3964:\ttotal: 7m 26s\tremaining: 1m 56s\n",
      "3965:\tlearn: 0.6153971\ttest: 1.0178849\tbest: 1.0178849 (3965)\ttotal: 7m 26s\tremaining: 1m 56s\n",
      "3966:\ttotal: 7m 26s\tremaining: 1m 56s\n",
      "3967:\ttotal: 7m 26s\tremaining: 1m 56s\n",
      "3968:\ttotal: 7m 26s\tremaining: 1m 56s\n",
      "3969:\ttotal: 7m 26s\tremaining: 1m 55s\n",
      "3970:\tlearn: 0.6149958\ttest: 1.0177729\tbest: 1.0177729 (3970)\ttotal: 7m 26s\tremaining: 1m 55s\n",
      "3971:\ttotal: 7m 26s\tremaining: 1m 55s\n",
      "3972:\ttotal: 7m 27s\tremaining: 1m 55s\n",
      "3973:\ttotal: 7m 27s\tremaining: 1m 55s\n",
      "3974:\ttotal: 7m 27s\tremaining: 1m 55s\n",
      "3975:\tlearn: 0.6145951\ttest: 1.0176508\tbest: 1.0176508 (3975)\ttotal: 7m 27s\tremaining: 1m 55s\n",
      "3976:\ttotal: 7m 27s\tremaining: 1m 55s\n",
      "3977:\ttotal: 7m 27s\tremaining: 1m 54s\n",
      "3978:\ttotal: 7m 27s\tremaining: 1m 54s\n",
      "3979:\ttotal: 7m 27s\tremaining: 1m 54s\n",
      "3980:\tlearn: 0.6141713\ttest: 1.0175475\tbest: 1.0175475 (3980)\ttotal: 7m 27s\tremaining: 1m 54s\n",
      "3981:\ttotal: 7m 27s\tremaining: 1m 54s\n",
      "3982:\ttotal: 7m 28s\tremaining: 1m 54s\n",
      "3983:\ttotal: 7m 28s\tremaining: 1m 54s\n",
      "3984:\ttotal: 7m 28s\tremaining: 1m 54s\n",
      "3985:\tlearn: 0.6137843\ttest: 1.0174775\tbest: 1.0174775 (3985)\ttotal: 7m 28s\tremaining: 1m 54s\n",
      "3986:\ttotal: 7m 28s\tremaining: 1m 53s\n",
      "3987:\ttotal: 7m 28s\tremaining: 1m 53s\n",
      "3988:\ttotal: 7m 28s\tremaining: 1m 53s\n",
      "3989:\ttotal: 7m 28s\tremaining: 1m 53s\n",
      "3990:\tlearn: 0.6133828\ttest: 1.0173627\tbest: 1.0173627 (3990)\ttotal: 7m 28s\tremaining: 1m 53s\n",
      "3991:\ttotal: 7m 28s\tremaining: 1m 53s\n",
      "3992:\ttotal: 7m 29s\tremaining: 1m 53s\n",
      "3993:\ttotal: 7m 29s\tremaining: 1m 53s\n",
      "3994:\ttotal: 7m 29s\tremaining: 1m 53s\n",
      "3995:\tlearn: 0.6129580\ttest: 1.0171985\tbest: 1.0171985 (3995)\ttotal: 7m 29s\tremaining: 1m 52s\n",
      "3996:\ttotal: 7m 29s\tremaining: 1m 52s\n",
      "3997:\ttotal: 7m 29s\tremaining: 1m 52s\n",
      "3998:\ttotal: 7m 29s\tremaining: 1m 52s\n",
      "3999:\ttotal: 7m 29s\tremaining: 1m 52s\n",
      "4000:\tlearn: 0.6125656\ttest: 1.0170974\tbest: 1.0170974 (4000)\ttotal: 7m 29s\tremaining: 1m 52s\n",
      "4001:\ttotal: 7m 30s\tremaining: 1m 52s\n",
      "4002:\ttotal: 7m 30s\tremaining: 1m 52s\n",
      "4003:\ttotal: 7m 30s\tremaining: 1m 52s\n",
      "4004:\ttotal: 7m 30s\tremaining: 1m 51s\n",
      "4005:\tlearn: 0.6121593\ttest: 1.0169705\tbest: 1.0169705 (4005)\ttotal: 7m 30s\tremaining: 1m 51s\n",
      "4006:\ttotal: 7m 30s\tremaining: 1m 51s\n",
      "4007:\ttotal: 7m 30s\tremaining: 1m 51s\n",
      "4008:\ttotal: 7m 30s\tremaining: 1m 51s\n",
      "4009:\ttotal: 7m 30s\tremaining: 1m 51s\n",
      "4010:\tlearn: 0.6118042\ttest: 1.0168978\tbest: 1.0168978 (4010)\ttotal: 7m 30s\tremaining: 1m 51s\n",
      "4011:\ttotal: 7m 31s\tremaining: 1m 51s\n",
      "4012:\ttotal: 7m 31s\tremaining: 1m 50s\n",
      "4013:\ttotal: 7m 31s\tremaining: 1m 50s\n",
      "4014:\ttotal: 7m 31s\tremaining: 1m 50s\n",
      "4015:\tlearn: 0.6113397\ttest: 1.0167240\tbest: 1.0167240 (4015)\ttotal: 7m 31s\tremaining: 1m 50s\n",
      "4016:\ttotal: 7m 31s\tremaining: 1m 50s\n",
      "4017:\ttotal: 7m 31s\tremaining: 1m 50s\n",
      "4018:\ttotal: 7m 31s\tremaining: 1m 50s\n",
      "4019:\ttotal: 7m 31s\tremaining: 1m 50s\n",
      "4020:\tlearn: 0.6108868\ttest: 1.0166123\tbest: 1.0166123 (4020)\ttotal: 7m 32s\tremaining: 1m 50s\n",
      "4021:\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4022:\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4023:\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4024:\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4025:\tlearn: 0.6104835\ttest: 1.0165459\tbest: 1.0165459 (4025)\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4026:\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4027:\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4028:\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4029:\ttotal: 7m 32s\tremaining: 1m 49s\n",
      "4030:\tlearn: 0.6101140\ttest: 1.0164548\tbest: 1.0164548 (4030)\ttotal: 7m 33s\tremaining: 1m 48s\n",
      "4031:\ttotal: 7m 33s\tremaining: 1m 48s\n",
      "4032:\ttotal: 7m 33s\tremaining: 1m 48s\n",
      "4033:\ttotal: 7m 33s\tremaining: 1m 48s\n",
      "4034:\ttotal: 7m 33s\tremaining: 1m 48s\n",
      "4035:\tlearn: 0.6096997\ttest: 1.0164300\tbest: 1.0164300 (4035)\ttotal: 7m 33s\tremaining: 1m 48s\n",
      "4036:\ttotal: 7m 33s\tremaining: 1m 48s\n",
      "4037:\ttotal: 7m 33s\tremaining: 1m 48s\n",
      "4038:\ttotal: 7m 33s\tremaining: 1m 47s\n",
      "4039:\ttotal: 7m 33s\tremaining: 1m 47s\n",
      "4040:\tlearn: 0.6093007\ttest: 1.0163202\tbest: 1.0163202 (4040)\ttotal: 7m 34s\tremaining: 1m 47s\n",
      "4041:\ttotal: 7m 34s\tremaining: 1m 47s\n",
      "4042:\ttotal: 7m 34s\tremaining: 1m 47s\n",
      "4043:\ttotal: 7m 34s\tremaining: 1m 47s\n",
      "4044:\ttotal: 7m 34s\tremaining: 1m 47s\n",
      "4045:\tlearn: 0.6089080\ttest: 1.0162669\tbest: 1.0162669 (4045)\ttotal: 7m 34s\tremaining: 1m 47s\n",
      "4046:\ttotal: 7m 34s\tremaining: 1m 47s\n",
      "4047:\ttotal: 7m 34s\tremaining: 1m 46s\n",
      "4048:\ttotal: 7m 34s\tremaining: 1m 46s\n",
      "4049:\ttotal: 7m 35s\tremaining: 1m 46s\n",
      "4050:\tlearn: 0.6084443\ttest: 1.0161948\tbest: 1.0161948 (4050)\ttotal: 7m 35s\tremaining: 1m 46s\n",
      "4051:\ttotal: 7m 35s\tremaining: 1m 46s\n",
      "4052:\ttotal: 7m 35s\tremaining: 1m 46s\n",
      "4053:\ttotal: 7m 35s\tremaining: 1m 46s\n",
      "4054:\ttotal: 7m 35s\tremaining: 1m 46s\n",
      "4055:\tlearn: 0.6080582\ttest: 1.0161226\tbest: 1.0161226 (4055)\ttotal: 7m 35s\tremaining: 1m 46s\n",
      "4056:\ttotal: 7m 35s\tremaining: 1m 45s\n",
      "4057:\ttotal: 7m 35s\tremaining: 1m 45s\n",
      "4058:\ttotal: 7m 35s\tremaining: 1m 45s\n",
      "4059:\ttotal: 7m 36s\tremaining: 1m 45s\n",
      "4060:\tlearn: 0.6077120\ttest: 1.0160206\tbest: 1.0160206 (4060)\ttotal: 7m 36s\tremaining: 1m 45s\n",
      "4061:\ttotal: 7m 36s\tremaining: 1m 45s\n",
      "4062:\ttotal: 7m 36s\tremaining: 1m 45s\n",
      "4063:\ttotal: 7m 36s\tremaining: 1m 45s\n",
      "4064:\ttotal: 7m 36s\tremaining: 1m 45s\n",
      "4065:\tlearn: 0.6072890\ttest: 1.0159265\tbest: 1.0159265 (4065)\ttotal: 7m 36s\tremaining: 1m 44s\n",
      "4066:\ttotal: 7m 36s\tremaining: 1m 44s\n",
      "4067:\ttotal: 7m 36s\tremaining: 1m 44s\n",
      "4068:\ttotal: 7m 36s\tremaining: 1m 44s\n",
      "4069:\ttotal: 7m 37s\tremaining: 1m 44s\n",
      "4070:\tlearn: 0.6068543\ttest: 1.0158358\tbest: 1.0158358 (4070)\ttotal: 7m 37s\tremaining: 1m 44s\n",
      "4071:\ttotal: 7m 37s\tremaining: 1m 44s\n",
      "4072:\ttotal: 7m 37s\tremaining: 1m 44s\n",
      "4073:\ttotal: 7m 37s\tremaining: 1m 43s\n",
      "4074:\ttotal: 7m 37s\tremaining: 1m 43s\n",
      "4075:\tlearn: 0.6064581\ttest: 1.0156810\tbest: 1.0156810 (4075)\ttotal: 7m 37s\tremaining: 1m 43s\n",
      "4076:\ttotal: 7m 37s\tremaining: 1m 43s\n",
      "4077:\ttotal: 7m 37s\tremaining: 1m 43s\n",
      "4078:\ttotal: 7m 38s\tremaining: 1m 43s\n",
      "4079:\ttotal: 7m 38s\tremaining: 1m 43s\n",
      "4080:\tlearn: 0.6059880\ttest: 1.0156118\tbest: 1.0156118 (4080)\ttotal: 7m 38s\tremaining: 1m 43s\n",
      "4081:\ttotal: 7m 38s\tremaining: 1m 43s\n",
      "4082:\ttotal: 7m 38s\tremaining: 1m 42s\n",
      "4083:\ttotal: 7m 38s\tremaining: 1m 42s\n",
      "4084:\ttotal: 7m 38s\tremaining: 1m 42s\n",
      "4085:\tlearn: 0.6055789\ttest: 1.0155229\tbest: 1.0155229 (4085)\ttotal: 7m 38s\tremaining: 1m 42s\n",
      "4086:\ttotal: 7m 38s\tremaining: 1m 42s\n",
      "4087:\ttotal: 7m 39s\tremaining: 1m 42s\n",
      "4088:\ttotal: 7m 39s\tremaining: 1m 42s\n",
      "4089:\ttotal: 7m 39s\tremaining: 1m 42s\n",
      "4090:\tlearn: 0.6051772\ttest: 1.0154771\tbest: 1.0154771 (4090)\ttotal: 7m 39s\tremaining: 1m 42s\n",
      "4091:\ttotal: 7m 39s\tremaining: 1m 41s\n",
      "4092:\ttotal: 7m 39s\tremaining: 1m 41s\n",
      "4093:\ttotal: 7m 39s\tremaining: 1m 41s\n",
      "4094:\ttotal: 7m 39s\tremaining: 1m 41s\n",
      "4095:\tlearn: 0.6047834\ttest: 1.0154341\tbest: 1.0154341 (4095)\ttotal: 7m 39s\tremaining: 1m 41s\n",
      "4096:\ttotal: 7m 39s\tremaining: 1m 41s\n",
      "4097:\ttotal: 7m 40s\tremaining: 1m 41s\n",
      "4098:\ttotal: 7m 40s\tremaining: 1m 41s\n",
      "4099:\ttotal: 7m 40s\tremaining: 1m 41s\n",
      "4100:\tlearn: 0.6043713\ttest: 1.0153779\tbest: 1.0153779 (4100)\ttotal: 7m 40s\tremaining: 1m 40s\n",
      "4101:\ttotal: 7m 40s\tremaining: 1m 40s\n",
      "4102:\ttotal: 7m 40s\tremaining: 1m 40s\n",
      "4103:\ttotal: 7m 40s\tremaining: 1m 40s\n",
      "4104:\ttotal: 7m 40s\tremaining: 1m 40s\n",
      "4105:\tlearn: 0.6039439\ttest: 1.0153213\tbest: 1.0153213 (4105)\ttotal: 7m 40s\tremaining: 1m 40s\n",
      "4106:\ttotal: 7m 40s\tremaining: 1m 40s\n",
      "4107:\ttotal: 7m 41s\tremaining: 1m 40s\n",
      "4108:\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4109:\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4110:\tlearn: 0.6035655\ttest: 1.0152685\tbest: 1.0152685 (4110)\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4111:\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4112:\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4113:\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4114:\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4115:\tlearn: 0.6031573\ttest: 1.0151452\tbest: 1.0151452 (4115)\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4116:\ttotal: 7m 41s\tremaining: 1m 39s\n",
      "4117:\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4118:\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4119:\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4120:\tlearn: 0.6026961\ttest: 1.0150962\tbest: 1.0150962 (4120)\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4121:\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4122:\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4123:\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4124:\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4125:\tlearn: 0.6022980\ttest: 1.0150611\tbest: 1.0150611 (4125)\ttotal: 7m 42s\tremaining: 1m 38s\n",
      "4126:\ttotal: 7m 42s\tremaining: 1m 37s\n",
      "4127:\ttotal: 7m 43s\tremaining: 1m 37s\n",
      "4128:\ttotal: 7m 43s\tremaining: 1m 37s\n",
      "4129:\ttotal: 7m 43s\tremaining: 1m 37s\n",
      "4130:\tlearn: 0.6019095\ttest: 1.0149942\tbest: 1.0149942 (4130)\ttotal: 7m 43s\tremaining: 1m 37s\n",
      "4131:\ttotal: 7m 43s\tremaining: 1m 37s\n",
      "4132:\ttotal: 7m 43s\tremaining: 1m 37s\n",
      "4133:\ttotal: 7m 43s\tremaining: 1m 37s\n",
      "4134:\ttotal: 7m 43s\tremaining: 1m 37s\n",
      "4135:\tlearn: 0.6015546\ttest: 1.0149153\tbest: 1.0149153 (4135)\ttotal: 7m 43s\tremaining: 1m 36s\n",
      "4136:\ttotal: 7m 43s\tremaining: 1m 36s\n",
      "4137:\ttotal: 7m 44s\tremaining: 1m 36s\n",
      "4138:\ttotal: 7m 44s\tremaining: 1m 36s\n",
      "4139:\ttotal: 7m 44s\tremaining: 1m 36s\n",
      "4140:\tlearn: 0.6011362\ttest: 1.0148259\tbest: 1.0148259 (4140)\ttotal: 7m 44s\tremaining: 1m 36s\n",
      "4141:\ttotal: 7m 44s\tremaining: 1m 36s\n",
      "4142:\ttotal: 7m 44s\tremaining: 1m 36s\n",
      "4143:\ttotal: 7m 44s\tremaining: 1m 35s\n",
      "4144:\ttotal: 7m 44s\tremaining: 1m 35s\n",
      "4145:\tlearn: 0.6007116\ttest: 1.0147693\tbest: 1.0147693 (4145)\ttotal: 7m 44s\tremaining: 1m 35s\n",
      "4146:\ttotal: 7m 44s\tremaining: 1m 35s\n",
      "4147:\ttotal: 7m 45s\tremaining: 1m 35s\n",
      "4148:\ttotal: 7m 45s\tremaining: 1m 35s\n",
      "4149:\ttotal: 7m 45s\tremaining: 1m 35s\n",
      "4150:\tlearn: 0.6003148\ttest: 1.0147716\tbest: 1.0147693 (4145)\ttotal: 7m 45s\tremaining: 1m 35s\n",
      "4151:\ttotal: 7m 45s\tremaining: 1m 35s\n",
      "4152:\ttotal: 7m 45s\tremaining: 1m 34s\n",
      "4153:\ttotal: 7m 45s\tremaining: 1m 34s\n",
      "4154:\ttotal: 7m 45s\tremaining: 1m 34s\n",
      "4155:\tlearn: 0.5999232\ttest: 1.0146199\tbest: 1.0146199 (4155)\ttotal: 7m 45s\tremaining: 1m 34s\n",
      "4156:\ttotal: 7m 45s\tremaining: 1m 34s\n",
      "4157:\ttotal: 7m 46s\tremaining: 1m 34s\n",
      "4158:\ttotal: 7m 46s\tremaining: 1m 34s\n",
      "4159:\ttotal: 7m 46s\tremaining: 1m 34s\n",
      "4160:\tlearn: 0.5995720\ttest: 1.0145569\tbest: 1.0145569 (4160)\ttotal: 7m 46s\tremaining: 1m 34s\n",
      "4161:\ttotal: 7m 46s\tremaining: 1m 33s\n",
      "4162:\ttotal: 7m 46s\tremaining: 1m 33s\n",
      "4163:\ttotal: 7m 46s\tremaining: 1m 33s\n",
      "4164:\ttotal: 7m 46s\tremaining: 1m 33s\n",
      "4165:\tlearn: 0.5991503\ttest: 1.0144740\tbest: 1.0144740 (4165)\ttotal: 7m 46s\tremaining: 1m 33s\n",
      "4166:\ttotal: 7m 46s\tremaining: 1m 33s\n",
      "4167:\ttotal: 7m 47s\tremaining: 1m 33s\n",
      "4168:\ttotal: 7m 47s\tremaining: 1m 33s\n",
      "4169:\ttotal: 7m 47s\tremaining: 1m 33s\n",
      "4170:\tlearn: 0.5987498\ttest: 1.0144543\tbest: 1.0144543 (4170)\ttotal: 7m 47s\tremaining: 1m 32s\n",
      "4171:\ttotal: 7m 47s\tremaining: 1m 32s\n",
      "4172:\ttotal: 7m 47s\tremaining: 1m 32s\n",
      "4173:\ttotal: 7m 47s\tremaining: 1m 32s\n",
      "4174:\ttotal: 7m 47s\tremaining: 1m 32s\n",
      "4175:\tlearn: 0.5983319\ttest: 1.0143930\tbest: 1.0143930 (4175)\ttotal: 7m 47s\tremaining: 1m 32s\n",
      "4176:\ttotal: 7m 48s\tremaining: 1m 32s\n",
      "4177:\ttotal: 7m 48s\tremaining: 1m 32s\n",
      "4178:\ttotal: 7m 48s\tremaining: 1m 31s\n",
      "4179:\ttotal: 7m 48s\tremaining: 1m 31s\n",
      "4180:\tlearn: 0.5979483\ttest: 1.0143308\tbest: 1.0143308 (4180)\ttotal: 7m 48s\tremaining: 1m 31s\n",
      "4181:\ttotal: 7m 48s\tremaining: 1m 31s\n",
      "4182:\ttotal: 7m 48s\tremaining: 1m 31s\n",
      "4183:\ttotal: 7m 48s\tremaining: 1m 31s\n",
      "4184:\ttotal: 7m 48s\tremaining: 1m 31s\n",
      "4185:\tlearn: 0.5975507\ttest: 1.0142748\tbest: 1.0142748 (4185)\ttotal: 7m 48s\tremaining: 1m 31s\n",
      "4186:\ttotal: 7m 49s\tremaining: 1m 31s\n",
      "4187:\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4188:\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4189:\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4190:\tlearn: 0.5972022\ttest: 1.0142188\tbest: 1.0142188 (4190)\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4191:\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4192:\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4193:\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4194:\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4195:\tlearn: 0.5968744\ttest: 1.0141384\tbest: 1.0141384 (4195)\ttotal: 7m 49s\tremaining: 1m 30s\n",
      "4196:\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4197:\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4198:\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4199:\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4200:\tlearn: 0.5964670\ttest: 1.0141368\tbest: 1.0141368 (4200)\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4201:\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4202:\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4203:\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4204:\ttotal: 7m 50s\tremaining: 1m 29s\n",
      "4205:\tlearn: 0.5960858\ttest: 1.0140593\tbest: 1.0140593 (4205)\ttotal: 7m 50s\tremaining: 1m 28s\n",
      "4206:\ttotal: 7m 51s\tremaining: 1m 28s\n",
      "4207:\ttotal: 7m 51s\tremaining: 1m 28s\n",
      "4208:\ttotal: 7m 51s\tremaining: 1m 28s\n",
      "4209:\ttotal: 7m 51s\tremaining: 1m 28s\n",
      "4210:\tlearn: 0.5956869\ttest: 1.0139882\tbest: 1.0139882 (4210)\ttotal: 7m 51s\tremaining: 1m 28s\n",
      "4211:\ttotal: 7m 51s\tremaining: 1m 28s\n",
      "4212:\ttotal: 7m 51s\tremaining: 1m 28s\n",
      "4213:\ttotal: 7m 51s\tremaining: 1m 28s\n",
      "4214:\ttotal: 7m 51s\tremaining: 1m 27s\n",
      "4215:\tlearn: 0.5953096\ttest: 1.0138925\tbest: 1.0138925 (4215)\ttotal: 7m 52s\tremaining: 1m 27s\n",
      "4216:\ttotal: 7m 52s\tremaining: 1m 27s\n",
      "4217:\ttotal: 7m 52s\tremaining: 1m 27s\n",
      "4218:\ttotal: 7m 52s\tremaining: 1m 27s\n",
      "4219:\ttotal: 7m 52s\tremaining: 1m 27s\n",
      "4220:\tlearn: 0.5948957\ttest: 1.0138503\tbest: 1.0138503 (4220)\ttotal: 7m 52s\tremaining: 1m 27s\n",
      "4221:\ttotal: 7m 52s\tremaining: 1m 27s\n",
      "4222:\ttotal: 7m 52s\tremaining: 1m 26s\n",
      "4223:\ttotal: 7m 52s\tremaining: 1m 26s\n",
      "4224:\ttotal: 7m 52s\tremaining: 1m 26s\n",
      "4225:\tlearn: 0.5944886\ttest: 1.0137183\tbest: 1.0137183 (4225)\ttotal: 7m 53s\tremaining: 1m 26s\n",
      "4226:\ttotal: 7m 53s\tremaining: 1m 26s\n",
      "4227:\ttotal: 7m 53s\tremaining: 1m 26s\n",
      "4228:\ttotal: 7m 53s\tremaining: 1m 26s\n",
      "4229:\ttotal: 7m 53s\tremaining: 1m 26s\n",
      "4230:\tlearn: 0.5941473\ttest: 1.0136661\tbest: 1.0136661 (4230)\ttotal: 7m 53s\tremaining: 1m 26s\n",
      "4231:\ttotal: 7m 53s\tremaining: 1m 25s\n",
      "4232:\ttotal: 7m 53s\tremaining: 1m 25s\n",
      "4233:\ttotal: 7m 53s\tremaining: 1m 25s\n",
      "4234:\ttotal: 7m 53s\tremaining: 1m 25s\n",
      "4235:\tlearn: 0.5937846\ttest: 1.0136597\tbest: 1.0136597 (4235)\ttotal: 7m 53s\tremaining: 1m 25s\n",
      "4236:\ttotal: 7m 54s\tremaining: 1m 25s\n",
      "4237:\ttotal: 7m 54s\tremaining: 1m 25s\n",
      "4238:\ttotal: 7m 54s\tremaining: 1m 25s\n",
      "4239:\ttotal: 7m 54s\tremaining: 1m 25s\n",
      "4240:\tlearn: 0.5934379\ttest: 1.0136468\tbest: 1.0136468 (4240)\ttotal: 7m 54s\tremaining: 1m 24s\n",
      "4241:\ttotal: 7m 54s\tremaining: 1m 24s\n",
      "4242:\ttotal: 7m 54s\tremaining: 1m 24s\n",
      "4243:\ttotal: 7m 54s\tremaining: 1m 24s\n",
      "4244:\ttotal: 7m 54s\tremaining: 1m 24s\n",
      "4245:\tlearn: 0.5930656\ttest: 1.0134990\tbest: 1.0134990 (4245)\ttotal: 7m 54s\tremaining: 1m 24s\n",
      "4246:\ttotal: 7m 55s\tremaining: 1m 24s\n",
      "4247:\ttotal: 7m 55s\tremaining: 1m 24s\n",
      "4248:\ttotal: 7m 55s\tremaining: 1m 23s\n",
      "4249:\ttotal: 7m 55s\tremaining: 1m 23s\n",
      "4250:\tlearn: 0.5926919\ttest: 1.0133716\tbest: 1.0133716 (4250)\ttotal: 7m 55s\tremaining: 1m 23s\n",
      "4251:\ttotal: 7m 55s\tremaining: 1m 23s\n",
      "4252:\ttotal: 7m 55s\tremaining: 1m 23s\n",
      "4253:\ttotal: 7m 55s\tremaining: 1m 23s\n",
      "4254:\ttotal: 7m 55s\tremaining: 1m 23s\n",
      "4255:\tlearn: 0.5923054\ttest: 1.0132753\tbest: 1.0132753 (4255)\ttotal: 7m 55s\tremaining: 1m 23s\n",
      "4256:\ttotal: 7m 56s\tremaining: 1m 23s\n",
      "4257:\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4258:\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4259:\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4260:\tlearn: 0.5919139\ttest: 1.0131840\tbest: 1.0131840 (4260)\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4261:\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4262:\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4263:\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4264:\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4265:\tlearn: 0.5915808\ttest: 1.0131654\tbest: 1.0131654 (4265)\ttotal: 7m 56s\tremaining: 1m 22s\n",
      "4266:\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4267:\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4268:\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4269:\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4270:\tlearn: 0.5912490\ttest: 1.0130177\tbest: 1.0130177 (4270)\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4271:\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4272:\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4273:\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4274:\ttotal: 7m 57s\tremaining: 1m 21s\n",
      "4275:\tlearn: 0.5908336\ttest: 1.0129192\tbest: 1.0129192 (4275)\ttotal: 7m 57s\tremaining: 1m 20s\n",
      "4276:\ttotal: 7m 58s\tremaining: 1m 20s\n",
      "4277:\ttotal: 7m 58s\tremaining: 1m 20s\n",
      "4278:\ttotal: 7m 58s\tremaining: 1m 20s\n",
      "4279:\ttotal: 7m 58s\tremaining: 1m 20s\n",
      "4280:\tlearn: 0.5903973\ttest: 1.0128966\tbest: 1.0128966 (4280)\ttotal: 7m 58s\tremaining: 1m 20s\n",
      "4281:\ttotal: 7m 58s\tremaining: 1m 20s\n",
      "4282:\ttotal: 7m 58s\tremaining: 1m 20s\n",
      "4283:\ttotal: 7m 58s\tremaining: 1m 20s\n",
      "4284:\ttotal: 7m 58s\tremaining: 1m 19s\n",
      "4285:\tlearn: 0.5900111\ttest: 1.0127931\tbest: 1.0127931 (4285)\ttotal: 7m 59s\tremaining: 1m 19s\n",
      "4286:\ttotal: 7m 59s\tremaining: 1m 19s\n",
      "4287:\ttotal: 7m 59s\tremaining: 1m 19s\n",
      "4288:\ttotal: 7m 59s\tremaining: 1m 19s\n",
      "4289:\ttotal: 7m 59s\tremaining: 1m 19s\n",
      "4290:\tlearn: 0.5896348\ttest: 1.0126724\tbest: 1.0126724 (4290)\ttotal: 7m 59s\tremaining: 1m 19s\n",
      "4291:\ttotal: 7m 59s\tremaining: 1m 19s\n",
      "4292:\ttotal: 7m 59s\tremaining: 1m 19s\n",
      "4293:\ttotal: 7m 59s\tremaining: 1m 18s\n",
      "4294:\ttotal: 7m 59s\tremaining: 1m 18s\n",
      "4295:\tlearn: 0.5893177\ttest: 1.0126261\tbest: 1.0126261 (4295)\ttotal: 8m\tremaining: 1m 18s\n",
      "4296:\ttotal: 8m\tremaining: 1m 18s\n",
      "4297:\ttotal: 8m\tremaining: 1m 18s\n",
      "4298:\ttotal: 8m\tremaining: 1m 18s\n",
      "4299:\ttotal: 8m\tremaining: 1m 18s\n",
      "4300:\tlearn: 0.5889489\ttest: 1.0126237\tbest: 1.0126237 (4300)\ttotal: 8m\tremaining: 1m 18s\n",
      "4301:\ttotal: 8m\tremaining: 1m 17s\n",
      "4302:\ttotal: 8m\tremaining: 1m 17s\n",
      "4303:\ttotal: 8m\tremaining: 1m 17s\n",
      "4304:\ttotal: 8m\tremaining: 1m 17s\n",
      "4305:\tlearn: 0.5885496\ttest: 1.0125919\tbest: 1.0125919 (4305)\ttotal: 8m 1s\tremaining: 1m 17s\n",
      "4306:\ttotal: 8m 1s\tremaining: 1m 17s\n",
      "4307:\ttotal: 8m 1s\tremaining: 1m 17s\n",
      "4308:\ttotal: 8m 1s\tremaining: 1m 17s\n",
      "4309:\ttotal: 8m 1s\tremaining: 1m 17s\n",
      "4310:\tlearn: 0.5881746\ttest: 1.0125100\tbest: 1.0125100 (4310)\ttotal: 8m 1s\tremaining: 1m 16s\n",
      "4311:\ttotal: 8m 1s\tremaining: 1m 16s\n",
      "4312:\ttotal: 8m 1s\tremaining: 1m 16s\n",
      "4313:\ttotal: 8m 1s\tremaining: 1m 16s\n",
      "4314:\ttotal: 8m 1s\tremaining: 1m 16s\n",
      "4315:\tlearn: 0.5878114\ttest: 1.0124349\tbest: 1.0124349 (4315)\ttotal: 8m 2s\tremaining: 1m 16s\n",
      "4316:\ttotal: 8m 2s\tremaining: 1m 16s\n",
      "4317:\ttotal: 8m 2s\tremaining: 1m 16s\n",
      "4318:\ttotal: 8m 2s\tremaining: 1m 16s\n",
      "4319:\ttotal: 8m 2s\tremaining: 1m 15s\n",
      "4320:\tlearn: 0.5874170\ttest: 1.0123988\tbest: 1.0123988 (4320)\ttotal: 8m 2s\tremaining: 1m 15s\n",
      "4321:\ttotal: 8m 2s\tremaining: 1m 15s\n",
      "4322:\ttotal: 8m 2s\tremaining: 1m 15s\n",
      "4323:\ttotal: 8m 2s\tremaining: 1m 15s\n",
      "4324:\ttotal: 8m 3s\tremaining: 1m 15s\n",
      "4325:\tlearn: 0.5869915\ttest: 1.0123740\tbest: 1.0123740 (4325)\ttotal: 8m 3s\tremaining: 1m 15s\n",
      "4326:\ttotal: 8m 3s\tremaining: 1m 15s\n",
      "4327:\ttotal: 8m 3s\tremaining: 1m 15s\n",
      "4328:\ttotal: 8m 3s\tremaining: 1m 14s\n",
      "4329:\ttotal: 8m 3s\tremaining: 1m 14s\n",
      "4330:\tlearn: 0.5865713\ttest: 1.0123036\tbest: 1.0123036 (4330)\ttotal: 8m 3s\tremaining: 1m 14s\n",
      "4331:\ttotal: 8m 3s\tremaining: 1m 14s\n",
      "4332:\ttotal: 8m 3s\tremaining: 1m 14s\n",
      "4333:\ttotal: 8m 3s\tremaining: 1m 14s\n",
      "4334:\ttotal: 8m 4s\tremaining: 1m 14s\n",
      "4335:\tlearn: 0.5862316\ttest: 1.0121964\tbest: 1.0121964 (4335)\ttotal: 8m 4s\tremaining: 1m 14s\n",
      "4336:\ttotal: 8m 4s\tremaining: 1m 14s\n",
      "4337:\ttotal: 8m 4s\tremaining: 1m 13s\n",
      "4338:\ttotal: 8m 4s\tremaining: 1m 13s\n",
      "4339:\ttotal: 8m 4s\tremaining: 1m 13s\n",
      "4340:\tlearn: 0.5858085\ttest: 1.0121105\tbest: 1.0121105 (4340)\ttotal: 8m 4s\tremaining: 1m 13s\n",
      "4341:\ttotal: 8m 4s\tremaining: 1m 13s\n",
      "4342:\ttotal: 8m 4s\tremaining: 1m 13s\n",
      "4343:\ttotal: 8m 4s\tremaining: 1m 13s\n",
      "4344:\ttotal: 8m 4s\tremaining: 1m 13s\n",
      "4345:\tlearn: 0.5854724\ttest: 1.0120270\tbest: 1.0120270 (4345)\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4346:\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4347:\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4348:\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4349:\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4350:\tlearn: 0.5850520\ttest: 1.0119141\tbest: 1.0119141 (4350)\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4351:\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4352:\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4353:\ttotal: 8m 5s\tremaining: 1m 12s\n",
      "4354:\ttotal: 8m 5s\tremaining: 1m 11s\n",
      "4355:\tlearn: 0.5846767\ttest: 1.0118805\tbest: 1.0118805 (4355)\ttotal: 8m 6s\tremaining: 1m 11s\n",
      "4356:\ttotal: 8m 6s\tremaining: 1m 11s\n",
      "4357:\ttotal: 8m 6s\tremaining: 1m 11s\n",
      "4358:\ttotal: 8m 6s\tremaining: 1m 11s\n",
      "4359:\ttotal: 8m 6s\tremaining: 1m 11s\n",
      "4360:\tlearn: 0.5842324\ttest: 1.0117071\tbest: 1.0117071 (4360)\ttotal: 8m 6s\tremaining: 1m 11s\n",
      "4361:\ttotal: 8m 6s\tremaining: 1m 11s\n",
      "4362:\ttotal: 8m 6s\tremaining: 1m 11s\n",
      "4363:\ttotal: 8m 6s\tremaining: 1m 10s\n",
      "4364:\ttotal: 8m 6s\tremaining: 1m 10s\n",
      "4365:\tlearn: 0.5838836\ttest: 1.0116522\tbest: 1.0116522 (4365)\ttotal: 8m 7s\tremaining: 1m 10s\n",
      "4366:\ttotal: 8m 7s\tremaining: 1m 10s\n",
      "4367:\ttotal: 8m 7s\tremaining: 1m 10s\n",
      "4368:\ttotal: 8m 7s\tremaining: 1m 10s\n",
      "4369:\ttotal: 8m 7s\tremaining: 1m 10s\n",
      "4370:\tlearn: 0.5835665\ttest: 1.0115737\tbest: 1.0115737 (4370)\ttotal: 8m 7s\tremaining: 1m 10s\n",
      "4371:\ttotal: 8m 7s\tremaining: 1m 10s\n",
      "4372:\ttotal: 8m 7s\tremaining: 1m 9s\n",
      "4373:\ttotal: 8m 7s\tremaining: 1m 9s\n",
      "4374:\ttotal: 8m 7s\tremaining: 1m 9s\n",
      "4375:\tlearn: 0.5832007\ttest: 1.0115861\tbest: 1.0115737 (4370)\ttotal: 8m 8s\tremaining: 1m 9s\n",
      "4376:\ttotal: 8m 8s\tremaining: 1m 9s\n",
      "4377:\ttotal: 8m 8s\tremaining: 1m 9s\n",
      "4378:\ttotal: 8m 8s\tremaining: 1m 9s\n",
      "4379:\ttotal: 8m 8s\tremaining: 1m 9s\n",
      "4380:\tlearn: 0.5828664\ttest: 1.0115560\tbest: 1.0115560 (4380)\ttotal: 8m 8s\tremaining: 1m 9s\n",
      "4381:\ttotal: 8m 8s\tremaining: 1m 8s\n",
      "4382:\ttotal: 8m 8s\tremaining: 1m 8s\n",
      "4383:\ttotal: 8m 8s\tremaining: 1m 8s\n",
      "4384:\ttotal: 8m 8s\tremaining: 1m 8s\n",
      "4385:\tlearn: 0.5824892\ttest: 1.0115057\tbest: 1.0115057 (4385)\ttotal: 8m 8s\tremaining: 1m 8s\n",
      "4386:\ttotal: 8m 9s\tremaining: 1m 8s\n",
      "4387:\ttotal: 8m 9s\tremaining: 1m 8s\n",
      "4388:\ttotal: 8m 9s\tremaining: 1m 8s\n",
      "4389:\ttotal: 8m 9s\tremaining: 1m 7s\n",
      "4390:\tlearn: 0.5821724\ttest: 1.0114271\tbest: 1.0114271 (4390)\ttotal: 8m 9s\tremaining: 1m 7s\n",
      "4391:\ttotal: 8m 9s\tremaining: 1m 7s\n",
      "4392:\ttotal: 8m 9s\tremaining: 1m 7s\n",
      "4393:\ttotal: 8m 9s\tremaining: 1m 7s\n",
      "4394:\ttotal: 8m 9s\tremaining: 1m 7s\n",
      "4395:\tlearn: 0.5817988\ttest: 1.0113624\tbest: 1.0113624 (4395)\ttotal: 8m 9s\tremaining: 1m 7s\n",
      "4396:\ttotal: 8m 10s\tremaining: 1m 7s\n",
      "4397:\ttotal: 8m 10s\tremaining: 1m 7s\n",
      "4398:\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "4399:\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "4400:\tlearn: 0.5814502\ttest: 1.0112494\tbest: 1.0112494 (4400)\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "4401:\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "4402:\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "4403:\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "4404:\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "4405:\tlearn: 0.5811165\ttest: 1.0111715\tbest: 1.0111715 (4405)\ttotal: 8m 10s\tremaining: 1m 6s\n",
      "4406:\ttotal: 8m 11s\tremaining: 1m 6s\n",
      "4407:\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4408:\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4409:\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4410:\tlearn: 0.5807477\ttest: 1.0111331\tbest: 1.0111331 (4410)\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4411:\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4412:\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4413:\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4414:\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4415:\tlearn: 0.5804112\ttest: 1.0110618\tbest: 1.0110618 (4415)\ttotal: 8m 11s\tremaining: 1m 5s\n",
      "4416:\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4417:\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4418:\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4419:\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4420:\tlearn: 0.5800110\ttest: 1.0109869\tbest: 1.0109869 (4420)\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4421:\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4422:\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4423:\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4424:\ttotal: 8m 12s\tremaining: 1m 4s\n",
      "4425:\tlearn: 0.5796549\ttest: 1.0109167\tbest: 1.0109167 (4425)\ttotal: 8m 12s\tremaining: 1m 3s\n",
      "4426:\ttotal: 8m 13s\tremaining: 1m 3s\n",
      "4427:\ttotal: 8m 13s\tremaining: 1m 3s\n",
      "4428:\ttotal: 8m 13s\tremaining: 1m 3s\n",
      "4429:\ttotal: 8m 13s\tremaining: 1m 3s\n",
      "4430:\tlearn: 0.5792967\ttest: 1.0108593\tbest: 1.0108593 (4430)\ttotal: 8m 13s\tremaining: 1m 3s\n",
      "4431:\ttotal: 8m 13s\tremaining: 1m 3s\n",
      "4432:\ttotal: 8m 13s\tremaining: 1m 3s\n",
      "4433:\ttotal: 8m 13s\tremaining: 1m 3s\n",
      "4434:\ttotal: 8m 13s\tremaining: 1m 2s\n",
      "4435:\tlearn: 0.5789191\ttest: 1.0107452\tbest: 1.0107452 (4435)\ttotal: 8m 13s\tremaining: 1m 2s\n",
      "4436:\ttotal: 8m 14s\tremaining: 1m 2s\n",
      "4437:\ttotal: 8m 14s\tremaining: 1m 2s\n",
      "4438:\ttotal: 8m 14s\tremaining: 1m 2s\n",
      "4439:\ttotal: 8m 14s\tremaining: 1m 2s\n",
      "4440:\tlearn: 0.5785630\ttest: 1.0106989\tbest: 1.0106989 (4440)\ttotal: 8m 14s\tremaining: 1m 2s\n",
      "4441:\ttotal: 8m 14s\tremaining: 1m 2s\n",
      "4442:\ttotal: 8m 14s\tremaining: 1m 2s\n",
      "4443:\ttotal: 8m 14s\tremaining: 1m 1s\n",
      "4444:\ttotal: 8m 14s\tremaining: 1m 1s\n",
      "4445:\tlearn: 0.5782276\ttest: 1.0106200\tbest: 1.0106200 (4445)\ttotal: 8m 14s\tremaining: 1m 1s\n",
      "4446:\ttotal: 8m 15s\tremaining: 1m 1s\n",
      "4447:\ttotal: 8m 15s\tremaining: 1m 1s\n",
      "4448:\ttotal: 8m 15s\tremaining: 1m 1s\n",
      "4449:\ttotal: 8m 15s\tremaining: 1m 1s\n",
      "4450:\tlearn: 0.5778493\ttest: 1.0104868\tbest: 1.0104868 (4450)\ttotal: 8m 15s\tremaining: 1m 1s\n",
      "4451:\ttotal: 8m 15s\tremaining: 1m 1s\n",
      "4452:\ttotal: 8m 15s\tremaining: 1m\n",
      "4453:\ttotal: 8m 15s\tremaining: 1m\n",
      "4454:\ttotal: 8m 15s\tremaining: 1m\n",
      "4455:\tlearn: 0.5774790\ttest: 1.0103856\tbest: 1.0103856 (4455)\ttotal: 8m 16s\tremaining: 1m\n",
      "4456:\ttotal: 8m 16s\tremaining: 1m\n",
      "4457:\ttotal: 8m 16s\tremaining: 1m\n",
      "4458:\ttotal: 8m 16s\tremaining: 1m\n",
      "4459:\ttotal: 8m 16s\tremaining: 1m\n",
      "4460:\tlearn: 0.5770811\ttest: 1.0103979\tbest: 1.0103856 (4455)\ttotal: 8m 16s\tremaining: 1m\n",
      "4461:\ttotal: 8m 16s\tremaining: 59.9s\n",
      "4462:\ttotal: 8m 16s\tremaining: 59.8s\n",
      "4463:\ttotal: 8m 16s\tremaining: 59.7s\n",
      "4464:\ttotal: 8m 17s\tremaining: 59.6s\n",
      "4465:\tlearn: 0.5766536\ttest: 1.0103075\tbest: 1.0103075 (4465)\ttotal: 8m 17s\tremaining: 59.5s\n",
      "4466:\ttotal: 8m 17s\tremaining: 59.3s\n",
      "4467:\ttotal: 8m 17s\tremaining: 59.2s\n",
      "4468:\ttotal: 8m 17s\tremaining: 59.1s\n",
      "4469:\ttotal: 8m 17s\tremaining: 59s\n",
      "4470:\tlearn: 0.5763194\ttest: 1.0102693\tbest: 1.0102693 (4470)\ttotal: 8m 17s\tremaining: 58.9s\n",
      "4471:\ttotal: 8m 17s\tremaining: 58.8s\n",
      "4472:\ttotal: 8m 17s\tremaining: 58.7s\n",
      "4473:\ttotal: 8m 18s\tremaining: 58.6s\n",
      "4474:\ttotal: 8m 18s\tremaining: 58.4s\n",
      "4475:\tlearn: 0.5759579\ttest: 1.0101956\tbest: 1.0101956 (4475)\ttotal: 8m 18s\tremaining: 58.3s\n",
      "4476:\ttotal: 8m 18s\tremaining: 58.2s\n",
      "4477:\ttotal: 8m 18s\tremaining: 58.1s\n",
      "4478:\ttotal: 8m 18s\tremaining: 58s\n",
      "4479:\ttotal: 8m 18s\tremaining: 57.9s\n",
      "4480:\tlearn: 0.5756281\ttest: 1.0101644\tbest: 1.0101644 (4480)\ttotal: 8m 18s\tremaining: 57.8s\n",
      "4481:\ttotal: 8m 18s\tremaining: 57.7s\n",
      "4482:\ttotal: 8m 18s\tremaining: 57.5s\n",
      "4483:\ttotal: 8m 19s\tremaining: 57.4s\n",
      "4484:\ttotal: 8m 19s\tremaining: 57.3s\n",
      "4485:\tlearn: 0.5752336\ttest: 1.0100939\tbest: 1.0100939 (4485)\ttotal: 8m 19s\tremaining: 57.2s\n",
      "4486:\ttotal: 8m 19s\tremaining: 57.1s\n",
      "4487:\ttotal: 8m 19s\tremaining: 57s\n",
      "4488:\ttotal: 8m 19s\tremaining: 56.9s\n",
      "4489:\ttotal: 8m 19s\tremaining: 56.8s\n",
      "4490:\tlearn: 0.5748641\ttest: 1.0100576\tbest: 1.0100576 (4490)\ttotal: 8m 19s\tremaining: 56.7s\n",
      "4491:\ttotal: 8m 19s\tremaining: 56.5s\n",
      "4492:\ttotal: 8m 20s\tremaining: 56.4s\n",
      "4493:\ttotal: 8m 20s\tremaining: 56.3s\n",
      "4494:\ttotal: 8m 20s\tremaining: 56.2s\n",
      "4495:\tlearn: 0.5744815\ttest: 1.0099408\tbest: 1.0099408 (4495)\ttotal: 8m 20s\tremaining: 56.1s\n",
      "4496:\ttotal: 8m 20s\tremaining: 56s\n",
      "4497:\ttotal: 8m 20s\tremaining: 55.9s\n",
      "4498:\ttotal: 8m 20s\tremaining: 55.8s\n",
      "4499:\ttotal: 8m 20s\tremaining: 55.6s\n",
      "4500:\tlearn: 0.5741614\ttest: 1.0098965\tbest: 1.0098965 (4500)\ttotal: 8m 20s\tremaining: 55.5s\n",
      "4501:\ttotal: 8m 21s\tremaining: 55.4s\n",
      "4502:\ttotal: 8m 21s\tremaining: 55.3s\n",
      "4503:\ttotal: 8m 21s\tremaining: 55.2s\n",
      "4504:\ttotal: 8m 21s\tremaining: 55.1s\n",
      "4505:\tlearn: 0.5737963\ttest: 1.0098153\tbest: 1.0098153 (4505)\ttotal: 8m 21s\tremaining: 55s\n",
      "4506:\ttotal: 8m 21s\tremaining: 54.9s\n",
      "4507:\ttotal: 8m 21s\tremaining: 54.7s\n",
      "4508:\ttotal: 8m 21s\tremaining: 54.6s\n",
      "4509:\ttotal: 8m 21s\tremaining: 54.5s\n",
      "4510:\tlearn: 0.5734645\ttest: 1.0097532\tbest: 1.0097532 (4510)\ttotal: 8m 21s\tremaining: 54.4s\n",
      "4511:\ttotal: 8m 22s\tremaining: 54.3s\n",
      "4512:\ttotal: 8m 22s\tremaining: 54.2s\n",
      "4513:\ttotal: 8m 22s\tremaining: 54.1s\n",
      "4514:\ttotal: 8m 22s\tremaining: 54s\n",
      "4515:\tlearn: 0.5731087\ttest: 1.0096867\tbest: 1.0096867 (4515)\ttotal: 8m 22s\tremaining: 53.9s\n",
      "4516:\ttotal: 8m 22s\tremaining: 53.7s\n",
      "4517:\ttotal: 8m 22s\tremaining: 53.6s\n",
      "4518:\ttotal: 8m 22s\tremaining: 53.5s\n",
      "4519:\ttotal: 8m 22s\tremaining: 53.4s\n",
      "4520:\tlearn: 0.5728032\ttest: 1.0095814\tbest: 1.0095814 (4520)\ttotal: 8m 22s\tremaining: 53.3s\n",
      "4521:\ttotal: 8m 23s\tremaining: 53.2s\n",
      "4522:\ttotal: 8m 23s\tremaining: 53.1s\n",
      "4523:\ttotal: 8m 23s\tremaining: 53s\n",
      "4524:\ttotal: 8m 23s\tremaining: 52.8s\n",
      "4525:\tlearn: 0.5724334\ttest: 1.0095318\tbest: 1.0095318 (4525)\ttotal: 8m 23s\tremaining: 52.7s\n",
      "4526:\ttotal: 8m 23s\tremaining: 52.6s\n",
      "4527:\ttotal: 8m 23s\tremaining: 52.5s\n",
      "4528:\ttotal: 8m 23s\tremaining: 52.4s\n",
      "4529:\ttotal: 8m 23s\tremaining: 52.3s\n",
      "4530:\tlearn: 0.5720675\ttest: 1.0094390\tbest: 1.0094390 (4530)\ttotal: 8m 24s\tremaining: 52.2s\n",
      "4531:\ttotal: 8m 24s\tremaining: 52.1s\n",
      "4532:\ttotal: 8m 24s\tremaining: 51.9s\n",
      "4533:\ttotal: 8m 24s\tremaining: 51.8s\n",
      "4534:\ttotal: 8m 24s\tremaining: 51.7s\n",
      "4535:\tlearn: 0.5717359\ttest: 1.0093680\tbest: 1.0093680 (4535)\ttotal: 8m 24s\tremaining: 51.6s\n",
      "4536:\ttotal: 8m 24s\tremaining: 51.5s\n",
      "4537:\ttotal: 8m 24s\tremaining: 51.4s\n",
      "4538:\ttotal: 8m 24s\tremaining: 51.3s\n",
      "4539:\ttotal: 8m 24s\tremaining: 51.2s\n",
      "4540:\tlearn: 0.5714033\ttest: 1.0093256\tbest: 1.0093256 (4540)\ttotal: 8m 25s\tremaining: 51.1s\n",
      "4541:\ttotal: 8m 25s\tremaining: 50.9s\n",
      "4542:\ttotal: 8m 25s\tremaining: 50.8s\n",
      "4543:\ttotal: 8m 25s\tremaining: 50.7s\n",
      "4544:\ttotal: 8m 25s\tremaining: 50.6s\n",
      "4545:\tlearn: 0.5710693\ttest: 1.0092141\tbest: 1.0092141 (4545)\ttotal: 8m 25s\tremaining: 50.5s\n",
      "4546:\ttotal: 8m 25s\tremaining: 50.4s\n",
      "4547:\ttotal: 8m 25s\tremaining: 50.3s\n",
      "4548:\ttotal: 8m 25s\tremaining: 50.1s\n",
      "4549:\ttotal: 8m 25s\tremaining: 50s\n",
      "4550:\tlearn: 0.5707786\ttest: 1.0091550\tbest: 1.0091550 (4550)\ttotal: 8m 26s\tremaining: 49.9s\n",
      "4551:\ttotal: 8m 26s\tremaining: 49.8s\n",
      "4552:\ttotal: 8m 26s\tremaining: 49.7s\n",
      "4553:\ttotal: 8m 26s\tremaining: 49.6s\n",
      "4554:\ttotal: 8m 26s\tremaining: 49.5s\n",
      "4555:\tlearn: 0.5704392\ttest: 1.0090917\tbest: 1.0090917 (4555)\ttotal: 8m 26s\tremaining: 49.4s\n",
      "4556:\ttotal: 8m 26s\tremaining: 49.2s\n",
      "4557:\ttotal: 8m 26s\tremaining: 49.1s\n",
      "4558:\ttotal: 8m 26s\tremaining: 49s\n",
      "4559:\ttotal: 8m 26s\tremaining: 48.9s\n",
      "4560:\tlearn: 0.5700973\ttest: 1.0090950\tbest: 1.0090917 (4555)\ttotal: 8m 27s\tremaining: 48.8s\n",
      "4561:\ttotal: 8m 27s\tremaining: 48.7s\n",
      "4562:\ttotal: 8m 27s\tremaining: 48.6s\n",
      "4563:\ttotal: 8m 27s\tremaining: 48.5s\n",
      "4564:\ttotal: 8m 27s\tremaining: 48.4s\n",
      "4565:\tlearn: 0.5697324\ttest: 1.0089993\tbest: 1.0089993 (4565)\ttotal: 8m 27s\tremaining: 48.2s\n",
      "4566:\ttotal: 8m 27s\tremaining: 48.1s\n",
      "4567:\ttotal: 8m 27s\tremaining: 48s\n",
      "4568:\ttotal: 8m 27s\tremaining: 47.9s\n",
      "4569:\ttotal: 8m 27s\tremaining: 47.8s\n",
      "4570:\tlearn: 0.5694069\ttest: 1.0090146\tbest: 1.0089993 (4565)\ttotal: 8m 28s\tremaining: 47.7s\n",
      "4571:\ttotal: 8m 28s\tremaining: 47.6s\n",
      "4572:\ttotal: 8m 28s\tremaining: 47.5s\n",
      "4573:\ttotal: 8m 28s\tremaining: 47.3s\n",
      "4574:\ttotal: 8m 28s\tremaining: 47.2s\n",
      "4575:\tlearn: 0.5690636\ttest: 1.0089174\tbest: 1.0089174 (4575)\ttotal: 8m 28s\tremaining: 47.1s\n",
      "4576:\ttotal: 8m 28s\tremaining: 47s\n",
      "4577:\ttotal: 8m 28s\tremaining: 46.9s\n",
      "4578:\ttotal: 8m 28s\tremaining: 46.8s\n",
      "4579:\ttotal: 8m 28s\tremaining: 46.7s\n",
      "4580:\tlearn: 0.5686777\ttest: 1.0088697\tbest: 1.0088697 (4580)\ttotal: 8m 29s\tremaining: 46.6s\n",
      "4581:\ttotal: 8m 29s\tremaining: 46.5s\n",
      "4582:\ttotal: 8m 29s\tremaining: 46.3s\n",
      "4583:\ttotal: 8m 29s\tremaining: 46.2s\n",
      "4584:\ttotal: 8m 29s\tremaining: 46.1s\n",
      "4585:\tlearn: 0.5683145\ttest: 1.0087843\tbest: 1.0087843 (4585)\ttotal: 8m 29s\tremaining: 46s\n",
      "4586:\ttotal: 8m 29s\tremaining: 45.9s\n",
      "4587:\ttotal: 8m 29s\tremaining: 45.8s\n",
      "4588:\ttotal: 8m 29s\tremaining: 45.7s\n",
      "4589:\ttotal: 8m 30s\tremaining: 45.6s\n",
      "4590:\tlearn: 0.5679834\ttest: 1.0086962\tbest: 1.0086962 (4590)\ttotal: 8m 30s\tremaining: 45.4s\n",
      "4591:\ttotal: 8m 30s\tremaining: 45.3s\n",
      "4592:\ttotal: 8m 30s\tremaining: 45.2s\n",
      "4593:\ttotal: 8m 30s\tremaining: 45.1s\n",
      "4594:\ttotal: 8m 30s\tremaining: 45s\n",
      "4595:\tlearn: 0.5676100\ttest: 1.0086071\tbest: 1.0086071 (4595)\ttotal: 8m 30s\tremaining: 44.9s\n",
      "4596:\ttotal: 8m 30s\tremaining: 44.8s\n",
      "4597:\ttotal: 8m 30s\tremaining: 44.7s\n",
      "4598:\ttotal: 8m 30s\tremaining: 44.5s\n",
      "4599:\ttotal: 8m 30s\tremaining: 44.4s\n",
      "4600:\tlearn: 0.5673560\ttest: 1.0085432\tbest: 1.0085432 (4600)\ttotal: 8m 31s\tremaining: 44.3s\n",
      "4601:\ttotal: 8m 31s\tremaining: 44.2s\n",
      "4602:\ttotal: 8m 31s\tremaining: 44.1s\n",
      "4603:\ttotal: 8m 31s\tremaining: 44s\n",
      "4604:\ttotal: 8m 31s\tremaining: 43.9s\n",
      "4605:\tlearn: 0.5670271\ttest: 1.0084586\tbest: 1.0084586 (4605)\ttotal: 8m 31s\tremaining: 43.8s\n",
      "4606:\ttotal: 8m 31s\tremaining: 43.6s\n",
      "4607:\ttotal: 8m 31s\tremaining: 43.5s\n",
      "4608:\ttotal: 8m 31s\tremaining: 43.4s\n",
      "4609:\ttotal: 8m 31s\tremaining: 43.3s\n",
      "4610:\tlearn: 0.5667023\ttest: 1.0083918\tbest: 1.0083918 (4610)\ttotal: 8m 32s\tremaining: 43.2s\n",
      "4611:\ttotal: 8m 32s\tremaining: 43.1s\n",
      "4612:\ttotal: 8m 32s\tremaining: 43s\n",
      "4613:\ttotal: 8m 32s\tremaining: 42.9s\n",
      "4614:\ttotal: 8m 32s\tremaining: 42.8s\n",
      "4615:\tlearn: 0.5663387\ttest: 1.0083345\tbest: 1.0083345 (4615)\ttotal: 8m 32s\tremaining: 42.6s\n",
      "4616:\ttotal: 8m 32s\tremaining: 42.5s\n",
      "4617:\ttotal: 8m 32s\tremaining: 42.4s\n",
      "4618:\ttotal: 8m 32s\tremaining: 42.3s\n",
      "4619:\ttotal: 8m 32s\tremaining: 42.2s\n",
      "4620:\tlearn: 0.5660390\ttest: 1.0082376\tbest: 1.0082376 (4620)\ttotal: 8m 33s\tremaining: 42.1s\n",
      "4621:\ttotal: 8m 33s\tremaining: 42s\n",
      "4622:\ttotal: 8m 33s\tremaining: 41.9s\n",
      "4623:\ttotal: 8m 33s\tremaining: 41.7s\n",
      "4624:\ttotal: 8m 33s\tremaining: 41.6s\n",
      "4625:\tlearn: 0.5657150\ttest: 1.0081711\tbest: 1.0081711 (4625)\ttotal: 8m 33s\tremaining: 41.5s\n",
      "4626:\ttotal: 8m 33s\tremaining: 41.4s\n",
      "4627:\ttotal: 8m 33s\tremaining: 41.3s\n",
      "4628:\ttotal: 8m 33s\tremaining: 41.2s\n",
      "4629:\ttotal: 8m 33s\tremaining: 41.1s\n",
      "4630:\tlearn: 0.5654432\ttest: 1.0081729\tbest: 1.0081711 (4625)\ttotal: 8m 34s\tremaining: 41s\n",
      "4631:\ttotal: 8m 34s\tremaining: 40.8s\n",
      "4632:\ttotal: 8m 34s\tremaining: 40.7s\n",
      "4633:\ttotal: 8m 34s\tremaining: 40.6s\n",
      "4634:\ttotal: 8m 34s\tremaining: 40.5s\n",
      "4635:\tlearn: 0.5650640\ttest: 1.0081156\tbest: 1.0081156 (4635)\ttotal: 8m 34s\tremaining: 40.4s\n",
      "4636:\ttotal: 8m 34s\tremaining: 40.3s\n",
      "4637:\ttotal: 8m 34s\tremaining: 40.2s\n",
      "4638:\ttotal: 8m 34s\tremaining: 40.1s\n",
      "4639:\ttotal: 8m 34s\tremaining: 40s\n",
      "4640:\tlearn: 0.5647283\ttest: 1.0080354\tbest: 1.0080354 (4640)\ttotal: 8m 35s\tremaining: 39.8s\n",
      "4641:\ttotal: 8m 35s\tremaining: 39.7s\n",
      "4642:\ttotal: 8m 35s\tremaining: 39.6s\n",
      "4643:\ttotal: 8m 35s\tremaining: 39.5s\n",
      "4644:\ttotal: 8m 35s\tremaining: 39.4s\n",
      "4645:\tlearn: 0.5643906\ttest: 1.0079799\tbest: 1.0079799 (4645)\ttotal: 8m 35s\tremaining: 39.3s\n",
      "4646:\ttotal: 8m 35s\tremaining: 39.2s\n",
      "4647:\ttotal: 8m 35s\tremaining: 39.1s\n",
      "4648:\ttotal: 8m 35s\tremaining: 38.9s\n",
      "4649:\ttotal: 8m 35s\tremaining: 38.8s\n",
      "4650:\tlearn: 0.5640640\ttest: 1.0078955\tbest: 1.0078955 (4650)\ttotal: 8m 35s\tremaining: 38.7s\n",
      "4651:\ttotal: 8m 36s\tremaining: 38.6s\n",
      "4652:\ttotal: 8m 36s\tremaining: 38.5s\n",
      "4653:\ttotal: 8m 36s\tremaining: 38.4s\n",
      "4654:\ttotal: 8m 36s\tremaining: 38.3s\n",
      "4655:\tlearn: 0.5637195\ttest: 1.0078154\tbest: 1.0078154 (4655)\ttotal: 8m 36s\tremaining: 38.2s\n",
      "4656:\ttotal: 8m 36s\tremaining: 38s\n",
      "4657:\ttotal: 8m 36s\tremaining: 37.9s\n",
      "4658:\ttotal: 8m 36s\tremaining: 37.8s\n",
      "4659:\ttotal: 8m 36s\tremaining: 37.7s\n",
      "4660:\tlearn: 0.5633803\ttest: 1.0077780\tbest: 1.0077780 (4660)\ttotal: 8m 36s\tremaining: 37.6s\n",
      "4661:\ttotal: 8m 37s\tremaining: 37.5s\n",
      "4662:\ttotal: 8m 37s\tremaining: 37.4s\n",
      "4663:\ttotal: 8m 37s\tremaining: 37.3s\n",
      "4664:\ttotal: 8m 37s\tremaining: 37.2s\n",
      "4665:\tlearn: 0.5629907\ttest: 1.0077026\tbest: 1.0077026 (4665)\ttotal: 8m 37s\tremaining: 37s\n",
      "4666:\ttotal: 8m 37s\tremaining: 36.9s\n",
      "4667:\ttotal: 8m 37s\tremaining: 36.8s\n",
      "4668:\ttotal: 8m 37s\tremaining: 36.7s\n",
      "4669:\ttotal: 8m 37s\tremaining: 36.6s\n",
      "4670:\tlearn: 0.5626308\ttest: 1.0076128\tbest: 1.0076128 (4670)\ttotal: 8m 38s\tremaining: 36.5s\n",
      "4671:\ttotal: 8m 38s\tremaining: 36.4s\n",
      "4672:\ttotal: 8m 38s\tremaining: 36.3s\n",
      "4673:\ttotal: 8m 38s\tremaining: 36.2s\n",
      "4674:\ttotal: 8m 38s\tremaining: 36s\n",
      "4675:\tlearn: 0.5623214\ttest: 1.0075685\tbest: 1.0075685 (4675)\ttotal: 8m 38s\tremaining: 35.9s\n",
      "4676:\ttotal: 8m 38s\tremaining: 35.8s\n",
      "4677:\ttotal: 8m 38s\tremaining: 35.7s\n",
      "4678:\ttotal: 8m 38s\tremaining: 35.6s\n",
      "4679:\ttotal: 8m 38s\tremaining: 35.5s\n",
      "4680:\tlearn: 0.5620469\ttest: 1.0075108\tbest: 1.0075108 (4680)\ttotal: 8m 38s\tremaining: 35.4s\n",
      "4681:\ttotal: 8m 39s\tremaining: 35.3s\n",
      "4682:\ttotal: 8m 39s\tremaining: 35.1s\n",
      "4683:\ttotal: 8m 39s\tremaining: 35s\n",
      "4684:\ttotal: 8m 39s\tremaining: 34.9s\n",
      "4685:\tlearn: 0.5617281\ttest: 1.0074354\tbest: 1.0074354 (4685)\ttotal: 8m 39s\tremaining: 34.8s\n",
      "4686:\ttotal: 8m 39s\tremaining: 34.7s\n",
      "4687:\ttotal: 8m 39s\tremaining: 34.6s\n",
      "4688:\ttotal: 8m 39s\tremaining: 34.5s\n",
      "4689:\ttotal: 8m 39s\tremaining: 34.4s\n",
      "4690:\tlearn: 0.5614200\ttest: 1.0073353\tbest: 1.0073353 (4690)\ttotal: 8m 39s\tremaining: 34.2s\n",
      "4691:\ttotal: 8m 40s\tremaining: 34.1s\n",
      "4692:\ttotal: 8m 40s\tremaining: 34s\n",
      "4693:\ttotal: 8m 40s\tremaining: 33.9s\n",
      "4694:\ttotal: 8m 40s\tremaining: 33.8s\n",
      "4695:\tlearn: 0.5610592\ttest: 1.0072625\tbest: 1.0072625 (4695)\ttotal: 8m 40s\tremaining: 33.7s\n",
      "4696:\ttotal: 8m 40s\tremaining: 33.6s\n",
      "4697:\ttotal: 8m 40s\tremaining: 33.5s\n",
      "4698:\ttotal: 8m 40s\tremaining: 33.4s\n",
      "4699:\ttotal: 8m 40s\tremaining: 33.2s\n",
      "4700:\tlearn: 0.5607325\ttest: 1.0072743\tbest: 1.0072625 (4695)\ttotal: 8m 40s\tremaining: 33.1s\n",
      "4701:\ttotal: 8m 41s\tremaining: 33s\n",
      "4702:\ttotal: 8m 41s\tremaining: 32.9s\n",
      "4703:\ttotal: 8m 41s\tremaining: 32.8s\n",
      "4704:\ttotal: 8m 41s\tremaining: 32.7s\n",
      "4705:\tlearn: 0.5603566\ttest: 1.0072479\tbest: 1.0072479 (4705)\ttotal: 8m 41s\tremaining: 32.6s\n",
      "4706:\ttotal: 8m 41s\tremaining: 32.5s\n",
      "4707:\ttotal: 8m 41s\tremaining: 32.4s\n",
      "4708:\ttotal: 8m 41s\tremaining: 32.2s\n",
      "4709:\ttotal: 8m 41s\tremaining: 32.1s\n",
      "4710:\tlearn: 0.5600401\ttest: 1.0071962\tbest: 1.0071962 (4710)\ttotal: 8m 41s\tremaining: 32s\n",
      "4711:\ttotal: 8m 42s\tremaining: 31.9s\n",
      "4712:\ttotal: 8m 42s\tremaining: 31.8s\n",
      "4713:\ttotal: 8m 42s\tremaining: 31.7s\n",
      "4714:\ttotal: 8m 42s\tremaining: 31.6s\n",
      "4715:\tlearn: 0.5597147\ttest: 1.0071300\tbest: 1.0071300 (4715)\ttotal: 8m 42s\tremaining: 31.5s\n",
      "4716:\ttotal: 8m 42s\tremaining: 31.3s\n",
      "4717:\ttotal: 8m 42s\tremaining: 31.2s\n",
      "4718:\ttotal: 8m 42s\tremaining: 31.1s\n",
      "4719:\ttotal: 8m 42s\tremaining: 31s\n",
      "4720:\tlearn: 0.5593689\ttest: 1.0069831\tbest: 1.0069831 (4720)\ttotal: 8m 42s\tremaining: 30.9s\n",
      "4721:\ttotal: 8m 43s\tremaining: 30.8s\n",
      "4722:\ttotal: 8m 43s\tremaining: 30.7s\n",
      "4723:\ttotal: 8m 43s\tremaining: 30.6s\n",
      "4724:\ttotal: 8m 43s\tremaining: 30.5s\n",
      "4725:\tlearn: 0.5590682\ttest: 1.0069109\tbest: 1.0069109 (4725)\ttotal: 8m 43s\tremaining: 30.3s\n",
      "4726:\ttotal: 8m 43s\tremaining: 30.2s\n",
      "4727:\ttotal: 8m 43s\tremaining: 30.1s\n",
      "4728:\ttotal: 8m 43s\tremaining: 30s\n",
      "4729:\ttotal: 8m 43s\tremaining: 29.9s\n",
      "4730:\tlearn: 0.5587602\ttest: 1.0068565\tbest: 1.0068565 (4730)\ttotal: 8m 43s\tremaining: 29.8s\n",
      "4731:\ttotal: 8m 43s\tremaining: 29.7s\n",
      "4732:\ttotal: 8m 44s\tremaining: 29.6s\n",
      "4733:\ttotal: 8m 44s\tremaining: 29.5s\n",
      "4734:\ttotal: 8m 44s\tremaining: 29.3s\n",
      "4735:\tlearn: 0.5584384\ttest: 1.0068055\tbest: 1.0068055 (4735)\ttotal: 8m 44s\tremaining: 29.2s\n",
      "4736:\ttotal: 8m 44s\tremaining: 29.1s\n",
      "4737:\ttotal: 8m 44s\tremaining: 29s\n",
      "4738:\ttotal: 8m 44s\tremaining: 28.9s\n",
      "4739:\ttotal: 8m 44s\tremaining: 28.8s\n",
      "4740:\tlearn: 0.5580986\ttest: 1.0068012\tbest: 1.0068012 (4740)\ttotal: 8m 44s\tremaining: 28.7s\n",
      "4741:\ttotal: 8m 44s\tremaining: 28.6s\n",
      "4742:\ttotal: 8m 45s\tremaining: 28.4s\n",
      "4743:\ttotal: 8m 45s\tremaining: 28.3s\n",
      "4744:\ttotal: 8m 45s\tremaining: 28.2s\n",
      "4745:\tlearn: 0.5577643\ttest: 1.0067488\tbest: 1.0067488 (4745)\ttotal: 8m 45s\tremaining: 28.1s\n",
      "4746:\ttotal: 8m 45s\tremaining: 28s\n",
      "4747:\ttotal: 8m 45s\tremaining: 27.9s\n",
      "4748:\ttotal: 8m 45s\tremaining: 27.8s\n",
      "4749:\ttotal: 8m 45s\tremaining: 27.7s\n",
      "4750:\tlearn: 0.5574621\ttest: 1.0066731\tbest: 1.0066731 (4750)\ttotal: 8m 45s\tremaining: 27.6s\n",
      "4751:\ttotal: 8m 45s\tremaining: 27.4s\n",
      "4752:\ttotal: 8m 46s\tremaining: 27.3s\n",
      "4753:\ttotal: 8m 46s\tremaining: 27.2s\n",
      "4754:\ttotal: 8m 46s\tremaining: 27.1s\n",
      "4755:\tlearn: 0.5571079\ttest: 1.0066358\tbest: 1.0066358 (4755)\ttotal: 8m 46s\tremaining: 27s\n",
      "4756:\ttotal: 8m 46s\tremaining: 26.9s\n",
      "4757:\ttotal: 8m 46s\tremaining: 26.8s\n",
      "4758:\ttotal: 8m 46s\tremaining: 26.7s\n",
      "4759:\ttotal: 8m 46s\tremaining: 26.6s\n",
      "4760:\tlearn: 0.5568098\ttest: 1.0064743\tbest: 1.0064743 (4760)\ttotal: 8m 46s\tremaining: 26.4s\n",
      "4761:\ttotal: 8m 46s\tremaining: 26.3s\n",
      "4762:\ttotal: 8m 46s\tremaining: 26.2s\n",
      "4763:\ttotal: 8m 47s\tremaining: 26.1s\n",
      "4764:\ttotal: 8m 47s\tremaining: 26s\n",
      "4765:\tlearn: 0.5564514\ttest: 1.0065079\tbest: 1.0064743 (4760)\ttotal: 8m 47s\tremaining: 25.9s\n",
      "4766:\ttotal: 8m 47s\tremaining: 25.8s\n",
      "4767:\ttotal: 8m 47s\tremaining: 25.7s\n",
      "4768:\ttotal: 8m 47s\tremaining: 25.6s\n",
      "4769:\ttotal: 8m 47s\tremaining: 25.4s\n",
      "4770:\tlearn: 0.5561283\ttest: 1.0065063\tbest: 1.0064743 (4760)\ttotal: 8m 47s\tremaining: 25.3s\n",
      "4771:\ttotal: 8m 47s\tremaining: 25.2s\n",
      "4772:\ttotal: 8m 48s\tremaining: 25.1s\n",
      "4773:\ttotal: 8m 48s\tremaining: 25s\n",
      "4774:\ttotal: 8m 48s\tremaining: 24.9s\n",
      "4775:\tlearn: 0.5558398\ttest: 1.0064304\tbest: 1.0064304 (4775)\ttotal: 8m 48s\tremaining: 24.8s\n",
      "4776:\ttotal: 8m 48s\tremaining: 24.7s\n",
      "4777:\ttotal: 8m 48s\tremaining: 24.6s\n",
      "4778:\ttotal: 8m 48s\tremaining: 24.4s\n",
      "4779:\ttotal: 8m 48s\tremaining: 24.3s\n",
      "4780:\tlearn: 0.5554880\ttest: 1.0063227\tbest: 1.0063227 (4780)\ttotal: 8m 48s\tremaining: 24.2s\n",
      "4781:\ttotal: 8m 48s\tremaining: 24.1s\n",
      "4782:\ttotal: 8m 49s\tremaining: 24s\n",
      "4783:\ttotal: 8m 49s\tremaining: 23.9s\n",
      "4784:\ttotal: 8m 49s\tremaining: 23.8s\n",
      "4785:\tlearn: 0.5551258\ttest: 1.0062280\tbest: 1.0062280 (4785)\ttotal: 8m 49s\tremaining: 23.7s\n",
      "4786:\ttotal: 8m 49s\tremaining: 23.6s\n",
      "4787:\ttotal: 8m 49s\tremaining: 23.4s\n",
      "4788:\ttotal: 8m 49s\tremaining: 23.3s\n",
      "4789:\ttotal: 8m 49s\tremaining: 23.2s\n",
      "4790:\tlearn: 0.5547479\ttest: 1.0061748\tbest: 1.0061748 (4790)\ttotal: 8m 49s\tremaining: 23.1s\n",
      "4791:\ttotal: 8m 50s\tremaining: 23s\n",
      "4792:\ttotal: 8m 50s\tremaining: 22.9s\n",
      "4793:\ttotal: 8m 50s\tremaining: 22.8s\n",
      "4794:\ttotal: 8m 50s\tremaining: 22.7s\n",
      "4795:\tlearn: 0.5544071\ttest: 1.0061147\tbest: 1.0061147 (4795)\ttotal: 8m 50s\tremaining: 22.6s\n",
      "4796:\ttotal: 8m 50s\tremaining: 22.4s\n",
      "4797:\ttotal: 8m 50s\tremaining: 22.3s\n",
      "4798:\ttotal: 8m 50s\tremaining: 22.2s\n",
      "4799:\ttotal: 8m 50s\tremaining: 22.1s\n",
      "4800:\tlearn: 0.5540566\ttest: 1.0060465\tbest: 1.0060465 (4800)\ttotal: 8m 50s\tremaining: 22s\n",
      "4801:\ttotal: 8m 51s\tremaining: 21.9s\n",
      "4802:\ttotal: 8m 51s\tremaining: 21.8s\n",
      "4803:\ttotal: 8m 51s\tremaining: 21.7s\n",
      "4804:\ttotal: 8m 51s\tremaining: 21.6s\n",
      "4805:\tlearn: 0.5537051\ttest: 1.0059925\tbest: 1.0059925 (4805)\ttotal: 8m 51s\tremaining: 21.5s\n",
      "4806:\ttotal: 8m 51s\tremaining: 21.3s\n",
      "4807:\ttotal: 8m 51s\tremaining: 21.2s\n",
      "4808:\ttotal: 8m 51s\tremaining: 21.1s\n",
      "4809:\ttotal: 8m 51s\tremaining: 21s\n",
      "4810:\tlearn: 0.5533493\ttest: 1.0058888\tbest: 1.0058888 (4810)\ttotal: 8m 51s\tremaining: 20.9s\n",
      "4811:\ttotal: 8m 52s\tremaining: 20.8s\n",
      "4812:\ttotal: 8m 52s\tremaining: 20.7s\n",
      "4813:\ttotal: 8m 52s\tremaining: 20.6s\n",
      "4814:\ttotal: 8m 52s\tremaining: 20.5s\n",
      "4815:\tlearn: 0.5529989\ttest: 1.0058424\tbest: 1.0058424 (4815)\ttotal: 8m 52s\tremaining: 20.3s\n",
      "4816:\ttotal: 8m 52s\tremaining: 20.2s\n",
      "4817:\ttotal: 8m 52s\tremaining: 20.1s\n",
      "4818:\ttotal: 8m 52s\tremaining: 20s\n",
      "4819:\ttotal: 8m 52s\tremaining: 19.9s\n",
      "4820:\tlearn: 0.5526713\ttest: 1.0058012\tbest: 1.0058012 (4820)\ttotal: 8m 53s\tremaining: 19.8s\n",
      "4821:\ttotal: 8m 53s\tremaining: 19.7s\n",
      "4822:\ttotal: 8m 53s\tremaining: 19.6s\n",
      "4823:\ttotal: 8m 53s\tremaining: 19.5s\n",
      "4824:\ttotal: 8m 53s\tremaining: 19.3s\n",
      "4825:\tlearn: 0.5523334\ttest: 1.0056718\tbest: 1.0056718 (4825)\ttotal: 8m 53s\tremaining: 19.2s\n",
      "4826:\ttotal: 8m 53s\tremaining: 19.1s\n",
      "4827:\ttotal: 8m 53s\tremaining: 19s\n",
      "4828:\ttotal: 8m 53s\tremaining: 18.9s\n",
      "4829:\ttotal: 8m 53s\tremaining: 18.8s\n",
      "4830:\tlearn: 0.5520392\ttest: 1.0055785\tbest: 1.0055785 (4830)\ttotal: 8m 53s\tremaining: 18.7s\n",
      "4831:\ttotal: 8m 54s\tremaining: 18.6s\n",
      "4832:\ttotal: 8m 54s\tremaining: 18.5s\n",
      "4833:\ttotal: 8m 54s\tremaining: 18.3s\n",
      "4834:\ttotal: 8m 54s\tremaining: 18.2s\n",
      "4835:\tlearn: 0.5516870\ttest: 1.0055349\tbest: 1.0055349 (4835)\ttotal: 8m 54s\tremaining: 18.1s\n",
      "4836:\ttotal: 8m 54s\tremaining: 18s\n",
      "4837:\ttotal: 8m 54s\tremaining: 17.9s\n",
      "4838:\ttotal: 8m 54s\tremaining: 17.8s\n",
      "4839:\ttotal: 8m 54s\tremaining: 17.7s\n",
      "4840:\tlearn: 0.5513756\ttest: 1.0055144\tbest: 1.0055144 (4840)\ttotal: 8m 54s\tremaining: 17.6s\n",
      "4841:\ttotal: 8m 55s\tremaining: 17.5s\n",
      "4842:\ttotal: 8m 55s\tremaining: 17.3s\n",
      "4843:\ttotal: 8m 55s\tremaining: 17.2s\n",
      "4844:\ttotal: 8m 55s\tremaining: 17.1s\n",
      "4845:\tlearn: 0.5511178\ttest: 1.0054676\tbest: 1.0054676 (4845)\ttotal: 8m 55s\tremaining: 17s\n",
      "4846:\ttotal: 8m 55s\tremaining: 16.9s\n",
      "4847:\ttotal: 8m 55s\tremaining: 16.8s\n",
      "4848:\ttotal: 8m 55s\tremaining: 16.7s\n",
      "4849:\ttotal: 8m 55s\tremaining: 16.6s\n",
      "4850:\tlearn: 0.5507443\ttest: 1.0054140\tbest: 1.0054140 (4850)\ttotal: 8m 55s\tremaining: 16.5s\n",
      "4851:\ttotal: 8m 56s\tremaining: 16.4s\n",
      "4852:\ttotal: 8m 56s\tremaining: 16.2s\n",
      "4853:\ttotal: 8m 56s\tremaining: 16.1s\n",
      "4854:\ttotal: 8m 56s\tremaining: 16s\n",
      "4855:\tlearn: 0.5504277\ttest: 1.0053649\tbest: 1.0053649 (4855)\ttotal: 8m 56s\tremaining: 15.9s\n",
      "4856:\ttotal: 8m 56s\tremaining: 15.8s\n",
      "4857:\ttotal: 8m 56s\tremaining: 15.7s\n",
      "4858:\ttotal: 8m 56s\tremaining: 15.6s\n",
      "4859:\ttotal: 8m 56s\tremaining: 15.5s\n",
      "4860:\tlearn: 0.5500768\ttest: 1.0053410\tbest: 1.0053410 (4860)\ttotal: 8m 56s\tremaining: 15.4s\n",
      "4861:\ttotal: 8m 57s\tremaining: 15.2s\n",
      "4862:\ttotal: 8m 57s\tremaining: 15.1s\n",
      "4863:\ttotal: 8m 57s\tremaining: 15s\n",
      "4864:\ttotal: 8m 57s\tremaining: 14.9s\n",
      "4865:\tlearn: 0.5497612\ttest: 1.0053491\tbest: 1.0053410 (4860)\ttotal: 8m 57s\tremaining: 14.8s\n",
      "4866:\ttotal: 8m 57s\tremaining: 14.7s\n",
      "4867:\ttotal: 8m 57s\tremaining: 14.6s\n",
      "4868:\ttotal: 8m 57s\tremaining: 14.5s\n",
      "4869:\ttotal: 8m 57s\tremaining: 14.4s\n",
      "4870:\tlearn: 0.5494460\ttest: 1.0052777\tbest: 1.0052777 (4870)\ttotal: 8m 57s\tremaining: 14.2s\n",
      "4871:\ttotal: 8m 57s\tremaining: 14.1s\n",
      "4872:\ttotal: 8m 58s\tremaining: 14s\n",
      "4873:\ttotal: 8m 58s\tremaining: 13.9s\n",
      "4874:\ttotal: 8m 58s\tremaining: 13.8s\n",
      "4875:\tlearn: 0.5490494\ttest: 1.0053342\tbest: 1.0052777 (4870)\ttotal: 8m 58s\tremaining: 13.7s\n",
      "4876:\ttotal: 8m 58s\tremaining: 13.6s\n",
      "4877:\ttotal: 8m 58s\tremaining: 13.5s\n",
      "4878:\ttotal: 8m 58s\tremaining: 13.4s\n",
      "4879:\ttotal: 8m 58s\tremaining: 13.2s\n",
      "4880:\tlearn: 0.5487320\ttest: 1.0052794\tbest: 1.0052777 (4870)\ttotal: 8m 58s\tremaining: 13.1s\n",
      "4881:\ttotal: 8m 59s\tremaining: 13s\n",
      "4882:\ttotal: 8m 59s\tremaining: 12.9s\n",
      "4883:\ttotal: 8m 59s\tremaining: 12.8s\n",
      "4884:\ttotal: 8m 59s\tremaining: 12.7s\n",
      "4885:\tlearn: 0.5483932\ttest: 1.0052772\tbest: 1.0052772 (4885)\ttotal: 8m 59s\tremaining: 12.6s\n",
      "4886:\ttotal: 8m 59s\tremaining: 12.5s\n",
      "4887:\ttotal: 8m 59s\tremaining: 12.4s\n",
      "4888:\ttotal: 8m 59s\tremaining: 12.3s\n",
      "4889:\ttotal: 8m 59s\tremaining: 12.1s\n",
      "4890:\tlearn: 0.5480439\ttest: 1.0052580\tbest: 1.0052580 (4890)\ttotal: 8m 59s\tremaining: 12s\n",
      "4891:\ttotal: 9m\tremaining: 11.9s\n",
      "4892:\ttotal: 9m\tremaining: 11.8s\n",
      "4893:\ttotal: 9m\tremaining: 11.7s\n",
      "4894:\ttotal: 9m\tremaining: 11.6s\n",
      "4895:\tlearn: 0.5477863\ttest: 1.0052057\tbest: 1.0052057 (4895)\ttotal: 9m\tremaining: 11.5s\n",
      "4896:\ttotal: 9m\tremaining: 11.4s\n",
      "4897:\ttotal: 9m\tremaining: 11.3s\n",
      "4898:\ttotal: 9m\tremaining: 11.1s\n",
      "4899:\ttotal: 9m\tremaining: 11s\n",
      "4900:\tlearn: 0.5474796\ttest: 1.0051843\tbest: 1.0051843 (4900)\ttotal: 9m\tremaining: 10.9s\n",
      "4901:\ttotal: 9m 1s\tremaining: 10.8s\n",
      "4902:\ttotal: 9m 1s\tremaining: 10.7s\n",
      "4903:\ttotal: 9m 1s\tremaining: 10.6s\n",
      "4904:\ttotal: 9m 1s\tremaining: 10.5s\n",
      "4905:\tlearn: 0.5471331\ttest: 1.0051606\tbest: 1.0051606 (4905)\ttotal: 9m 1s\tremaining: 10.4s\n",
      "4906:\ttotal: 9m 1s\tremaining: 10.3s\n",
      "4907:\ttotal: 9m 1s\tremaining: 10.2s\n",
      "4908:\ttotal: 9m 1s\tremaining: 10s\n",
      "4909:\ttotal: 9m 1s\tremaining: 9.93s\n",
      "4910:\tlearn: 0.5468270\ttest: 1.0051163\tbest: 1.0051163 (4910)\ttotal: 9m 1s\tremaining: 9.82s\n",
      "4911:\ttotal: 9m 1s\tremaining: 9.71s\n",
      "4912:\ttotal: 9m 2s\tremaining: 9.6s\n",
      "4913:\ttotal: 9m 2s\tremaining: 9.49s\n",
      "4914:\ttotal: 9m 2s\tremaining: 9.38s\n",
      "4915:\tlearn: 0.5464991\ttest: 1.0050469\tbest: 1.0050469 (4915)\ttotal: 9m 2s\tremaining: 9.27s\n",
      "4916:\ttotal: 9m 2s\tremaining: 9.16s\n",
      "4917:\ttotal: 9m 2s\tremaining: 9.05s\n",
      "4918:\ttotal: 9m 2s\tremaining: 8.94s\n",
      "4919:\ttotal: 9m 2s\tremaining: 8.82s\n",
      "4920:\tlearn: 0.5461965\ttest: 1.0050635\tbest: 1.0050469 (4915)\ttotal: 9m 2s\tremaining: 8.71s\n",
      "4921:\ttotal: 9m 2s\tremaining: 8.6s\n",
      "4922:\ttotal: 9m 3s\tremaining: 8.49s\n",
      "4923:\ttotal: 9m 3s\tremaining: 8.38s\n",
      "4924:\ttotal: 9m 3s\tremaining: 8.27s\n",
      "4925:\tlearn: 0.5458945\ttest: 1.0050235\tbest: 1.0050235 (4925)\ttotal: 9m 3s\tremaining: 8.16s\n",
      "4926:\ttotal: 9m 3s\tremaining: 8.05s\n",
      "4927:\ttotal: 9m 3s\tremaining: 7.94s\n",
      "4928:\ttotal: 9m 3s\tremaining: 7.83s\n",
      "4929:\ttotal: 9m 3s\tremaining: 7.72s\n",
      "4930:\tlearn: 0.5455732\ttest: 1.0049942\tbest: 1.0049942 (4930)\ttotal: 9m 3s\tremaining: 7.61s\n",
      "4931:\ttotal: 9m 3s\tremaining: 7.5s\n",
      "4932:\ttotal: 9m 4s\tremaining: 7.39s\n",
      "4933:\ttotal: 9m 4s\tremaining: 7.28s\n",
      "4934:\ttotal: 9m 4s\tremaining: 7.17s\n",
      "4935:\tlearn: 0.5452152\ttest: 1.0049537\tbest: 1.0049537 (4935)\ttotal: 9m 4s\tremaining: 7.06s\n",
      "4936:\ttotal: 9m 4s\tremaining: 6.95s\n",
      "4937:\ttotal: 9m 4s\tremaining: 6.84s\n",
      "4938:\ttotal: 9m 4s\tremaining: 6.73s\n",
      "4939:\ttotal: 9m 4s\tremaining: 6.62s\n",
      "4940:\tlearn: 0.5449278\ttest: 1.0048746\tbest: 1.0048746 (4940)\ttotal: 9m 4s\tremaining: 6.51s\n",
      "4941:\ttotal: 9m 4s\tremaining: 6.39s\n",
      "4942:\ttotal: 9m 5s\tremaining: 6.29s\n",
      "4943:\ttotal: 9m 5s\tremaining: 6.17s\n",
      "4944:\ttotal: 9m 5s\tremaining: 6.06s\n",
      "4945:\tlearn: 0.5446244\ttest: 1.0048295\tbest: 1.0048295 (4945)\ttotal: 9m 5s\tremaining: 5.95s\n",
      "4946:\ttotal: 9m 5s\tremaining: 5.84s\n",
      "4947:\ttotal: 9m 5s\tremaining: 5.73s\n",
      "4948:\ttotal: 9m 5s\tremaining: 5.62s\n",
      "4949:\ttotal: 9m 5s\tremaining: 5.51s\n",
      "4950:\tlearn: 0.5442985\ttest: 1.0047917\tbest: 1.0047917 (4950)\ttotal: 9m 5s\tremaining: 5.4s\n",
      "4951:\ttotal: 9m 5s\tremaining: 5.29s\n",
      "4952:\ttotal: 9m 6s\tremaining: 5.18s\n",
      "4953:\ttotal: 9m 6s\tremaining: 5.07s\n",
      "4954:\ttotal: 9m 6s\tremaining: 4.96s\n",
      "4955:\tlearn: 0.5439663\ttest: 1.0046675\tbest: 1.0046675 (4955)\ttotal: 9m 6s\tremaining: 4.85s\n",
      "4956:\ttotal: 9m 6s\tremaining: 4.74s\n",
      "4957:\ttotal: 9m 6s\tremaining: 4.63s\n",
      "4958:\ttotal: 9m 6s\tremaining: 4.52s\n",
      "4959:\ttotal: 9m 6s\tremaining: 4.41s\n",
      "4960:\tlearn: 0.5436533\ttest: 1.0045552\tbest: 1.0045552 (4960)\ttotal: 9m 6s\tremaining: 4.3s\n",
      "4961:\ttotal: 9m 6s\tremaining: 4.19s\n",
      "4962:\ttotal: 9m 7s\tremaining: 4.08s\n",
      "4963:\ttotal: 9m 7s\tremaining: 3.97s\n",
      "4964:\ttotal: 9m 7s\tremaining: 3.86s\n",
      "4965:\tlearn: 0.5432996\ttest: 1.0045184\tbest: 1.0045184 (4965)\ttotal: 9m 7s\tremaining: 3.75s\n",
      "4966:\ttotal: 9m 7s\tremaining: 3.64s\n",
      "4967:\ttotal: 9m 7s\tremaining: 3.53s\n",
      "4968:\ttotal: 9m 7s\tremaining: 3.42s\n",
      "4969:\ttotal: 9m 7s\tremaining: 3.31s\n",
      "4970:\tlearn: 0.5430249\ttest: 1.0045031\tbest: 1.0045031 (4970)\ttotal: 9m 7s\tremaining: 3.2s\n",
      "4971:\ttotal: 9m 7s\tremaining: 3.09s\n",
      "4972:\ttotal: 9m 8s\tremaining: 2.98s\n",
      "4973:\ttotal: 9m 8s\tremaining: 2.87s\n",
      "4974:\ttotal: 9m 8s\tremaining: 2.75s\n",
      "4975:\tlearn: 0.5427565\ttest: 1.0045029\tbest: 1.0045029 (4975)\ttotal: 9m 8s\tremaining: 2.64s\n",
      "4976:\ttotal: 9m 8s\tremaining: 2.53s\n",
      "4977:\ttotal: 9m 8s\tremaining: 2.42s\n",
      "4978:\ttotal: 9m 8s\tremaining: 2.31s\n",
      "4979:\ttotal: 9m 8s\tremaining: 2.2s\n",
      "4980:\tlearn: 0.5424529\ttest: 1.0044797\tbest: 1.0044797 (4980)\ttotal: 9m 8s\tremaining: 2.09s\n",
      "4981:\ttotal: 9m 8s\tremaining: 1.98s\n",
      "4982:\ttotal: 9m 9s\tremaining: 1.87s\n",
      "4983:\ttotal: 9m 9s\tremaining: 1.76s\n",
      "4984:\ttotal: 9m 9s\tremaining: 1.65s\n",
      "4985:\tlearn: 0.5421748\ttest: 1.0044603\tbest: 1.0044603 (4985)\ttotal: 9m 9s\tremaining: 1.54s\n",
      "4986:\ttotal: 9m 9s\tremaining: 1.43s\n",
      "4987:\ttotal: 9m 9s\tremaining: 1.32s\n",
      "4988:\ttotal: 9m 9s\tremaining: 1.21s\n",
      "4989:\ttotal: 9m 9s\tremaining: 1.1s\n",
      "4990:\tlearn: 0.5419036\ttest: 1.0044025\tbest: 1.0044025 (4990)\ttotal: 9m 9s\tremaining: 991ms\n",
      "4991:\ttotal: 9m 9s\tremaining: 881ms\n",
      "4992:\ttotal: 9m 10s\tremaining: 771ms\n",
      "4993:\ttotal: 9m 10s\tremaining: 661ms\n",
      "4994:\ttotal: 9m 10s\tremaining: 551ms\n",
      "4995:\tlearn: 0.5416077\ttest: 1.0043655\tbest: 1.0043655 (4995)\ttotal: 9m 10s\tremaining: 441ms\n",
      "4996:\ttotal: 9m 10s\tremaining: 330ms\n",
      "4997:\ttotal: 9m 10s\tremaining: 220ms\n",
      "4998:\ttotal: 9m 10s\tremaining: 110ms\n",
      "4999:\tlearn: 0.5413286\ttest: 1.0043619\tbest: 1.0043619 (4999)\ttotal: 9m 10s\tremaining: 0us\n",
      "bestTest = 1.004361921\n",
      "bestIteration = 4999\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f4abb2b0df0>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "clf = CatBoostClassifier(\n",
    "    iterations=5000,\n",
    "    random_seed=42,\n",
    "    learning_rate=0.001,\n",
    "    custom_loss=['AUC', 'Accuracy'],\n",
    "#   verbose=5,\n",
    "    task_type=\"GPU\"\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_for_RF, y_train,\n",
    "    eval_set=(X_test_features, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prediction_RF \u001b[38;5;241m=\u001b[39m \u001b[43mclf\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test_features)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "prediction_RF = clf.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  0.5486725663716814\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 6s 540ms/step\n",
      "4/4 [==============================] - 2s 471ms/step\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = resnet_model.predict(X_train)\n",
    "\n",
    "features = feature_extractor.reshape(feature_extractor.shape[0], -1)\n",
    "\n",
    "X_for_RF = features #This is our X input to RF\n",
    "\n",
    "RF_model = RandomForestClassifier(n_estimators = 250, max_depth=10, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "RF_model.fit(X_for_RF, y_train) #For sklearn no one hot encoding\n",
    "\n",
    "#Send test data through same feature extractor process\n",
    "X_test_feature = resnet_model.predict(X_test)\n",
    "X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)\n",
    "\n",
    "#Now predict using the trained RF model. \n",
    "prediction_RF = RF_model.predict(X_test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metrics\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy = \u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m.\u001b[39maccuracy_score(\u001b[43my_test\u001b[49m, prediction_RF))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import metrics\n",
    "print (\"Accuracy = \", metrics.accuracy_score(y_test, prediction_RF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m X_for_RF \u001b[38;5;241m=\u001b[39m \u001b[43mfeature_extractor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m(df_interno)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "X_for_RF = feature_extractor.predict(df_interno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43madaBoostClassificator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_for_RF\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/feijao/Classificacao-main/classificadores.py:180\u001b[0m, in \u001b[0;36madaBoostClassificator\u001b[0;34m(X, y, folds)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39madaBoostClassificator\u001b[39m(X, y, folds):\n\u001b[1;32m    176\u001b[0m \t\u001b[39m# ----------------------- ADA Boost -------------------------------\u001b[39;00m\n\u001b[1;32m    177\u001b[0m \t\u001b[39m# ad = AdaBoostClassifier(n_estimators=10, algorithm=\"SAMME.R\", random_state=1)  # binary\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \tad \u001b[39m=\u001b[39m AdaBoostClassifier(tree\u001b[39m.\u001b[39mDecisionTreeClassifier(max_depth\u001b[39m=\u001b[39m\u001b[39m8\u001b[39m), n_estimators\u001b[39m=\u001b[39m\u001b[39m256\u001b[39m,\n\u001b[1;32m    179\u001b[0m \t                        learning_rate\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m)  \u001b[39m# multiclass\u001b[39;00m\n\u001b[0;32m--> 180\u001b[0m \tcross_validation(\u001b[39m'\u001b[39;49m\u001b[39mAD\u001b[39;49m\u001b[39m'\u001b[39;49m, ad, X, y, folds)\n\u001b[1;32m    181\u001b[0m \t\u001b[39m# scores = cross_val_score(clf, X, y, cv=5)\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \t\u001b[39m# scores.mean()\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \tX_treino, X_teste, y_treino, y_teste \u001b[39m=\u001b[39m train_test_split(X, y, test_size\u001b[39m=\u001b[39m\u001b[39m0.3\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/feijao/Classificacao-main/classificadores.py:23\u001b[0m, in \u001b[0;36mcross_validation\u001b[0;34m(name, classifier, X, y, k)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcross_validation\u001b[39m(name, classifier, X, y, k):\n\u001b[1;32m     21\u001b[0m \t\u001b[39m# cross-validation k-folds\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \tfolds \u001b[39m=\u001b[39m k\n\u001b[0;32m---> 23\u001b[0m \tscoresAccuracy \u001b[39m=\u001b[39m cross_val_score(classifier, X, y, cv\u001b[39m=\u001b[39;49mfolds, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     24\u001b[0m \tscoresPrecision \u001b[39m=\u001b[39m cross_val_score(classifier, X, y, cv\u001b[39m=\u001b[39mfolds, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mprecision_macro\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     25\u001b[0m \tscoresRecall \u001b[39m=\u001b[39m cross_val_score(classifier, X, y, cv\u001b[39m=\u001b[39mfolds, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mrecall_macro\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:515\u001b[0m, in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[1;32m    513\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[0;32m--> 515\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[1;32m    516\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[1;32m    517\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[1;32m    518\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[1;32m    519\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[1;32m    520\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[1;32m    521\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[1;32m    522\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[1;32m    523\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    524\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[1;32m    525\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[1;32m    526\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    527\u001b[0m )\n\u001b[1;32m    528\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:266\u001b[0m, in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[39m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[1;32m    265\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m--> 266\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    267\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    268\u001b[0m         clone(estimator),\n\u001b[1;32m    269\u001b[0m         X,\n\u001b[1;32m    270\u001b[0m         y,\n\u001b[1;32m    271\u001b[0m         scorers,\n\u001b[1;32m    272\u001b[0m         train,\n\u001b[1;32m    273\u001b[0m         test,\n\u001b[1;32m    274\u001b[0m         verbose,\n\u001b[1;32m    275\u001b[0m         \u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m    276\u001b[0m         fit_params,\n\u001b[1;32m    277\u001b[0m         return_train_score\u001b[39m=\u001b[39;49mreturn_train_score,\n\u001b[1;32m    278\u001b[0m         return_times\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    279\u001b[0m         return_estimator\u001b[39m=\u001b[39;49mreturn_estimator,\n\u001b[1;32m    280\u001b[0m         error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[1;32m    281\u001b[0m     )\n\u001b[1;32m    282\u001b[0m     \u001b[39mfor\u001b[39;49;00m train, test \u001b[39min\u001b[39;49;00m cv\u001b[39m.\u001b[39;49msplit(X, y, groups)\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    285\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[1;32m    287\u001b[0m \u001b[39m# For callabe scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:1088\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdispatch_one_batch(iterator):\n\u001b[1;32m   1089\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \u001b[39mif\u001b[39;00m pre_dispatch \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mall\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1092\u001b[0m     \u001b[39m# The iterable was consumed all at once by the above for loop.\u001b[39;00m\n\u001b[1;32m   1093\u001b[0m     \u001b[39m# No need to wait for async callbacks to trigger to\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m     \u001b[39m# consumption.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_backend\u001b[39m.\u001b[39;49mapply_async(batch, callback\u001b[39m=\u001b[39;49mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m     \u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/fixes.py:117\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    116\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfig):\n\u001b[0;32m--> 117\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    684\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    685\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 686\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    688\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    689\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:506\u001b[0m, in \u001b[0;36mAdaBoostClassifier.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    501\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAlgorithm must be \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    502\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm\u001b[39m!r}\u001b[39;00m\u001b[39m instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    503\u001b[0m     )\n\u001b[1;32m    505\u001b[0m \u001b[39m# Fit\u001b[39;00m\n\u001b[0;32m--> 506\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:160\u001b[0m, in \u001b[0;36mBaseWeightBoosting.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    156\u001b[0m random_state \u001b[39m=\u001b[39m check_random_state(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrandom_state)\n\u001b[1;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m iboost \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators):\n\u001b[1;32m    159\u001b[0m     \u001b[39m# Boosting step\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     sample_weight, estimator_weight, estimator_error \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost(\n\u001b[1;32m    161\u001b[0m         iboost, X, y, sample_weight, random_state\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m     \u001b[39m# Early termination\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:568\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[39m\"\"\"Implement a single boost.\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \n\u001b[1;32m    531\u001b[0m \u001b[39mPerform a single boost according to the real multi-class SAMME.R\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39m    If None then boosting has terminated early.\u001b[39;00m\n\u001b[1;32m    566\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    567\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39malgorithm \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSAMME.R\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 568\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_boost_real(iboost, X, y, sample_weight, random_state)\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# elif self.algorithm == \"SAMME\":\u001b[39;00m\n\u001b[1;32m    571\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_boost_discrete(iboost, X, y, sample_weight, random_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/ensemble/_weight_boosting.py:577\u001b[0m, in \u001b[0;36mAdaBoostClassifier._boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39m\"\"\"Implement a single boost using the SAMME.R real algorithm.\"\"\"\u001b[39;00m\n\u001b[1;32m    575\u001b[0m estimator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_estimator(random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m--> 577\u001b[0m estimator\u001b[39m.\u001b[39;49mfit(X, y, sample_weight\u001b[39m=\u001b[39;49msample_weight)\n\u001b[1;32m    579\u001b[0m y_predict_proba \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mpredict_proba(X)\n\u001b[1;32m    581\u001b[0m \u001b[39mif\u001b[39;00m iboost \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:969\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    939\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m    940\u001b[0m     \u001b[39m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[1;32m    941\u001b[0m \n\u001b[1;32m    942\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    966\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    967\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    970\u001b[0m         X,\n\u001b[1;32m    971\u001b[0m         y,\n\u001b[1;32m    972\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    973\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m    974\u001b[0m     )\n\u001b[1;32m    975\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/tree/_classes.py:458\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    448\u001b[0m     builder \u001b[39m=\u001b[39m BestFirstTreeBuilder(\n\u001b[1;32m    449\u001b[0m         splitter,\n\u001b[1;32m    450\u001b[0m         min_samples_split,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_impurity_decrease,\n\u001b[1;32m    456\u001b[0m     )\n\u001b[0;32m--> 458\u001b[0m builder\u001b[39m.\u001b[39;49mbuild(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtree_, X, y, sample_weight)\n\u001b[1;32m    460\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m is_classifier(\u001b[39mself\u001b[39m):\n\u001b[1;32m    461\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_[\u001b[39m0\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#adaBoostClassificator(X_for_RF, classe, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
